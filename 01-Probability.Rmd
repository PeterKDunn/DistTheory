\mainmatter

# Probability essentials {#Probability}


::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
Upon completion of this module you should be able to:

* understand the concepts of probability, and apply rules of probability.
* define probability from different perspectives and apply them to compute probabilities in various situations.
* apply the concepts of conditional probability and independence.
* differentiate between mutually exclusive events and independent events.
* apply Bayes' Theorem.
* use combinations and permutations to compute the probabilities of various events involving counting problems.
:::




## Introduction

Imagine if life was deterministic!
The commute to university or work would always take exactly the same length of time; weather predictions would always be accurate; you would know exactly what lotto numbers would be drawn on the weekend...

However, life is full of unpredictable variation.

While variation is  *unpredictable*, patterns still emerge. 
We may not know what the next toss of a coin will produce... but we see a *pattern* in the long run: a Head appears about half the time.

Statistics is essentially the study of the patterns in this unpredictable variation.
Probability is one of the tools used to describe and understand this unpredictability, and the patterns.

In most fields of study, situations exist where being certain is almost impossible, and so probability is necessary:

* What is the chance that Bitcoin will crash next month?
* What are the odds that a medical patient will suffer from a dangerous side-effect?
* How likely is it that a dam will overflow next year?
* What is the chance of finding a rare bird species in a given forest?

To answer these questions, a framework is needed: concepts like *probability* need defining, and notation and theory are required.
These tools are important for modelling real-world phenomena, but also for providing a firm mathematical foundation for the theory of statistics.

This chapter covers the concept of probability, introduces notation and definitions, and develops some theory useful in working with probabilities.


## Sets, sample space, sample points {#SampleSpaces}

The basis of probability is dealing with *sets*, which we first define.


::: {.definition #Sets name="Sets"}
A *set* is a collection of *elements*, usually denoted using a capital letter: $A$.
:::


Sets may comprise:

* Distinct elements, such as the set comprising the six states of Australia.
* Regions, such as the set of real numbers.


:::{.definition #Elements name="Elements"}
If a set $A$ has distinct components, these are called the *elements* of the set, and are usually denoted by lower-case letters, and are shown to belong to a set by enclosing them in braces:
\[
   A = \{ a_1, a_2, a_3, a_4\}.
\]
:::


Sets can be *described* in various ways:

* By listing the individual elements.
  After rolling a single die, the set $R$ can be defined by listing its elements: $R = \{2, 4, 6\}$.
* By describing the elements.
  Set $A$ may be 'States belonging to the United States of America'. 
* By describing a pattern.
  The set $N$ could be defined by the pattern: $N = \{1, 3, 5, 7, 9, \dots\}$.
* By describing regions rather than distinct elements.
  The set $H$ may be the set of 'the heights of humans'.
 

In the context of probability, sets are related to the outcomes of *random processes*.


:::{.definition #Process name="Random process"}
A **random process** is a procedure that:

* can be repeated, in theory, indefinitely under essentially identical conditions; and
* has well-defined outcomes; and
* the outcome of any individual repetition is unpredictable.
:::


Essentially, a random process produces unknown outcomes.
Examples of simple *random processes* include tossing a coin, or rolling a die.

The possible outcomes of the random process constitute a special *set*, called the *sample space*.


::: {.definition #SampleSpace name="Sample space"}
A *sample space* (or *event space*, or *outcome space*) for a random process is a set of all possible outcomes from a random process, usually denoted by $S$, $\Omega$ or $U$ (for the 'universal set').

When appropriate, a single element of $S$ is called an *element* or *sample point*.
The sample points are usually denoted $s_1$, $s_2$, and so on.
:::


:::{.example #SampleSpaceDice name="Sample space"}
Consider observing the uppermost number on rolling a die (the outcome).
The sample space $S$ is the set:
\[
   S = \{1, 2, 3, 4, 5, 6 \}.
\]
There are six sample points.
:::


:::{.example #SampleSpaceContinuous name="Sample space"}
Consider observing the distance a cricket ball can be thrown.
The sample space $\Omega$ is:
\[
   \Omega = \mathbb{R}_{+},
\]
where $\mathbb{R}_{+}$ represents the positive real numbers.
No absolute upper limit exists for the distance the ball can be thrown, though clearly some parts of the sample space are extremely unlikely to be observed.
:::


One special set is useful to define.


:::{.definition #EmptySet name="Empty set"}
The **null set**, or the *empty set* has zero points, and is denoted by $\emptyset$.
:::


:::{.example #NullSet name="Null set"}
Consider observing the outcome on a single roll of a die (Example \@ref(exm:SampleSpaceDice)).

The set 'Observing a number larger than 10' has no elements; the set is the *null set*.
:::


## Discrete and continuous sample spaces

Sample spaces may be discrete or continuous.

::: {.definition #DiscreteSampleSpace name="Discrete sample space"}
A *discrete sample space* is a sample space that contains a finite, or countably infinite, number of distinct sample points.
:::


The idea of a *countably infinite* number of distinct sample points sounds a little strange... an example helps illustrate.


:::{.example #RollingTill6 name="Countably infinite sample space"}
Consider rolling a standard die, and counting the number of rolls needed until a 6 is thrown.

The *sample space* is the set of all possible outcomes.
Now, the 6 could appear on the first roll, or the second, or the third.

However, even though it is very unlikely, it may take 20 rolls... or 50 rolls.
What is the *maximum* number?
There is no maximum number (though there is a point beyond which it becomes extremely unlikely).
In such a situation, we say there are a 'countably' infinite number of points even though we can't list them all.
The sample space could be denoted
\[
   S = \{ 1, 2, 3, \dots \}.
\]
:::


:::{.example #DiscreteSS name="Discrete sample space"}
Consider observing the uppermost number on rolling a die (Example \@ref(exm:SampleSpaceDice)).
The sample space $S$ is *discrete* with exactly six sample points.
:::


::: {.definition #ContinuousSampleSpace name="Continuous sample space"}
A *continuous sample space* is a sample space where any interval contains an infinite number of points.
:::


:::{.example #ContinuousSampleSpaceThrow name="Continuous sample space"}
Example \@ref(exm:SampleSpaceContinuous) considered the distance a cricket ball can be thrown.
The sample space $\Omega$ was
\[
   \Omega = \mathbb{R}_{+},
\]
where $\mathbb{R}_{+}$ represents the positive real numbers.

The distance cannot be specified *exactly*.
The distance could, in principle, be recorded to any number of decimal places with suitable equipment. 
Between a distance of 35.71m and 35.72m are an infinite number of possible values (in theory).
The sample space $\Omega$ is *continuous*.

Furthermore, no upper limit exists for the distance the ball can be thrown, though clearly some parts of the sample space are extremely unlikely to be observed.
:::


## Events {#Events}

While the sample space defines the set of *all* possible outcomes, usually we are interested in just some of those elements of the sample space.


::: {.definition #Event name="Event"}
An *event* is a set of sample points (discrete sample space), or a region of the sample space (continuous sample space).
An event is a subset of $S$, and we write $A \subseteq S$.
:::


In the two extreme cases, $S$ itself is an event called the *certain* event, and $\emptyset$ is called the *impossible* (or *nonrealisable*) event.


:::{.example #TwoCoinToss name="Events"}
Consider the simple random process of tossing a coin twice.

The [sample space](#def:SampleSpace) could be listed as:
\[
   S = \{(HH), (HT), (TH), (TT) \},
\]
where $H$ represents tossing a head and $T$ represents tossing a tail, and the pair lists the result of each toss in order.

We can define the event $A$ as 'tossing a head on the second toss', and list the elements:
\[
   A = \{ (HH), (TH)\}.
\]
The event 'the set of outcomes corresponding to tossing *three* heads' is the [*null set*](#def:NullSet), as there are no sample points with three heads.
:::


::: {.definition #ElementaryEvent name="Elementary event"}
For a discrete sample space, an *elementary event* (or a *simple event*) is an event with one sample point, that cannot be decomposed into smaller events.
:::


:::{.example #ElementaryEvents name="Elementary events"}
Consider observing the outcome on a single roll of a die (Example \@ref(exm:SampleSpaceDice)).
The elementary events are:
\begin{align*}
   E_1:&\quad \text{Roll a 1}; & E_2:&\quad \text{Roll a 2};\\
   E_3:&\quad \text{Roll a 3}; & E_4:&\quad \text{Roll a 4};\\
   E_5:&\quad \text{Roll a 5}; & E_6:&\quad \text{Roll a 6}.\\
\end{align*}
:::

A collection of elementary events is sometimes called a *compound event*.

An important concept is that of an *occurrence* of an event.


::: {.definition #Occurence name="Occurrence"}
An event $A$ *occurs* on a particular trial of a [random process](#RandomProcess) if the outcome of the trial is part of the sample space for the random process.
:::


The relationship between different sets, say sets $A$ and $B$, can be described also.


:::{.definition #IntersectionUnionSubset name="Intersection, union, subset, complement"}
Consider two sets $A$ and $B$ defined on the same sample space $S$.
Then:

* the **intersection** of sets $A$ and $B$, written as $A\cap B$, is the set of points in *both* $A$ and $B$.
* the **union** of sets $A$ and $B$, written as $A\cup B$, is the combined set of all the points in either $A$ or $B$, or both. 
  (Usually we just say that $A\cup B$ comprises the points in '$A$ or $B$'.)
* $A$ is a **subset** of B, written as $A\subset B$, if all the elements of $A$ are in $B$. (Set $B$ may have other elements that are not in $A$.)
* the **complement** of $A$, written $\overline{A}$, is the set of points that are in $S$, but are *not* in $A$.
:::


The visual representation in Fig. \@ref(fig:IntersectionUnionSubset) may help clarify.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Be aware of variations in notation!

The complement of an event $A$ (everything that is *not* in event $A$) can be denoted $\overline{A}$, or $A^c$, or $A'$.
:::

::: {.definition #Implication name="Implication"}
An event $A$ *implies* an event $B$ if, and only if, $A\subseteq B$.
:::


```{r IntersectionUnionSubset, echo=FALSE, out.width='80%', fig.height = 6.5, fig.align="center", fig.cap="Subsets, union, intersection and complement of sets. The rectangle represents the universal set, $S$."}
#par( mar = c(0.05, 0.05, 0.05, 0.05))
par(mfrow = c(2, 2) )


colourA <- rgb(0, 0, 255, 
               max = 255, 
               alpha = 125)
colourB <- rgb(0, 255, 0, 
               max = 255, 
               alpha = 125)
colourS <- rgb(100, 100, 100, 
               max = 255, 
               alpha = 125)


### INTERSECTION
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("The ", bold(intersection), " of sets ", italic(A), " and ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.ellipse(x = 0.4, 
                     y = 0.5,
                     a = 0.22,
                     b = 0.16,
                     col = colourA)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.19,
                     col = colourB)
text(x = 0.4,
     y = 0.65,
     labels = expression(italic(A)), 
     pos = 3)
text(x = 0.6,
     y = 0.75,
     labels = expression(italic(B)), 
     pos = 3)
arrows( x0 = 0.5, 
        y0 = 0.15,
        x1 = 0.5,
        y1 = 0.5,
        length = 0.15,
        lwd = 1)
text(x = 0.5,
     y = 0.18,
     pos = 1,
     labels = expression(italic(A) ~~ intersect() ~~ italic(B)))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


### UNION
colour1 <- plotColour1

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste("The ", bold(union), " of sets ", italic(A), " and ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.ellipse(x = 0.4, 
                     y = 0.5,
                     a = 0.22,
                     b = 0.16,
                     col = colour1,
                     border = colour1)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colour1,
                     border = colour1)
text(x = 0.5,
     y = 0.5,
     labels = expression(italic(A) ~~ union() ~~ italic(B)))


text(x = 0.4,
     y = 0.75,
     labels = expression(italic(A)), 
     pos = 3)
text(x = 0.6,
     y = 0.75,
     labels = expression(italic(B)), 
     pos = 3)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)



### SUBSET
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste( italic(A), " is a ", bold(subset), " of ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.ellipse(x = 0.52, 
                     y = 0.55,
                     a = 0.1,
                     b = 0.07,
                     col = colourA)
plotrix::draw.circle(x = 0.5,
                     y = 0.5,
                     radius = 0.2,
                     col = colourB)
text(x = 0.52,
     y = 0.65,
     labels = expression(italic(A)),
     pos = 1)
text(x = 0.5,
     y = 0.75,
     labels = expression(italic(B)),
     pos = 3)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)




### COMPLEMENT
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste("The ", bold(complement), " of ", italic(A) )) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0),
         col = plotColour)
plotrix::draw.ellipse(x = 0.4, 
                     y = 0.5,
                     a = 0.22,
                     b = 0.16,
                     col = "white")
text(x = 0.4,
     y = 0.4,
     labels = expression(italic(A)))
text(x = 0.75,
     y = 0.55,
     labels = expression(bar(italic(A))))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)
```



:::{.example #RollDie name="Rolling a die"}
Suppose we roll a single, six-sided die.
We can define these two events:
\begin{align*}
   E 
   &= \text{An even number is thrown}
   &= \{2, 4, \phantom{5, }6\};\\
   G 
   &= \text{A number larger than 3 is thrown} 
   &= \{\phantom{2, }4, 5, 6\}.
\end{align*}
Then,
\begin{align*}
   E \cap G 
   &= \{4, 6\}\\
   E \cup G
   &= \{ 2, 4, 5, 6\}\\
   \overline{E}
   &= \{ 1, 3, 5\}\\
   \overline{G}
   &= \{ 1, 2, 3\}.
\end{align*}
We make other observations too:
\begin{align}
   E \cap \overline{G}
   &= \{2, 4, 6\} \cap \{ 1, 2, 3\} = \{ 2 \};\\
   \overline{F} \cap \overline{G}
   &= \{1, 3, 5\} \cap \{ 1, 2, 3\} = \{ 1, 3 \}.
\end{align}
See the figure below.


```{r echo=FALSE, out.width = '60%', fig.align="center"}
colourE <- rgb(0, 0, 255, 
               max = 255, 
               alpha = 125)
colourG <- rgb(0, 255, 0, 
               max = 255, 
               alpha = 125)

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(E), " and ", italic(G))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.ellipse(x = 0.4, 
                     y = 0.5,
                     a = 0.2,
                     b = 0.19,
                     col = colourE)
plotrix::draw.ellipse(x = 0.6,
                     y = 0.5,
                     a = 0.2,
                     b = 0.21,
                     col = colourG)
text(x = 0.4,
     y = 0.25,
     labels = expression(italic(E)), 
     pos = 1)
text(x = 0.6,
     y = 0.25,
     labels = expression(italic(G)), 
     pos = 1)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)

# The elements
text(x = c(0.1, 0.5),
     y = c(0.6, 0.9),
     cex = 1.75,
     labels = c("1",
                "3"))
text(x = c(0.52, 0.48),
     y = c(0.55, 0.42),
     cex = 1.75,
     labels = c("4",
                "6"))
text(x = 0.25,
     y = 0.50,
     cex = 1.75,
     labels = "2")
text(x = 0.75,
     y = 0.55,
     cex = 1.75,
     labels = "5" )
```
:::


:::{.example #CricketBallEvents name="Throwing a cricket ball"}
Consider throwing a cricket ball, where the distance of the throw is of interest (Example \@ref(exm:SampleSpaceContinuous)).
Define these two events (Fig. \@ref(fig:CricketBallSpace)):
\begin{align*}
   B_1:&\quad \text{Throw a cricket ball more than 40m};\\
   B_2:&\quad \text{Throw a cricket ball less than 50m}.
\end{align*}
Then:
\begin{align*}
   B_1 \cap B_2   &= \text{Throw the ball between 40m and 50m};\\
   B_1 \cup B_2   &= \mathbb{R}_+;\\
   \overline{B_1} &= \text{Throw the ball less than 40m}.
\end{align*}
:::

```{r CricketBallSpace, out.width='80%',echo=FALSE, fig.height=3, fig.align="center", fig.cap="The two events defined for throwing a cricket ball"}
plot( x = c(-10, 70),
      y = c(0, 0),
      ylim = c(-30, 30),
      type = "l",
      lwd = 2,
      axes = FALSE,
      xlab = "",
      ylab = "")
for (i in seq(0, 70, by = 10)){
   lines( x = c(i, i),
          y = c(-3, 3),
          lwd = 2)
  text(x = i,
       y = -13,
       labels = as.character(i))
}

b1 <- 40
b2 <- 50
b1lo <- 10
b1hi <- 15
b2lo <- 20
b2hi <- 25
b1limit1 <- 60
b1limit2 <- 70

# B1
polygon(x = c(b1limit2, b1, b1, b1limit2),
        y = c(b1lo, b1lo, b1hi, b1hi),
        col = plotColour,
        border = NA) # No borders
lines(x = c(b1limit1, b1, b1, b1limit1),
      y = c(b1lo, b1lo, b1hi, b1hi),
      lwd = 1)
lines(x = c(b1limit1, b1limit2),
      y = c(b1lo, b1lo),
      lwd = 1,
      lty = 2)
lines(x = c(b1limit1, b1limit2),
      y = c(b1hi, b1hi),
      lwd = 1,
      lty = 2)


# B2
polygon(x = c(0, b2, b2, 0),
        y = c(b2lo, b2lo, b2hi, b2hi),
        col = plotColour)

# Text
text(0, (b1lo + b1hi)/2, 
     labels = expression(italic(B)[1]),
     pos = 2)
text(0, (b2lo + b2hi)/2, 
     labels = expression(italic(B)[2]),
     pos = 2)
```





::: {.definition #MutuallyExclusive name="Mutually exclusive"}
Events $A$ and $B$ are *mutually exclusive* if, and only if, $A\cap B = \emptyset$; that is, there are no elements in common.

The term *disjoint* is used for *sets*, whereas *mutually exclusive* is used when referring to *events*.
:::

:::{.example #TwoCoinToss2 name="Tossing a coin twice"}
Consider the simple random process of tossing a coin twice (Example \@ref(exm:TwoCoinToss)), and define these two events:



Event                     | Notation | Set
--------------------------|----------|------------------
'Obtain a Head on Toss 1' | $M$      | $\{(HT), (HH)\}$
'Obtain a Tail on Toss 1' | $N$      | $\{(TT), (TH)\}$

The two sets are *disjoint*, as there are no sample points in common.
The events are therefore *mutually exclusive*.
:::


Set algebra has many rules; we only provide some. 
For sets $A$, $B$ and $C$ defined on the same sample space.

* Commutative: $A\cup B = B \cup A$.
* Associative: $A\cup(B\cup C) = (A\cup B)\cup C$.
* Distributive: $A\cap (B\cup C) = (A\cap B)\cup (A \cap C)$.
* De Morgan's law: $\overline{A \cap B } = \overline{A} \cup \overline{B}$.
* De Morgan's law: $\overline{A \cup B } = \overline{A} \cap \overline{B}$.


:::{.proof}
These may be proved using the rules of probability ([given later](#ProbabilityRules)), or using Venn diagrams.
:::

:::.{.example}
???
:::

## Assigning probabilities for discrete sample spaces {#AssignProbDiscrete}

The chance of an event occurring is formalised by assigning a number, called a *probability*, to an event. 
We denote the probability of an event $E$ occurring as $\text{Pr}(E)$.

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Be aware of variations in notation!

The probability of an event $E$ occurring can be denoted as $\text{P}(E)$, $\text{Pr}(E)$, $\text{Pr}\{E\}$, or other similar notation.
:::


A probability of 0 is assigned to an event that *never* occurs (i.e., corresponds to the empty set), and 1 to an event that is *certain* to occur (i.e., corresponds to the universal set).
This method is appealing as it aligns with the idea of [proportions](#EmpiricalApproach) as numbers between 0 and 1.

Developing a method of assigning sensible probabilities to events is difficult.
Four methods are discussed here.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Sometimes, the chances of an event occurring are expressed as *odds*, which are *not* the same as probabilities.
Odds are the ratio of how often an event is likely to occur, to how often the event is likely to *not occur*.

Using odds, an impossible event is assigned 0, a certain event is assigned $\infty$, and an event that will happen just as often as not happen is assigned 1.

We will only use the system with probabilities between $0$ and $1$ in this book.

Important: 'odds' and 'probability' are not the same.
:::


### Empirical (relative frequency) approach {#EmpiricalApproach}

When the random process is repeated many times, counting the number of times the event of interest occurs means we can compute the *proportion* of times the event occurs.
Mathematically, if the random process is repeated $n$ times, and event $E$ occurs in $m$ of these ($m < n$), then the *probability of the event occurring is
\[
   \Pr(E) = \lim_{n\to\infty} \frac{m}{n}.
\]
In practice, $n$ needs to be very large---and the repititions random---to compute probabilities accurately, and approximate probabilities can only ever be found (since $n$ is finite).

This is the *empirical* (or *relative frequency*) approach to probability.

This method cannot always be used.
For example, suppose a company wishes to determine the probability that matches they produce  will light.
To determine an accurate probability, many matches must be struck, and then can no longer be sold.

Or consider the probability that the airbag in a car will prevent a serious injury to the driver.
It is not ethical or financially viable to crash thousands of vehicles with drivers in them to see how many break bones.
(Fortunately, car manufacturers use dummies to represent people, and crash small numbers of cars to get some indications of the probabilities).
In these situations, sometimes computer simulations can be used to approximate the probabilities.


::: {.example #SalkVaccine name="Salk vaccine"}
In 1954, Jonas Salk developed a vaccine against polio (@book:Williams:BioStats, \S1.1.3).
To test the effectiveness of the vaccine, the data in Table \@ref(tab:Polio) were collected.

The relative frequency approach can be used to estimate the probabilities of developing polio *with* the vaccine and *without* the vaccine (the control group):
\begin{align*}
   \Pr(\text{develop polio in control group}) 
   &= \frac{115}{201\,229} = 0.000571;\\[3pt]
   \Pr(\text{develop polio in vaccinated group}) 
   &= \frac{33}{200\,745} = 0.000164.
\end{align*}
The estimated *probability* of contracting polio in the control group is about 3.5 times greater than in the control group.
The precision of these sample estimates could be quantified by producing a [confidence interval for the proportions](https://bookdown.org/pkaldunn/SRM-Textbook/CIOneProportion.html).
:::


```{r Polio, echo=FALSE}
VaccTable <-  array( dim = c(2, 2))
VaccTable[1, ] <- c("200 745", "33")
VaccTable[2, ] <- c("201 229", "115")

colnames(VaccTable) <- c("Number treated",
                         "Paralytic cases")
rownames(VaccTable) <- c("Vaccinated",
                         "Control")

knitr::kable(VaccTable,
             caption = "The number of paralytic cases for two groups of children: one group of controls and another vaccinated with the Salk polio vaccine")
```




::: {.example #CoinToss name="Simulating a coin toss"}
Repeating random processes large numbers of times can be impractical and tedious.
However, sometimes a computer can be used to *simulate* the random processes.
Consider using a computer to simulate large numbers of coin tosses; here, **R** is used to simulate 500 tosses

Use $\Pr(\text{Toss head}) = 0.5$.
Then, after each toss, the probability of obtaining a head using all the available information was computed at each toss.
For one such simulation, the running probabilities are shown in Fig. \@ref(fig:SimTosses).

While the result of any single toss is unpredictable, we see the general pattern emerging: Heads occur about half the time.
:::

```{r echo=FALSE}
set.seed(966141)                     # For repeatability
```

```{r SimTosses, echo=TRUE, fig.cap = "A simulation of tossing a fair coin $1000$ times. The probability of getting a head is computed from the data after each toss."}
NumTosses <- 500 # Simulated tossing a coin 500 times
Tosses <- sample(x = c("H", "T"),    # Choose "H"  or  "T"
                 size = NumTosses,   # Do this 500 times
                 replace = TRUE)     # H and T can be reselected 
Tosses[1 : 10]                       # Show the first 10 results
TossNumber <- 1:NumTosses            # Sequence: toss number
PropHeads <- cumsum(Tosses == "H") / TossNumber
                                     # P(Heads) after each toss

plot(PropHeads,
     main = "The proportion of heads after so many tosses",
     xlab = "Toss number",          # Label on x-axis
     ylab = "Proportion of heads",  # Label on y-axis
     type = "l",       # Draw a "l"ine rather than "p"oints
     lwd = 2,          # Make axes labels horizontal
     ylim = c(0, 1),   # y-axis limits
     las = 1,          # Make axes labels horizontal
     col = "blue")     # Line colour: blue
abline( h = 0.5,       # Draw horizontal line at y = 0.5
        col = "grey")  # Make line grey in colour
```


Using the empirical approach shows why probabilities are between 0 and 1 (inclusive), since the proportions $m/n$ are always between 0 and 1 (inclusive).


### Classical approach {#ClassicalApproach}

The *classical approach* requires being able to define a sample space containing a set of *equally-likely* outcomes.
In practice, this is only true for trivial random processes, like tossing coins, rolling dice, and dealing cards.
In the classical approach, random process with $n$ *equally-likely* outcomes have all outcomes assigned the probability $1/n$.


For the calculation of probabilities for events in a finite sample space, sometimes sample points can be described so that we have equally-likely outcomes (and hence the classical approach to the assignment of probabilities is appropriate).


:::{.example #TossingDice name="Tossing dice"}
When a standard die is tossed, the sample spaxe comprises six equally-likely outcomes: 
\[
   S = \{ {1},{2},{3},{4},{5},{6}\}.
\]
The probability of rolling an even number can be computed by counting those outcomes in the sample space that are even (i.e., three events), and dividing by the total number of outcome in the sample space (six events).
The probability is $3/6 = 0.5$.
:::


Associating probabilities with events in this situation is essentially counting sample points.
Example \@ref(exm:TossingDice) is a simple demonstration of the principle which we now formalise.


:::{.theorem #EquallyLikely name="Equally-likely events"}
Suppose that a sample space $S$ consists of $k$ equally likely elementary events $E_1$, $E_2$, $\ldots$, $E_k$, and $A = \{ E_1, E_2, \ldots, E_r\}$ where $(r\leq k)$.
Then

\[
   \Pr(A) = \frac{r}{k}.
\]
:::

This method of calculating the probability of an event is sometimes called the *sample-point method*.
Take care: errors are frequently made by failing to list all the sample points in $S$.

Methods of counting the points in a sample space are discussed in Section \@ref(Counting).


::: {.example #Lotto name="Lotto"}
In a game of Oz Lotto, [seven numbered balls are drawn from balls numbered 1 to 47](https://www.thelott.com/oz-lotto/how-to-play).
The goal is to correctly pick the seven numbers that will be drawn (without replacing the balls) at random.

There is no reason to suspect that any one number should be more or less likely to occur than any other number.
Any set of seven numbers is just a likely to occur as any other set of seven numbers.
That is,
\[
   \{2, 3, 4, 5, 6, 7, 8\}
\]
is just as likely to be the chosen seven winning numbers as 
\[
   \{4, 15, 23, 30, 33, 39, 45 \}.
\]

Listing the sample space is difficult as there are [a very large number of options](#exm:CombinationOzLotto) for selecting seven numbers from 47.
:::




### Subjective approach {#SubjectiveApproach}

'Subjective' probabilities are estimated after identifying the information that may influence the probability, and then evaluating and combining this information. 
You use this method when someone asks you about your team's chance of winning on the weekend.

The final (subjective) probability may, for example, be computed using mathematical models that use the information.
When different people or systems identify different information as relevant, and combine them differently, different subjective probabilities eventuate.

Some examples include:

* What is the chance that an investment will return a positive yield next year?
* How likely is it that Auckland will have above average rainfall next year?



```{r echo=FALSE}
# http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_nccObsCode=139&p_display_type=dataFile&p_startYear=&p_c=&p_stn_num=044021
CR <- read.csv("./Data/IDCJAC0001_044021/IDCJAC0001_044021_Data12.csv")

numAprils <- length(CR$Apr)
numZeros <- sum(CR$Apr == 0)
probZero <- numZeros/numAprils
probRain <- 1 - probZero

minYear <- min(CR$Year)
maxYear <- max(CR$Year)
numYears <- maxYear - minYear + 1
```

::: {.example #ChanceRain name="Subjective probability"}
What is the likelihood of rain in Charleville (a town in Queensland) during April?
Many farmers could give a subjective estimate of the probability based on their experience and the conditions.

Using the classical approach to determine the probability is not possible.
While two outcomes are possible---it *will* rain, or it *will not* rain---these are almost certainly not *equally likely*.

A relative frequency approach can be adopted.
Data from the [Bureau of Meterology](http://www.bom.gov.au), from `r minYear` to `r maxYear` (`r numYears` years), shows rain fell in `r numAprils - numZeros` years during April.
An *approximation* to the probability is therefore $`r numAprils - numZeros` / `r numAprils` = `r round(probRain, 3)`$, or $`r round((probRain) * 100, 1)`$\%.
:::


### Axiomatic approach {#AxiomaticApproach}

An **axiom** is a self-evident truth that does not require proof, or cannot be proven.
Perhaps surprisingly, only three axioms of probability are needed, from which all other results in probability can be proven.


:::{.definition #ThreeAxioms name="Three axioms of probability"}
Consider a sample space $S$ for a random process.
For every event $A$ (a subset of $S$), a number $\Pr(A)$ can be assigned which is called the *probability* of event $A$.

The three axioms of probability are:

1. Non-negativity: $\Pr(A) \ge 0$.
2. Exhaustive: $\Pr(S) = 1$.
3. Additivity: If $A_1$, $A_2$, $\dots$ form a sequence of pairwise mutually exclusive events in $S$, then
   \[
      \Pr(A_1 \cup A_2 \cup A_3 \cup \dots) = \sum_{i = 1}^\infty \Pr(A_i).
   \]
:::

In simple terms, these three axioms state:

1. Probabilities are never negative.
2. The probability that *something* in the sample space will occur is one.
   (Recall that the sample space lists *every* possible outcome.)
3.  For [*mutually exclusive* events](#def:MutuallyExclusive), the probability of the *union* of events is the sum of the individual probabilities.


While this approach can sometimes help to assign probabilities, its main purpose is to formally define the rules that apply to probabilities.
These axioms of probability can be used to develop all other probability formulae.


::: {.example #UsingAxions name="Using the axioms"}
Consider proving that $\Pr(\emptyset) = 0$.
While this may appear 'obvious', it is not one of the three axioms.

By definition, the empty set $\emptyset$ contain no points; hence $\emptyset \cup A = A$ for any event $A$.
 
Also, $\emptyset\cap A = \emptyset$, as $\emptyset$ and $A$ are [mutually exclusive](#def:MutuallyExclusive) (that is, they have no elements in common).
Hence, by the [third axiom](#def:ThreeAxioms)
\begin{equation}
   \Pr(\emptyset\cup A) = \Pr(\emptyset) + \Pr(A)
   (\#eq:ByThirdAxiom)
\end{equation}
But since $\emptyset \cup A = A$, then $\Pr(\emptyset \cup A) = \Pr(A)$, and so $\Pr(A) = \Pr(\emptyset) + \Pr(A)$ from \@ref(eq:ByThirdAxiom).
Hence $\Pr(\emptyset) = 0$.
:::

While this result may have seemed obvious, *all* probability formulae can be developed just from assuming the three axioms of probability.




## Assigning probabilities for continuous sample spaces {#AssignProbContinuous}

Continuous sample spaces do not have distinct outcomes to which probabilities can be assigned.
Instead, probabilities are assigned to *intervals* of the sample space, and these probabilities are described using a real-valued  *probability function*, say $f(x)$.

In the discrete case, the probability of observing an element of the sample space must *sum* to one; for a continuous sample space, the equivalent statement involves integration rather than summations.

Since the three [axioms of probability](#AxiomaticApproach) still apply, we have:

* integration over any region of the sample space must never produce a negative value: $f_X(x) \ge 0$ for *all* values of $x$.
* Over the whole sample space, the probability function must integrate to one:
  \[
     \int_S f(x)\,dx = 1.
  \]
* The probability of the union of any non-overlapping regions is the sum of the individual regions.

Using these axioms implies that we can describe a probability function for some event $A$ defined on the continuous sample space $S$ as
\[
   \Pr(X\in A) = \int_{A(x)} f_X(x)\, dx.
\]

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The probability function $f_X(x)$ does **not** give the probability of observing the value $X = x$.
Because the sample space is continuous, the probability of observing any single point is zero.
Instead, probabilities are computed for *intervals*

This implies that $f_X(x) > 1$ may be true for some values of $x$.
:::


:::{.example #ContinuousProbs name="Assigning probabilities"}
Suppose I throw a cricket ball 100 times, and record the distance thrown.
About 10% of the time, the distance is between 50m and 60m; 20% of the time further than 40m; 50% of the time further than 30m; and 100% of the time further than 20m.

With this information we have some idea of the probabilities that my throw goes for certain ranges of distance (Fig. \@ref(fig:BallThrow), left panel)).

For these areas to represent probabilities, though, the *total* area must sum to one.
Each rectangle has a width of 10m, and we can define the vertical-axis steps as shown as a distance of $k$ apart.

The area of each rectangle is easily found, and must sum to one; hence:
\[
  (10\times 5k) + (10\times 3k) + (10\times k) + (10\times k) = 1,
\]
so that $k = 1/100$.
With this information, we can create a rough (and coarse) probability model (Fig. \@ref(fig:BallThrow), right panel).
:::

```{r BallThrow, echo=FALSE, fig.align="center", fig.cap="A rough probability model for throwing distance"}
par( mfrow = c(1, 2))

Heights <- c(0, 0, 50, 30, 10, 10)

barplot(height = Heights,
        width = 10,
        space = 0,
        xlab = "Throwing distance (in m)",
        main = "Throwing distance regions",
        col = plotColour,
        axes = FALSE)
axis(side = 1,
     at = seq(0, 60,
              by = 10) )
axis(side = 2,
     las = 1,
     at = seq(0, 50,
              by = 10),
     labels = c("0", 
                expression(italic(k)),
                expression(2*italic(k)),
                expression(3*italic(k)),
                expression(4~italic(k)),
                expression(5~italic(k)) ) )
text(25, 20,
     cex = 0.8,
     labels = "50%")
text(35, 20,
     cex = 0.8,
     labels = "30%")
text(45, 5,
     cex = 0.8,
     labels = "10%")
text(55, 5,
     cex = 0.8,
     labels = "10%")


barplot(height = Heights,
        width = 10,
        space = 0,
        xlab = "Throwing distance (in m)",
        main = "Throwing distance regions:\n rough probability model",
        col = plotColour,
        axes = FALSE)
axis(side = 1,
     at = seq(0, 60,
              by = 10) )
axis(side = 2,
     las = 1,
     at = seq(0, 50,
              by = 10),
     labels = c("0", 
                "1/100",
                "2/100",
                "3/100",
                "4/100",
                "5/100") )

```





## Rules of probability {#ProbabilityRules}

Many useful results can be deduced from the [three axioms](#defThreeAxioms).
They allow probabilities to be computed in more complicated situations.

::: {.theorem #CompRule name="Complementary rule of probability"}
For any event $A$, the probability of 'not $A$' is

\[
   \Pr(\overline{A}) = 1 - \Pr(A).
\]
:::

:::{.proof}
By the definition of the [*complement* of an event](#IntersectionUnionSubset), $\overline{A}$ and $A$ are mutually exclusive.
Hence, by the [third axiom](#defThreeAxioms), $\Pr(\overline{A} \cup A) = \Pr(\overline{A}) + \Pr(A)$.

As $\overline{A}\cup A = S$ (by definition of the complement) and $\Pr(S) = 1$ (axiom 2), then $1 = \Pr(\overline{A}) + \Pr(A)$, and the result follows.
:::




:::{.theorem #ProbAddition name="Addition rule of probability"}
For *any* two events $A$ and $B$, the probability of either $A$ **or** $B$ occurring is 
\[
   \Pr(A\cup B) = \Pr(A) + \Pr(B) - \Pr(A\cap B).
\]
:::

:::{.proof}
See Exercise ???
:::


If the two events are [*mutually exclusive*](#MutuallyExclusive), we have a corollary of Theorem \@ref(thm:ProbAddition).

:::{.corollary #ProbAddition}
If the two events $A$ and $B$ are *mutually exclusive*, then the probability of either $A$ **or** $B$ is

\[
   \Pr(A\cup B) = \Pr(A) + \Pr(B).
\]
:::

:::{.proof}
See Exercise ???
:::


Some other important results that follow from the axioms are the following.

* $0 \leq \Pr(A) \leq 1$.
* For events $A$ and $B$, $\Pr(A\cup B) \leq \Pr(A) + \Pr(B)$.
* For events $A$ and $B$, if $A\subseteq B$ then $\Pr(B\cap \overline{A}) = \Pr(B) - \Pr(A)$.
* For events $A$ and $B$, if $A\subseteq B$ then $\Pr(A) \leq \Pr(B)$.

:::{.proof}
See Exercises ???
:::


:::{.example}
???
:::



## Conditional probability and independence {#CondProbIndependence}

### Conditional probability {#CondProb}

Assume that a sample space $S$ for the [random process](#RandomProcess) has been constructed, an event $A$ has been identified, and its probability, $\Pr(A)$, has been determined.
We then receive additional information that some event $B$ has occurred.
Possibly, this new information can change the value of $\Pr(A)$.


We now need to determine the probability that $A$ will occur, given that we know the information in event $B$.
We call this probability the *conditional probability of $A$ given $B$*, and denote it by $\Pr(A \mid B)$.


:::{.example #ConditionalPrinIntro name="Conditional probability"}
Suppose I roll a die.
Define event $A$ as 'rolling a 6'.
Then, you would compute $\Pr(A) = 1/6$ (using the [classical approach](#ClassicalApproach)).

However, suppose I provide you with extra information:
I tell you that event $B$ has already occurred, where $B$ is the event 'the number rolled is even'.

With this extra information, you know only three numbers could possibly have been rolled; the *reduced sample space* is now
\[
   S^*= \{2, 4, 6 \}.
\]
All of these outcomes are equally likely.
However, the probability that the number is a six is now $\Pr(A\mid B) = 1/3$.

Knowing the extra information in event $B$ has changed the calculation of $\Pr(A)$.
:::




::: {.example #Planes name="Planes"}
USE REAL DATA??

Define these two events:
\begin{align*}
   D:&\quad \text{A person dies};\\
   F:&\quad \text{A person falls from an airborne plane with no parachute}.
\end{align*}

Consider the difference between two probabilities $\Pr(D \mid F)$ and $\Pr(F\mid D)$.

Consider the first.
If you are told that someone falls out of an airborne plane with no parachute, the probability that they die is very high.

Consider the second.
If you are told that some has died, it is very unlikely the the cause is a fall from an airborne plane.

Thus, the first probability is very close to one, and the second is very close to zero.
:::


Two methods exist for computing conditional probability: first principles, or a formal definition of $\Pr(A \mid B)$.

For the first, we simply consider the original sample space $S$, remove the sample points inconsistent with the new information that $B$ has occurred, form a new sample space, say $S^*$, and recompute the probability of event $A$ relative to $S^*$.

$S^*$ is called the *reduced sample space*.

This method is appropriate when the number of outcomes is relatively small.
The following definition applies more generally.

::: {.definition #ConditionalProb name="Conditional probability"}
Let $A$ and $B$ be events in $S$ with $\Pr(B) > 0$. 
Then
\[
   \Pr(A \mid B) = \frac{\Pr(A\cap B)}{\Pr(B)}
\]
:::
The definition automatically takes care of the sample space reduction noted earlier.


```{r echo=FALSE}
#https://data.longpaddock.qld.gov.au/SeasonalClimateOutlook/SouthernOscillationIndex/SOIDataFiles/MonthlySOIPhase1887-1989Base.txt

SOIPhases <- read.table("./Data/MonthlySOIPhase1887-1989Base.txt",
                        header = TRUE)
SOIPhasesApril <- subset(SOIPhases,
                         Month == 4)
CRApril <- data.frame(Year = CR$Year,
                      Apr = CR$Apr)
ChApril <- merge(CRApril, SOIPhasesApril, "Year")

ChAprilTable <- xtabs( ~ (Apr > 0) + Phase, 
                       data = ChApril)

rownames(ChAprilTable) <- c("No rain",
                            "Rain")
colnames(ChAprilTable) <- c("Phase 1",
                            "Phase 2",
                            "Phase 3",
                            "Phase 4",
                            "Phase 5")
```

```{r echo=FALSE}
L <- sum(ChApril$Apr > 30)
R <- sum(ChApril$Apr > 0) 
Number <- length(ChApril$Apr)

Prob30 <- L / Number
Prob0 <- R / Number

CProb30 <- Prob30 / Prob0
```

::: {.example #Rainfall name="Rainfall"}
Consider again the rainfall at Charlevill in April (Example \@ref(exm:ChanceRain)).

Define $L$ as the event 'receiving *more than* 30mm in April', and $R$ as the event 'receiving *any* rainfall in April'.
Event $L$ occurs `r L` times in the `r numYears` years of data, while event $R$ occurs `r R` times.

Then, using the relative frequency approach with the [BoM](http://www.bom.gov.au) data, the probability of obtaining *more than* 30mm in April is
\[
   \Pr(L) = \frac{`r L`}{`r Number`} = `r round(Prob30, 3)`. 
\]
We could also consider the *conditional probability* of receiving more than 30mm, *given* that some rainfall was recorded.
That is:
\[
   \Pr(L \mid  R) = \frac{\Pr(L \cap R)}{\Pr(R)} = \frac{\Pr(L)}{\Pr(R)} = \frac{`r round(Prob30, 4)`}{`r round(Prob0, 4)`} = `r round(CProb30, 3)`.  
\]
If we know rain has been received, the probability that the amount was greater than 30mm is `r round(CProb30, 3)`.
Without this prior knowledge, the probability is `r round(Prob30, 3)`.
:::




:::{.example #MumpsIndependence name="Conditional probability"}
@data:Soud2009:Mumps discusses the response of students to a mumps outbreaks in Kansas in 2006.
Students were asked to isolate; Table \@ref(tab:MumpsIsolation) shows the behaviour of male and female student in the studied sample.

For females, the probability of complying with the isolation request is:
\[
   \Pr(\text{Compiled} \mid  \text{Females}) = 63/84 = 0.75.
\]

For males, the probability of complying with the isolation request is
\[
   \Pr(\text{Compiled} \mid  \text{Males}) = 36/48 = 0.75.
\]

Whether we look at only females or only males, the probability of selecting a student in the sample that complied with the isolation request is the same: 0.75.

Also, the *non-conditional* probability that a student isolated (ignoring their sex) is:
\[
   \Pr(\text{Student isolated}) = \frac{99}{132} = 0.75.
\]
:::


```{r MumpsIsolation, echo=FALSE}
MumpsTable <- array( dim = c(2, 3))

MumpsTable[1, ] <- c(63, 21, 63 + 21)
MumpsTable[2, ] <- c(36, 12, 36 + 12)

rownames(MumpsTable) <- c("Females",
                          "Males")
colnames(MumpsTable) <- c("Complied with isolation",
                          "Did not comply with isolation",
                          "TOTAL")

knitr::kable(MumpsTable,
             caption = "Students response to isolation request at a Kansas university") 
```

### Multiplication rule

As a consequence of Definition \@ref(def:ConditionalProb), we have the following theorem.

:::{.theorem #MultRule name="Multiplication rule for probabilities"}
For any events $A$ and $B$, the probability of $A$ and $B$ is
\begin{align*}
     \Pr(A\cap B)
     &= \Pr(A) \Pr(B \mid A)\\
     &= \Pr(B) \Pr(A \mid B).
\end{align*}
:::

This rule can be generalised to any number of events.
For example, for three events $A, B, C$,
\begin{equation}
  \Pr(A\cap B\cap C) = \Pr(A)\Pr(B\mid A)\Pr(C\mid A\cap B).
\end{equation}



### Independent events {#Independence}

The important idea of *independence* can now be defined.

::: {.definition #Independence name="Independence"}
Two events $A$ and $B$ are *independent* if
\[
  \Pr(A\cap B) = \Pr(A)\Pr(B).
\]
Otherwise the events *dependent* (or *not independent*).
:::


:::{.proof}
???
:::



Provided $\Pr(B) > 0$, Definitions \@ref(def:ConditionalProb) and \@ref(def:Independence) show that $A$ and $B$ are independent if, and only if, $\Pr(A \mid B) = \Pr(A)$.

This statement of independence is sensible in that $\Pr(A \mid B)$ is the probability of $A$ occurring if $B$ has already occurred, while $\Pr(A)$ is the probability of $A$ occurring without any knowledge of whether $B$ has occurred or not. 
If these are equal, then the fact that $B$ has occurred has made no difference to the probability that $A$ has occurred, which is precisely what is meant by *independence*.



:::{.example}
In Example \@ref(exm:MumpsIndependence), the probability of males isolating was the *same* as the probability of females isolating.

The sex of the student is *independent* of whether they isolate.
That is, whether we look at females or males, the probability that they isolated is the same.
:::


The idea of independence can be generalised to more than two events.
For three events, the following definition of *mutual independence* applies, which naturally extends to any number of events.

::: {.definition #MutualIndependence name="Mutual independence"}
Three events $A$, $B$ and $C$ are *mutually independent* if, and only if,
\begin{align*}
     \Pr(A\cap B) & = \Pr(A)\Pr(B).\\
     \Pr(A\cap C) & = \Pr(A)\Pr(C).\\
     \Pr(B\cap C) & = \Pr(B)\Pr(C).\\
     \Pr(A\cap B\cap C) & = \Pr(A) \Pr(B) \Pr(C).
     \end{align*}
:::
Three events can be *pairwise* independent in the sense of Definition  \@ref(def:Independence), but not be *mutually independent*.

The following theorem concerning independent events is sometimes useful.

:::{.theorem #Independence name="Independent events"}
If $A$ and $B$ are independent events, then

* $A$ and $\overline{B}$ are independent.
* $\overline{A}$ and $B$ are independent.
* $\overline{A}$ and $\overline{B}$ are independent.
:::

:::{.proof}
Exercise.
:::


### Independence and mutually exclusive events

[Mutually exclusive](def:MutuallyExclusive) and [independent](def:Independence) events sometimes get confused.

The simple events defined by the outcomes in a sample space are mutually exclusive, since only one can occur in any realisation of the random process.
Mutually exclusive events have no common outcomes: for example, achieving both an A grade and a C grade for this course is not possible.
Obtaining one excludes the possibility of the other... so *whether one occurs depends on whether the other has occurred*.

In contrast, if two events are *independent*, then whether or not one occurs does not affect the chance of the other happening.
If event $A$ can occur, then $B$ happening will not influence the chance of $A$ happening if they are independent, so *it certainly does not exclude the possibility of the other occurring*.


::: {.example #Independence name="Independence"}
Independent events refer to events that have no impact on each other.

For example, *how* I get to work tomorrow (walk or ride my bicycle) does not change whether or not I have a busy day at work.
They are independent.
:::


Confusion between mutual exclusiveness and independence arises sometimes because the sample space is not clearly identified.

Consider a random process involving tossing two coins *at the same time*.
The sample space is 
\[
   S_2 = \{(HH), (HT), (TH), (TT)\}
\]
and these outcomes are mutually exclusive, each with probability 1/4 (using the classical approach).
For example, $\Pr\big( (HH) \big) = 1/4$.

An alternative view of this random process is to think of *repeating the process of tossing a coin once*.
For one toss of a coin, the sample space 
\[
   S_1 = \{HT\}
\]
and $\Pr(H) = 1/2$ is the probability of getting a head on the *first* toss.
This is also the probability of getting a head on the *second* toss.

The events 'getting a head on the first toss' and 'getting a head on the second toss' are **not mutually exclusive**, because both events can occur together: the event $(HH)$ is an outcome in $S_2$.
Whether or not the outcomes $(HH)$ occurred *simultaneously*, because the two coins were tossed at the one time, or *sequentially*, in that one coin was tossed twice, is irrelevant.

Our interest is in the *joint* outcomes from two tosses.
The event 'getting a head on the "first" toss' is:
\[
   E_1 = \{ (HH), (HT) \}
\]
and 'getting a head on the "second" toss' is
\[
   E_2 = \{ (HH), (TH) \},
\]
where $E_1$ and $E_2$ are events defined on $S_2$.
This makes it clear that $E_1$ and $E_2$ are not mutually exclusive because $E_1\cap E_2 \ne \emptyset$.

The two events $E_1$ and $E_2$ are *independent* because,  whether or not a head occurs on one of the tosses, the probability of a head occurring on the other is still $1/2$... otherwise coins must have memories or can communicate...

Seeing that the events are independent provides another way of calculating the probability of the two heads occurring 'together': $1/2\times 1/2 = 1/4$, since the probabilities of *independent* events can be multiplied


::: {.example #Mendell name="Mendell"}
@BIB:Mendel:hybrids conducted famous experiments in genetics.

In one study, Mendel crossed a pure line of round yellow peas with a pure line of wrinkled green peas.
Table \@ref(tab:PeaTable) shows what happened in the *second* generation.
For example, $\Pr(\text{round peas}) = 0.7608$.
Biologically, we would expect about $75$\% to be round; the data appear reasonably sound in this respect.

```{r PeaTable, echo=FALSE}
PeaTable <- array(dim = c(2, 2) )

colnames(PeaTable) <- c("Yellow", 
                        "Green")
rownames(PeaTable) <- c("Rounded", 
                        "Wrinkled")

PeaTable[1, ] <- c(0.5665,
                   0.1942)
PeaTable[2, ] <- c(0.1817,
                   0.0576)
                   
knitr::kable(PeaTable,
             caption = "The second generation results from Mendel's experiment, crossing a pure line of round yellow peas with a pure line of wrinkled green peas")

```

Is the type of pea (round or wrinkled) independent of the colour?
That is, if the pea is round, does it have any effect in the colour of the pea?

To test independence, one form of the formula is $\Pr(\text{round} \mid \text{yellow}) = \Pr(\text{round})$.
In other words, the fact that the pea is yellow does not affect that probability that the pea is round.
From Table \@ref(tab:PeaTable):

\begin{align*}
   \Pr(\text{round}) 
   &= 0.7608,\\
   \Pr(\text{round} \mid \text{yellow}) 
   &= 0.5665/0.7482 = 0.757.
\end{align*}

These two probabilities are very close.
Given that the data in the Table is only a *sample* (from the population of all peas), it seems reasonable that the colour and shape of the peas are independent.
:::


### Partitioning the sample space {#SSPartitions}

The concepts introduced in this section allow us to determine the probability of an event using the *event-decomposition approach*, which we now discuss.


::: {.definition #Partitioning name="Partitioning"}
The events $B_1, B_2, \ldots , B_k$ are said to represent a *partition* of the sample space $S$ if

1. They are *mutually exclusive*: $B_i \cap B_j = \emptyset$ for all $i \neq j$.
2. The events are *exhaustive*: $B_1 \cup B_2 \cup \ldots \cup B_k = S$.
3. The events have a non-zero probability of occurring: $\Pr(B_i) > 0$ for all $i$.
:::


The implication is that when the random process is performed, one and only one of the events $B_i$ ($i = 1, \ldots, k)$ occurs.

We use this concept in the following theorem.

:::{.theorem #TotalProb name="Theorem of total probability"}
Let $A$ be an event in $S$ and $\{B_1, B_2, \ldots , B_k\}$ a partition of $S$.
Then
\begin{align*}
   \Pr(A) 
   &= \Pr(A \mid B_1) \Pr(B_1) + \Pr(A \mid B_2)\Pr(B_2) + \ldots \\
   & \qquad {} + \Pr(A \mid B_k)\Pr(B_k).
\end{align*}
:::

:::{.proof}
The proof follows from writing $A = (A\cap B_1) \cup (A\cap B_2) \cup \ldots \cup (A\cap B_k)$, where the events on the RHS are mutually exclusive.
The [third axiom](#def:ThreeAxioms) of probability together with the multiplication rule yield the result.
:::


:::{.example}
Consider the event 'rolling an even number on a die'.
We could also define the events
\[
   B_i:\quad\text{The number $i$ is rolled on a die}
\]
where $i = 1, 2, \dots 6$.
The events $B_i$ represent a [*partition*](#Partitioning) of the sample space.

Then, using the [*Theorem of total probability*](#TotalProb):
\begin{align*}
   \Pr(A)
   &= \Pr(A \mid B_1)\times \Pr(B_1)\quad +  \quad\Pr(A \mid B_2)\times \Pr(B_2) \quad+ {}\\
   &\quad \Pr(A \mid B_3)\times \Pr(B_3)\quad + \quad\Pr(A\mid B_4)\times \Pr(B_4) \quad+ {} \\
   &\quad \Pr(A \mid B_5)\times \Pr(B_5)\quad +  \quad\Pr(A\mid B_6)\times \Pr(B_6)\\
   &= \left(0\times \frac{1}{6}\right) + \left(1\times \frac{1}{6}\right) + {} \\
   &\quad \left(0\times \frac{1}{6}\right) + \left(1\times \frac{1}{6}\right) + {}\\
   &\quad \left(0\times \frac{1}{6}\right) + \left(1\times \frac{1}{6}\right) 
    = \frac{1}{2}.
\end{align*}
This the same answer we would obtain using the classical approach.
:::


### Bayes' theorem {#BayesTheorem}

If an event is known to have occurred (i.e., non-zero probability), and the sample space is partitioned, a result known as *Bayes' theorem* enables us to determine the probabilities associated with each of the partitioned events.


:::{.theorem #Bayes name="Bayes' theorem"}
Let $A$ be an event in $S$ such that $\Pr(A) > 0$ and $\{ B_1, B_2, \ldots , B_k\}$, a [partition](#Partitioning) of $S$.
Then
\[
   \Pr(B_i \mid A) = \frac{\Pr(B_i) \Pr(A \mid B_i)}
                          {\displaystyle \sum_{j = 1}^k \Pr(B_j)\Pr(A \mid B_j)}
\]
for $i = 1, 2, \dots, k$.
:::

:::{.proof}
This is a direct application of Definition \@ref(def:ConditionalProb), the multiplication rule and Theorem \@ref(thm:TotalProb).
:::

Notice that the right-hand side includes conditional probabilities of the form $\Pr(A\mid B_i)$, while the left-hand side contains the probability $\Pr(B_i\mid A)$.
In effect, the theorem takes a conditional probability and can 'reverse' the conditioning.

Bayes' theorem has many uses, as it uses conditional probabilities that are easy to find or estimate (such as $\Pr(A \mid B_j$), to compute a probability that is *not* easy to find or estimate (such as $\Pr(B_i \mid A)$).

The theorem is the basis of a branch of statistics known as *Bayesian statistics* which involves using pre-existing evidence in drawing conclusions from data.


::: {.example #BreastCancer name="Breast cancer"}
The success of mammograms for detecting breast cancer has been well documented. 
Mammograms are generally conducted on women over 40, though breast cancer is not unknown in women under 40. 

We can define two events of interest:
\begin{align*}
   C:&\quad \text{The woman actually has breast cancer; and}\\
   D:&\quad \text{The mammogram returns a positive test (breast cancer detected).}
\end{align*}
As with any diagnostic tool, a mammogram is not perfect.
*Sensitivity* and *specificity* are used to describe the accuracy of a test:

* *Sensitivity* is the probability of a *true* positive test result: the probability of a positive test result for people *with* the disease.
  This is $\Pr(D \mid C)$.
* *Specificity* is the probability of a *true* negative test result: the probability of a negative test for people *without* the disease.
  This is $\Pr(\overline{D} \mid \overline{C})$.

Clearly, we would like both these probabilities to be a high as possible.
For mammograms [@houssami2003sydney], the *sensitivity* is estimated as about 0.75 and the *specificity* as about 0.90.
We can write:

* $\Pr(D \mid C ) = 0.75$ (and so $\Pr(\overline{D} \mid C) = 0.25$);
* $\Pr(\overline{D} \mid \overline{C}) = 0.90$ (and so $\Pr(D \mid \overline{C}) = 0.10$).

Furthermore, about 2% of women under 40 will get breast cancer [@houssami2003sydney]; that is, $\Pr(C) = 0.02$ (and hence $\Pr(\overline{C}) = 0.98$).

For this study, the probabilities $\Pr(D\mid C)$ are easy to find: women who are *known* to have breast cancer have a mammogram, and we record whether the result is positive or negative.

But consider a women under 40 who gets a mammogram.
When the results are returned, her interest is whether they have breast cancer, *given* the test results; for example $\Pr(C \mid D)$.
In other words: If the test returns a positive result, what is the probability that she actually has breast cancer?

That is, we would like to take probabilities like $\Pr(D\mid C)$, that can be found readily, and determine $\Pr(C \mid  D)$, which is of interest in practice.

Using [Bayes' Theorem](#Bayes):
\begin{align*}
   \Pr(C \mid D) 
   &= \frac{\Pr(C) \times \Pr(D \mid  C)}
            {\Pr(C)\times \Pr(D \mid  C) + \Pr(\overline{C})\times \Pr(D \mid  \overline{C}) }\\
   &= \frac{0.02 \times 0.75}
            {(0.02\times 0.75) + (0.98\times 0.10)}\\
   &= \frac{0.015}{0.15 + 0.098} =  0.0604.         
\end{align*}
Consider what this says: Given that a mammogram returns a *positive test*, the probability that the woman really has breast cancer is only about 6%...

This partly explains why mammograms for women under 40 are not commonplace: most women who return a positive test results actually do not have breast cancer.

The reason for this surprising result is explained in Example \@ref(exm:BreastCancerTree).
:::





## Computing probabilities for discrete sample spaces {#ComputingProbs}

Different schemes can be used to help compute probabilities, such as tree diagrams, tables and Venn diagrams.
Typically, multiple methods may be applied to a given situation, but one method is often easier to apply.


### Tree diagrams

Tree diagrams are useful when a [random process](#RandomProcess) can be seen, or thought of, as occurring in steps or stages.
The branches in the 'second stage' are *conditional probabilities*, conditional of the branch on the first step. 


:::{.example #BreastCancerTree name="Breast cancer"}
Consider using a tree diagram to describe the breast cancer information from Example \@ref(exm:BreastCancer) (Fig. \@ref(fig:BreastTree)).
By following each 'branch' of the tree, we can compute, for example:
\[
   \Pr(C \cap D) = \Pr(C)\times \Pr(D\mid C) = 0.02 \times 0.75 = 0.015;
\]
that is, the probability that a woman has a positive test **and** breast cancer is about 0.015.
But compare:
\[
   \Pr(\overline{C} \cap D) = \Pr(\overline{C})\times \Pr(D\mid \overline{C}) = 0.98 \times 0.10 = 0.098;
\]
that is, the probability that a woman has a positive test **and no** breast cancer (that is, a *false* positive) is about 0.098.

This explains the surprisingly result in Example \@ref(exm:BreastCancer): Because breast cancer is so uncommon in younger women, the *false* positives (0.098) overwhelm the *true* positives (0.015).
:::


```{r BreastTree, echo=FALSE, fig.align="center", fig.cap="Tree diagram for the breast-cancer example"}

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      main = "Tree diagram for the breast cancer example",
      xlab = "",
      ylab = "",
      axes = FALSE)
#STEP 1
lines( x = c(0.2, 0.40),
       y = c(0.5, 0.75),
       lwd = 2)
lines( x = c(0.2, 0.40),
       y = c(0.5, 0.25),
       lwd = 2)
# STEP 2
lines( x = c(0.60, 0.80),
       y = c(0.75, 0.90),
       lwd = 2)
lines( x = c(0.60, 0.80),
       y = c(0.75, 0.60),
       lwd = 2)

lines( x = c(0.60, 0.80),
       y = c(0.25, 0.40),
       lwd = 2)
lines( x = c(0.60, 0.80),
       y = c(0.25, 0.10),
       lwd = 2)

# TEXT
text(x = 0.50,
     y = 0.75,
     labels = expression("Cancer,"~italic(C)))
text(x = 0.50,
     y = 0.25,
     labels = expression("Cancer,"~bar(italic(C))) )

text(x = 0.90,
     y = 0.90,
     labels = expression("+ve test,"~italic(D)) )
text(x = 0.90,
     y = 0.60,
     labels = expression("-ve test,"~bar(italic(D))) )

text(x = 0.90,
     y = 0.40,
     labels = expression("+ve test,"~italic(D)) )
text(x = 0.90,
     y = 0.10,
     labels = expression("-ve test,"~bar(italic(D))) )

# ADD PROBS
text(x = 0.38,
     y = 0.63,
     cex = 0.9,
     labels = "0.02")
text(x = 0.38,
     y = 0.37,
     cex = 0.9,
     labels = "0.98")

text(x = 0.65,
     y = 0.84,
     cex = 0.9,
     labels = "0.75")
text(x = 0.65,
     y = 0.66,
     cex = 0.9,
     labels = "0.25")

text(x = 0.65,
     y = 0.34,
     cex = 0.9,
     labels = "0.10")
text(x = 0.65,
     y = 0.16,
     cex = 0.9,
     labels = "0.90")

## STEPS
text(x = 0.50,
     y = 0.01,
     label = expression(bold("Step 1"))
     )
text(x = 0.90,
     y = 0.01,
     label = expression(bold("Step 2"))
     )
```






### Tables

With two variables of interest, tables may be a convenient way of summarizing the information.
Although tables can be used to represent random processes using conditional probabilities, it is usual to use the table to represent the whole sample space.


:::{.example #BreastCancer2 name="Breast cancer"}
The breast-cancer data in Example \@ref(exm:BreastCancer) can also be compiled into a table giving the four outcomes in the sample space (Table \@ref(tab:BreastTable)).
:::

```{r BreastTable, echo=FALSE}
BreastTable <- array(dim = c(2, 3))

colnames(BreastTable) <- c("+ive test",
                           "-ive test",
                           "Total")
rownames(BreastTable) <- c("Has breast cancer",
                           "Does not have breast cancer")
BreastTable[1, ] <- c("0.75 x 0.02 = 0.015",
                      "0.25 x 0.02 = 0.005",
                      "0.02")
BreastTable[2, ] <- c("0.10 x 0.98 = 0.098",
                      "0.90 x 0.98 = 0.882",
                      0.98)
knitr::kable(BreastTable,
             escape = FALSE,
             caption = "The probabilities from the breast cancer example")
```




### Venn diagrams

Venn diagrams can be useful when there are two events, sometimes three, but become unworkable for more than three.
Often, tables can be used to better represent situations that have been shown in Venn diagrams.




::: {.example #BreastCancerVenn name="Breast cancer"}
Consider again the breast cancer data (Example \@ref(exm:BreastCancer)).

The events $C$ and $D$ were defined [earlier](#exm:BreastCancer)).
A Venn diagram could be constructed to show the sample space (Fig. \@ref(fig:BreastVenn)).
:::

```{r BreastVenn, echo=FALSE, fig.height=7, out.width = '95%', fig.align="center", fig.cap="The Venn diagram for the breast cancer example"}
par( mfrow = c(2, 2))
colourCancer <- rgb(0, 0, 255, 
                    max = 255,
                    alpha = 125)
colourPos  <- rgb(0, 255, 0, 
                  max = 255, 
                  alpha = 125)

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(C), " and ", bar(italic(C)))),
      axes = FALSE)

polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourCancer)
text(x = 0.4,
     y = 0.5,
     labels = expression(paste(italic(C), ": 0.02")))
text(x = 0.8,
     y = 0.5,
     labels = expression(paste(bar(italic(C)), ": 0.98")))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


###############


plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(D), " and ", bar(italic(D)))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))

plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourPos)

text(x = 0.6,
     y = 0.5,
     labels = expression(paste(italic(D), ": 0.113")))
text(x = 0.2,
     y = 0.5,
     labels = expression(paste( bar(italic(D)), ": 0.887")))

mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


####################


plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(C), " and ", italic(D))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourCancer)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourPos)
text(x = 0.3,
     y = 0.5,
     labels = expression(italic(C)))
text(x = 0.7,
     y = 0.5,
     labels = expression(italic(D)))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


#################



plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression("The probabilities in each section"),
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourCancer)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourPos)
text(x = 0.3,
     y = 0.5,
     labels = "0.005")
text(x = 0.7,
     y = 0.5,
     labels = "0.098")
text(x = 0.7,
     y = 0.85,
     labels = expression(bar(italic(C)) ~ intersect() ~ bar(italic(D)) ~ ": 0.882") )
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)

# Intersection
text(x = 0.5, 
     y = 0.5, 
     label = "0.015")
```





### Sample spaces

Sometimes the most convenient way to compute probabilities is to list the sample space.
This only works for small discrete sample spaces, and works best when each of the outcomes in the sample space are equally likely.

::: {.example #TwoDice name="Rolling two dice"}
Consider rolling two standard dice and noting the *sum* of the numbers shown.
The sample space is listed in Table \@ref(tab:TwoDice).


```{r TwoDice, echo=FALSE}
Die1 <- 1:6
Die2 <- 1:6

DieSum <- outer(Die1, Die2,
                FUN = "+")

rownames(DieSum) <- paste("Die 1:", 1:6)
colnames(DieSum) <- paste("Die 2:", 1:6)

knitr::kable(DieSum,
             caption = "The sum of rolling two dice")
```

Then, $\Pr(\text{sum is 7}) = 6/36$ is found by counting the equally-likely outcomes that sum to seven.
:::

When the number of elements in the sample space is large, principles and formulae exist which facilitate counting.
Some of these are described in the next section.


## Counting techniques {#Counting}

The number of elements in a set is often large, and a complete enumeration of the set is unnecessary if all we want to do is to count the number of elements in it.


### Multiplication principle {#MultiplicationPrinciple}

If we have $m$ ways to perform act $A$ and if, for *each* of these, there are $n$ ways to perform act $B$, then there are $m\times n$ ways to perform the acts $A$ *and* $B$. 
This is called the *multiplication principle*.

:::{.definition #MultiplicationPrinciple name="Multiplication principle"}
With $m$ elements $a_1, a_2, \ldots , a_m$ and $n$ elements $b_1, b_2, \ldots, b_n$ it is possible to form $mn$ pairs containing one element from each group.
:::

The principle can be extended to any number of sets.
For example: For three sets of elements $a_1, a_2, \ldots , a_m$; $b_1, b_2, \ldots , b_n$ and $c_1, c_2, \ldots , c_p$, the number of distinct triplets containing one element from each set is equal to $mnp$.


:::{.example #MultiplicationPrinciple name="Multiplication principle"}
Suppose a restaurants offers five main courses and three desserts.

If a 'meal' consists of one main plus one dessert, a total of $5\times 3 = 15$ meal combinations are possible.
:::


### Permutations

Another important counting problem deals with different permutations of a finite set.
The word *permutation* in this context is simply an ordering of the set: selecting elements when the *selection order is important*.


#### Selecting without replacement

Suppose a set has $n$ elements. 
To order these, we must first choose the first element of the ordering, which can be done in $n$ different ways.
The second element must then be chosen, which can be done in $(n - 1)$ ways (since it cannot be the same as the first).
There are then $(n - 2)$ ways for the third, and so on. 

We find (using the multiplication principle) that there are $n(n - 1)(n - 2)\ldots 2 \times 1$ different ways to order the $n$ elements. 
This is denoted by $n!$ and called 'n factorial':
\[
   n! = n(n - 1)(n - 2) \ldots (2)(1)
\]
where $n\geq 1$, and we define $0! = 1$.

In some cases, it is necessary to know the number of ways in which the first $r$ elements of an ordering may be chosen. 

For this problem, the first element in the ordering may be chosen in $n$ different ways, the second in $(n -1)$ ways, the third in $(n - 2)$ ways, and so on... down to the $rth$, which may be chosen in $(n -r + 1)$ ways. 

This number is denoted by $^nP_r$, and we write
\begin{equation}
   ^nP_r = n(n-1)(n-2)\ldots (n - r + 1) = \frac{n!}{(n - r)!}.
    (\#eq:Permutation)
\end{equation}
This expression is referred to as *the number of permutations of $r$ elements from a set with $n$ elements*.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Notation for permutations varies.

Some notation for permutations include $nPr$, $^nP_r$, $P_n^r$ or $P(n,r)$.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
By definition, $0! = 1$.
By making this definition, many formulas in combinatorics (that follow) remain valid for all valid choices of parameters values.
:::


:::{.example #PasswordLowerCase name="Permutations"}
Suppose a company requires users to select a password of 8 characters using only lower-case letters.

Since the order of the letters is important in a password, we need to work with *permutations*.
There are 
\[
   \displaystyle {}^{26}P_8 =  \frac{26!}{(26 - 8)!} = 62\,990\,928\,000
\]
possible passwords to select.
:::


#### Selecting with replacement

If each item can be re-selected (for example, the item is returned to the larger pool of item), we say that selection is done *with replacement*.

The number of *ordered selections* of $r$ objects chosen from $n$ *with replacement* is $n^r$.
The first object can be selected in $n$ ways, the second can be selected in $n$ ways, etc., and by the multiplication principle, we have $n^r$ possible outcomes.


### Combinations {#Combinations}


In some cases, order is not important when choosing a subset (i.e., when dealing a hand of cards). 
A *combination* of $r$ elements from a set $S$ is a subset of $S$ with exactly $r$ elements.


#### Selecting without replacement

The number of *combinations* of $r$ elements from a set with $n$ distinct elements id denoted by $^nC_r$.
The number of permutations is given by \@ref(eq:Permutation), but of course the number of combinations must be smaller, since each combination gives rise to several permutations.
In fact, each combination of $r$ elements can be ordered in $r!$ different ways, and so gives rise to $r!$ permutations.
Hence, the number of permutations must be $r!$ times the number of combinations.
We have then,
\[
   ^nC_r = \frac{n(n - 1)\ldots (n - r + 1)}{r!} = \frac{n!}{(n - r)!r!}
\]
This is often written as ${n \choose r}$.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Notation for combinations varies.

Notation for combinations include $nCr$, $^nC_r$, $C_n^r$, ${n\choose r}$ or $C(n,r)$.
:::



::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The difference between *permutations* and *combinations* is important!

With permutations, the *selection order* is important, whereas *selection order is not important* with combinations.

In addition, both formulae apply when *there is no replacement* of the items.
:::


::: {.example #ChooseDigits name="Selecting digits"}
Consider the set of integers ${1, 3, 5, 7}$.
Choose two numbers, *without replacement*, and call the first $a$ and the second $b$.
If we then compute $a\times b$, then $^4C_2 = 6$ answers are possible since the *selection order is not important* (e.g., $3 \times 7$ gives the *same* answer as $7 \times 3$).

However, if we compute $a\div b$, there are $^4P_2 = 12$ possible answers, since the *selection order is important* (e.g., $3 \div 7$ gives a *different* answer than $7 \div 3$).
:::




:::{.example #CombinationOzLotto name="Oz Lotto combinations"}
In [Oz Lotto](#exm:Lotto), players select seven numbers from 47, and try to match these with seven randomly selected numbers.
The order in which the seven numbers are selected in not important, so *combinations* (not permutations) are appropriate.

The number of options for players to choose from is
\[
   {47\choose 7} = \frac{47!}{40!\times 7!} = 62\,891\,499;
\]
that is, almost 63 million combinations are possible.

The probability of picking the correct seven numbers in a simgle guess is
\[
   \frac{1}{62\,891\,499} = 1.59\times 10^{-8} = 0.000\,000\,015\,9.
\]
:::


The binomial expansion
\[
  (a + b)^n = \sum^{n}_{r = 0} {n \choose r} a^r b^{n - r}
\]
for $n$ a positive integer, is often referred to as the *Binomial Theorem* and hence ${n \choose r}$ is referred to as a *binomial coefficient*.

This series, and associated properties, is sometimes useful in counting.
Some of these properties are stated below.

1. ${n \choose r} = {n \choose n - r}$, for $r = 0, 1, \ldots, n$.
2. As a special case of the above, ${n \choose 0} = 1 = {n \choose n}$.
3. $\sum_{r = 0}^n {n \choose r} = 2^n$.





#### Selecting without replacement

The number of ways $r$ objects can be chosen from $n$ *with replacement* and *without regard to order* is somewhat more difficult and won't be attempted here.
The number of ways is actually ${n + r - 1 \choose r}$.




## Introducing statistical computing {#StatisticalComputing}

Computers and computer packages are essential tools in the application of statistics to real problems. 
In this book, you will be introduced to the statistical package **R**. 
It will be used to illustrate various concepts and should help you understand the theory (Example \@ref(exm:CoinToss)).

In particular, **R** will be used to verify theoretical results obtained.
To do this, a technique called *computer simulation* can be used. 

Simulation can also be used to solve problems for which it may be difficult (or impossible) to obtain a theoretical result. 
Sometimes these numerical solutions to intractable analytical problems is termed *Monte Carlo simulation*.


### The gameshow problem {#Gameshow}

A gameshow contestant is told there is a car behind one of three doors, and a goat behind each of the other doors. 
The contestant is asked to select a door. 

The host of the show (who knows where the car is) now opens one of the doors *not* selected by the contestant, and reveals a goat. 
The host now gives the contestant the choice of either (a) retaining the door chosen first, or (b) switching and choosing the other (unopened) door. 
What is the contestants best strategy?

1. Always retain the first choice.
2. Always change and select the other door.
3. Choose either unopened door at random.


Only a brief outline of the method is given here. 
A more complete solution is given later (see Exercise~\ref{QN:gameshow}).

1. Generate a random sequence of length 1000 consisting of the integers 1, 2 and 3. 
  (These numbers represent the door that the car is behind on each of 1000 nights, assumed chosen at random.)
2. Generate another such sequence to represent the contestants *first* choice on each of the 1000 nights (assuemd chisen at random).
3. The number of times the numbers in the two lists of trandom numbers *do* agree represents the number of times the contestant will win *if the contestant doesn't change doors*.
   If the numbers in the two columns *don't* agree then the contestant will win *only if the contestant decides to change doors*.


For the 1000 nights simulated, contestants would have won the car 30 times if they retained their first choice which means they would have won 70 times if they had changed. 
(Does this agree with your intuition?) 
This implies (correctly!) that the best strategy is to change. 
You might like to try doing the simulation for yourself.

The correct theoretical probability of winning if you retain the original door is 1/3, but 2/3 if you change.) 
We obtained a reasonable estimate of these probabilities from the simulation: 303/1000 and 697/1000. 
These estimates would improve for larger simulation sizes.

```{r echo=TRUE}
set.seed(93671) # For reproducability

NumSims <- 1000  # The number of simulations
# Choose the door where the car is hiding:
CarDoor <- sample(1:3,         # Could be behind Door 1, 2 or 3
                  size = NumSims, # Repeat
                  replace = TRUE)
# Choose the contestants initial choice:
FirstChoice <- sample(1:3,     # Could guess Door 1, 2 or 3
                  size = NumSims, # Repeat
                  replace = TRUE)

# Compute the chances of winning the car:
WinByNotSwitching  <- sum( CarDoor == FirstChoice)
WinBySwitching     <- sum( CarDoor != FirstChoice)

c(WinByNotSwitching, WinBySwitching) / NumSims
```

## Looking ahead

DELETE THIS SECTION??

The study of probability is basic to the study of modern statistics.
Consider the following example, the data coming from the Journal of Applied Physiology (1984), 1020--1023.
(Source: Devore, Jay and Peck, Roxy (1993) *Statistics: The Exploration
and Analysis of Data*,(2nd ed).)


### The experiment {#CAO}

REEXPRESS AS HTEST

Chronic airflow obstruction (CAO) severely limits the exercise capability of sufferers. 
Maximum exercise ventilation for each of 21 CAO patients was determined under two different experimental conditions. 
Fifteen patients recorded their best ventilation under experimental Condition 1.

Does this mean that one of the experimental condition gives better results than the other?

We might be tempted to say that *clearly* experimental Condition 1 is better since 15 of 21 did better. 
What is wrong with this reasoning? 

Let us suppose that a patient actually performs equally well under either experimental condition. 
Then it is a matter of chance under which experimental condition a patient is recorded as performing best.
The original question can now be restated as:

> Is it likely that 15 (or more) CAO patients will appear to do better under experimental Condition 1 (or 2), if in fact there is no difference between the effect of the two?}

Let us tackle the problem experimentally. 
The problem above is similar to that of tossing a coin: we could let a head represent a patient doing better under Condition 1, a tail as better under Condition 2. 
Tossing the coin 21 times then gives us one possible outcome for our experiment. 

If we repeat this a large number of times, then we can observe how many times we get 15 or more *patients* doing better on Condition 1 (or Condition 2) just by chance. 
(**Note**: If there is really no difference the results could go in either direction, not just the direction observed in the ONE experiment described above.) 
Suppose we carried out the experiment 1000 times, we should be able to make some definite conclusion. 
However, it is of course not really feasible to actually throw a coin this number of times.
We get around this problem by simulating the experiment on a computer using R. 

We let 0 represent a patient doing better on experimental Condition 1, and by a 1 a patient doing better on Condition 2. 
We can then generate a sequence of 1's and 0's representing the results of 21 patients. 
This can be repeated 1000 times.
The results of one such *simulation* experiment are given below:

FIX!!!!


```{r echo=TRUE}
set.seed(416893) # For reproducibility

numSimulations <- 1000 # The number of simulations
recordResults <- array( dim = numSimulations)

for (i in 1:1000){   # Do 1000 simulations, of:
   Results <- rbinom(21,       # 21 patients
                     size = 1, # Two outcomes: 0 (Cond 1 better) and 1 (Cond 2 better)
                     p = 0.5)
   recordResults[i] <- sum(Results)   
}

table(recordResults)
```

Let $X$ represent the number of times (out of 21) that CAO patients under Condition 1 do better than under Condition 2.
In Table \@ref(tab:CAOTable), the `Count` column then gives the number of trials (out of 1000) in which there were exactly $x$ CAO patients doing better under Condition 1.
This is given as a percentage in the third column.

```{r CAOTable, echo=FALSE}
tabResults <- table(recordResults)

CAOTable <- array( dim = c(7, 7))

colnames(CAOTable) <- c("Number",
                        "Count",
                        "Percentage",
                        " ", # Spacer
                        "Number",
                        "Count",
                        "Percentage")
                        
CAOTable[, 1] <- names(tabResults)[1:7]
CAOTable[, 5] <- names(tabResults)[8:14]

CAOTable[, 2] <- tabResults[1:7]
CAOTable[, 6] <- tabResults[8:14]

CAOTable[, 3] <- round( as.numeric(CAOTable[, 2]) / numSimulations * 100, 1)
CAOTable[, 7] <- round( as.numeric(CAOTable[, 6]) / numSimulations * 100, 1)

knitr::kable(CAOTable,
             caption = "The results of the CAO simulation")
                       
```
We can now make an informed answer to the original question.

Notice that $29 + 9 = 38$ (or 0.038) of the result in 15 or more CAO patients doing better on Condition 1, while $22 + 10 + 3 + 2 = 37$ (or 0.037) of the experiments result in 6 or fewer of the CAO patients doing better on Condition 2.
That is, $38 + 37 = 75$ out of the 1000 experiments resulted in an outcome as extreme as the one observed in the actual experiment, an estimated probability of 0.075 that a result this extreme would occur purely by chance if there is in fact NO DIFFERENCE in effect of the two experimental conditions.

If the probability is above 0.05 (that is 5\%), we usually say the case of a difference in effect has not been shown on the grounds that we can't be sure it has not occurred by chance alone. 
(5\% would mean we expect it to occur by chance 1 out of 20 times, a rate which is not unreasonable to expect to happen.)

Our conclusion here would be that there is insufficient evidence to conclude a difference in effect of the two experimental conditions.


**Comments**

1. The above conclusion relies on estimating an appropriate probability.
2. The calculations involved using a computer to simulate the problem.
3. Very little theoretical knowledge of probability was necessary although we did assume that the probability of getting a head on each toss of a fair coin was 0.5.
4. In this case if we had known more about probability modelling simulation would not have been necessary, as a satisfactory theoretical model can be found for this problem. 
   (This could then be applied in many other similar situations.)
   A knowledge of probability theory would have made our task much simpler here.
5. One of the aims in this course is to provide the tools for you to model different experimental situations.
6. **Final note:** Simulation is a very powerful tool. 
   In many complex situations, it may either provide the only method of proceeding or may be used to gain insight into the problem that allows some progress to be made by more conventional means. 
   It is also used to verify theoretical results.


We will return to this example later when we have the tools to find the probability model.






## Exercises


:::{.exercise #BasicProbs}
Suppose $\Pr(A) = 0.44$, $\Pr(B) = 0.35$ and $\Pr(A\cap B) = 0.11$.
Find:

1. $\Pr(A\cup B)$.
2. $\Pr(\overline{A}\cap B)$.
3. $\Pr(\overline{A} \cup \overline{B})$.
4. $\Pr(A \mid B)$.
5. Are events $A$ and $B$ independent?
:::


:::{.exercise #Quadratic}
Consider the solutions to the general quadratic equation $y = ax^2 + bx + c = 0$ (where $a\ne0$, since then the equation does not define a quadratic). 
Suppose real values are chosen at random for the constants $a$, $b$ and $c$.

1. Define the sample space $S$ for the experiment.
2. Define the event $R$: 'the equation has two equal real roots'.
:::



:::{.exercise #WalkScore}
Use @mypapers:dunnsmyth:glms Exercise 12.9 (redone of course).
:::


:::{.exercise #HatData}
Researchers [@data:Dexter2019:SunProtection] observed the behaviour of pedestrians in Brisbane, Queensland, around midday in summer.
The researchers found:

* For males: a probability of 0.025 of wearing a hat.
* For females: a probability of 0.060 of wearing a hat.

Using this information:

1. Construct a tree diagram for the sample space.
1. Construct a table of the sample space.
1. Construct the Venn diagram of the sample space.
:::


:::{.exercise #CarPassengers}
A family with six non-driving children, and two driving parents has an eight-seater vehicle.

1. In how many ways can the family be seated in the car (and legally go driving)?
1. Suppose one of the children obtains their driving licence.
   In how many ways can the family be seated in the car (and legally go driving) now?
1. Two of the children needs car seats, and there are two car seats fixed in the vehicle (i.e., they cannot be moved to different seats).
   If the two parents are the only drivers, in how many ways can the family be seated in the car (and legally go driving) now)?
:::


:::{.exercise #Monopoly}
A group of four people sit down to play Monopoly.
The eight tokens are distributed randomly.
In how many ways can this be done?
:::


:::{.exercise #PassWords}
A company password policy is that users must select an eight-letter password comprising lower-case letters (Example \@ref(exm:PasswordLowerCase)).

The company is considering each of the following changes separately:

1. Suppose the policy changes to allow eight-, nine-, or ten-letter password of just lower-case letters.
   How many passwords are possible now?
1. Suppose the policy changes to allow eight-letter password comprising lower-case and upper-case letters letters.
   How many passwords are possible now?
1. Suppose the policy changes to allow eight-letter password comprising lower-case, upper-case letters letters and the ten digits 0 to 9.
   How many passwords are possible now?
1. Suppose the policy changes to allow eight-letter password comprising lower-case, upper-case letters letters and the ten digits 0 to 9, and each password must have one of each category.
   How many passwords are possible now?
:::
