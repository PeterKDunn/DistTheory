\mainmatter

# Probability essentials {#Probability}



::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
Upon completion of this module you should be able to:

* understand the concepts of probability, including sample space and sample points of an experiment
* define probability from different perspectives and apply them to compute probabilities in various situations
* explain the concept of conditional probability and independence of two events
* differentiate between mutually exclusive events and independent events
* apply Bayes' Theorem to find the 'reverse' probability by using the formula and tree diagrams
* use the rules of combinations and permutations to compute the probabilities of various events involving counting problems
* recall and make use of the properties of arithmetic and geometric series
* recall and recognise the exponential, logarithmic and binomial power series.
:::




## Introduction

Imagine if life was all deterministic!
The commute from home to university or work would always take exactly the same length of time; weather predictions would always be accurate; you would know exactly what lotto numbers would be drawn on the weekend...

However, life is full of unpredictable variation.

While we talk about the variation being *unpredictable*, patterns still emerge. 
We may not know what the next toss of a coin will produce... but we see a *pattern* in the long run: a Head appears about half the time.

Statistics is essentially the study of this unpredictable variation.
Probability is one of the tools used to describe this variation.

In most fields of study, situations exist where being certain is almost impossible, and so probability is necessary:

* What is the chance that an investment will make money in the next 12 months?
* What is the chance that a medical procedure will be successful on a particular patient?
* How likely is it that the water level at a certain river crossing will rise above 2 meters in the next 20 years?
  And if it does, what is the chance that the bridge will not be washed away?
* What is the chance that two DNA sequences may come from identical parents if their genome sequences are almost identical?
* What is the chance of rain on the weekend?
* Given the evidence, what is the chance that the defendant is guilty?

To answer these questions, a framework is needed: concepts like *probability* need defining, and notation and theory are required.
These tools are important for modelling real-world phenomena, but also for providing a firm mathematical foundation in the theory of statistics.

This chapter covers the concept of probability, introduces notation and definitions, and develops some theory useful in working with probabilities.



## Sample space, sample points and events

To begin, certain terms must be defined

:::{.definition #Process name="Random process"}
A **random process** is a procedure that

* can be repeated, in theory, indefinitely under essentially identical conditions; and
* has well-defined outcomes, called **events**; and
* the outcome of any individual repetition is unpredictable.
:::

This definition for a *random process* is a little vague, but the intention is to define a process where data are gathered.

Examples of simple *random processes* include tossing a coin, or rolling a die.

The concepts of *sample space* and *sample point* are important for defining the outcomes of a random process, and for understanding probability.

*Spaces* can be defined in terms of *sets*: Collections of elements.


::: {.definition #Sets name="Sets"}
A *set* of elements (or sample points) is denoted using capital letters: $A$.

The *elements* (or sample points) in the set are denoted by lower-case letters, and are shown to belong to a set by enclosing them in braces:
\[
   A = \{ a_1, a_2, a_3, a_4\}.
\]
:::


::: {.definition #SampleSpace name="Sample space"}
A *sample space* (or *event space*, or *outcome space*) for a random process is a set of all possible outcomes.
This is denoted by $S$.

A single element of $S$ is called an *element* or *sample point*.
:::


Two special sets are useful to define.


:::{.definition #UniversalEmpty name="Universal and empty sets"}
The **universal set** is the set of *all elements under consideration*, usually denoted by $S$.

The **null set**, or the *empty set* has zero points, denoted by $\emptyset$.
:::


Having defined the universal set, we can define sets containing just some of those elements.

::: {.definition #Event name="Event"}
An *event* is a set of sample points.
That is, an event is a subset of $S$, and we write $A\subseteq S$.

In the two extreme cases, $S$ itself is an event called the *certain* event, and $\emptyset$ is called the *impossible* (or nonrealisable) event.
:::


::: {.definition #ElementaryEvent name="Elementary event"}
An *elementary event* (or a *simple event*) is an event that cannot be decomposed.
It is an event with only one sample point.
:::


:::{.example #TwoCoinToss name="Tossing a coin twice"}
Consider the simple random process of tossing a coin twice.

The sample space (the set of all possible outcomes) could be listed as:
\[
   S = \{(H, H), (H, T), (T, H), (T, T) \},
\]
where $H$ represents tossing a head; $T$ represents tossing a tail; and the pair $(cdot, \cdot)$ list the resut of each toss in order.

We can define the event $A$ as the set of points that correspond to 'tossing a head on the second toss' by listing the elements:
\[
   A = \{ (H, H), (T, H)\}.
\]
:::


An important concept is that of an *occurrence* of an event.

::: {.definition #Occurence name="Occurence"}
An event $A$ *occurs* on a particular trial of an experiment if the outcome of the trial is one of the sample points in $A$.
:::

PART OF THIS IS REPEATED FROM ABOVE

:::{.example}
In Example \@ref(exm:TwoCoinToss}, the *universal set* is the set of all possible outcomes:
\[
   S = \{(H, H), (H, T), (T, H), (T, T) \},
\]
where $H$ represents tossing a head; $T$ represents tossing a tail; and the pair $(cdot, \cdot)$ list the resut of each toss in order.

In the same example, a *null set* could be the set of outcomes with *three* heads,
as there are no sample points with three heads.
:::

The relationship between different sets, say sets $A$ and $B$, can be described also.

:::{.definition #IntersectionUnionSubset name="Intersection, union and subset"}
Consider two sets $A$ and $B$ defined on the same sample space $S$.
Then:

* the **intersection** of sets $A$ and $B$, written as $A\cap B$, is the set of points in both $A$ and $B$.
* the **union** of sets $A$ and $B$, written as $A\cup B$, is the combined set of all the points in either $A$ or $B$, or both.
* $A$ is a **subset** of B, written as $A\subset B$, if all the elements of $A$ are in $B$. (Set $B$ may have other elements that are not in $A$.)
* the **complement** of $A$ is the set of points that are in $S$, but are *not* in $A$.
:::


The visual representation in Fig. \@ref(fig:IntersectionUnionSubset) may help clarify.



```{r IntersectionUnionSubset, echo=FALSE, fig.height = 6.5, fig.align="center", fig.cap="Subsets, union, intersection and complement of sets. The rectangle represents the universal set $S$."}
#par( mar = c(0.05, 0.05, 0.05, 0.05))
par(mfrow = c(2, 2) )


colourA <- rgb(0, 0, 255, 
               max = 255, 
               alpha = 125)
colourB <- rgb(0, 255, 0, 
               max = 255, 
               alpha = 125)
colourS <- rgb(100, 100, 100, 
               max = 255, 
               alpha = 125)


### INTERSECTION
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("The ", bold(intersection), " of sets ", italic(A), " and ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourA)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourB)
text(x = 0.4,
     y = 0.75,
     labels = expression(italic(A)), 
     pos = 3)
text(x = 0.6,
     y = 0.75,
     labels = expression(italic(B)), 
     pos = 3)
arrows( x0 = 0.5, 
        y0 = 0.15,
        x1 = 0.5,
        y1 = 0.5,
        length = 0.15,
        lwd = 1)
text(x = 0.5,
     y = 0.18,
     pos = 1,
     labels = expression(italic(A) ~~ intersect() ~~ italic(B)))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


### UNION
colour1 <- rgb(128, 204, 255, 
               max = 255) 

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste("The ", bold(union), " of sets ", italic(A), " and ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colour1,
                     border = colour1)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colour1,
                     border = colour1)
text(x = 0.5,
     y = 0.5,
     labels = expression(italic(A) ~~ union() ~~ italic(B)))


text(x = 0.4,
     y = 0.75,
     labels = expression(italic(A)), 
     pos = 3)
text(x = 0.6,
     y = 0.75,
     labels = expression(italic(B)), 
     pos = 3)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)



### SUBSET
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste( italic(A), " is a ", bold(subset), " of ", italic(B))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.52, 
                     y = 0.55,
                     radius = 0.1,
                     col = colourA)
plotrix::draw.circle(x = 0.5,
                     y = 0.5,
                     radius = 0.2,
                     col = colourB)
text(x = 0.52,
     y = 0.65,
     labels = expression(italic(A)),
     pos = 1)
text(x = 0.5,
     y = 0.75,
     labels = expression(italic(B)),
     pos = 3)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)




### COMPLEMENT
plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      xlab= "",
      ylab= "",
      main = expression(paste("The ", bold(complement), " of ", italic(A) )) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0),
         col = colourS)
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = "white")
text(x = 0.4,
     y = 0.4,
     labels = expression(italic(A)))
text(x = 0.75,
     y = 0.55,
     labels = expression(bar(italic(A))))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)
```


::: {.definition #MutuallyExclusive name="Mutually exclusive"}
Events $A$ and $B$ are *mutually exclusive* if, and only if, $A\cap B = \emptyset$.

The term *disjoint* is used for *sets*, whereas *mutually exclusive* is used when referring to *events*.
:::


::: {.definition #Implication name="Implication"}
An event $A$ *implies* an event $B$ if, and only if, $A\subseteq B$.
:::





:::{.example #RollDie name="Rolling a die"}
Suppose we roll a single, six-sided die.
We can define these two events:
\begin{align}
   E 
   &= \{\text{An even number is thrown}\} 
   &= \{ 2, 4, 6\};\\
   G 
   &= \{\text{A number larger then 3 is thrown}\} 
   &= \{ 4, 5, 6\}.
\end{align}
Then,
\begin{align}
   F \cap G 
   &= \{4, 6\}\\
   F \cup G
   &= \{ 2, 4, 5, 6\}\\
   \overline{F}
   &= \{ 1, 3, 5\}\\
   \overline{G}
   &= \{ 1, 2, 3\}.
\end{align}
We make other observations too:
\begin{align}
   F \cap \overline{G}
   &= \{2, 4, 6\} \cap \{ 1, ,2, 3\} = \{ 2 \};\\
   \overline{F} \cap \overline{G}
   &= \{1, 3, 5\} \cap \{ 1, ,2, 3\} = \{ 1, 3 \}.
\end{align}
See the figure below.

```{r echo=FALSE, out.width = '60%', fig.align="center"}
colourF <- rgb(0, 0, 255, 
               max = 255, 
               alpha = 125)
colourG <- rgb(0, 255, 0, 
               max = 255, 
               alpha = 125)

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(F), " and ", italic(G))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourF)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourG)
text(x = 0.4,
     y = 0.75,
     labels = expression(italic(F)), 
     pos = 3)
text(x = 0.6,
     y = 0.75,
     labels = expression(italic(G)), 
     pos = 3)
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)

# The elements
text(x = c(0.1, 0.5),
     y = c(0.6, 0.9),
     cex = 1.75,
     labels = c("1",
                "3"))
text(x = c(0.52, 0.48),
     y = c(0.55, 0.42),
     cex = 1.75,
     labels = c("4",
                "6"))
text(x = 0.25,
     y = 0.47,
     cex = 1.75,
     labels = "2")
text(x = 0.75,
     y = 0.55,
     cex = 1.75,
     labels = "5" )
```
:::


Set algebra has many rules; we onky provide some.
For sets $A$, $B$ and $C$ defined on the same sample space:

* $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.
* $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$.
* $\overline{A \cap B } = \overline{A} \cup \overline{B}$.
* $\overline{A \cup B } = \overline{A} \cap \overline{B}$.

:::{.example}

EXAMPLE??
:::


## Discrete and continuous sample spaces

So far, the sample spaces used in the examples have been *discrete*, but this is not necessary.


::: {.definition #SDiscreteSampleSpace name="Discrete sample space"}
A *discrete sample space* is a sample space that contains a finite or countably infinite number of distinct sample points.
:::


:::{.example #Discrete SS name="Discrete sample space"}
In Example \@ref(exm:RollDie), the sample space on which events $F$ and $G$ were defined is discrete.
There are six outcomes.
:::


A *finite* set of points seems easy to understand (e.g., after rolling a standard die, there are exactly six possible outcomes).
However, the idea of a *countably infinite* number of distinct points sounds a little strange...


:::{.example #RollingTill6 nane="Rolling a die to obtain a 6"}
Consider rolling a standard die and counting the number of throws needed until a 6 is thrown.

The *sample space* is the set of all possible outcomes.
Now, the 6 could appear on the first roll, or the second, or the third.

However, even though it is very unlikely, it may take 20 rolls... or 50 rolls.
What is the maximum number?
There is no maximum number (though there is a point beyond which it becomes extremely unlikely).
In such a situation, we say there are a 'countably' infinite number of points even though we can't list them all.
The sample space could be deonted
\[
   S = \{ 1, 2, 3, \dots\}.
\]
:::





## Assigning probabilities

To formalise the notion of the chance of an event occurring, a number is assigned to this chance, called a *probability*.
What values should these numbers take?

One useful option is to assign a probability of 0 to an event that *never* occurs, and 1 to an event that is *certain* to occur.
This method is appealing as it aligns with the idea of proportions or percentages as numbers between 0 and 1.

One other method in standard use is to work with *odds*.
Odds compare how often an event is likely to occur, to how often the veent is likely to *not occur*.
In this system, an impossible event is assigned $0$, a certain event is assigned $\infty$, and an event that will happen just as often as not happen is assigned $1$.

We will only use the system with probabilities between $0$ and $1$ in this book.

Developing a method of assigning sensible probabilities to events is difficult.
Four methods are discussed here.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Be aware of variations in notation!

The probability of an event $E$ occurring can be denoted as $\text{P}(E)$ or $\text{Pr}(E)$.

The complement of an event $A$ (everything that is *not* in event $A$) can be denoted $\overline{A}$, or $A^c$, or $A'$.
:::


## Empirical (relative frequency) approach

When the random process is repeated many times, counting the number of times the event of interest occurs means we can compute the *proportion* of times the event occurs.
Mathematically, if the process is repeated $n$ times, and event $E$ occurs in $m$ of these ($m < n$), then the probability is of the event occurring is
\[
   \Pr(E) = \lim_{n\to\infty} \frac{m}{n}.
\]
$n$ needs to be very large to compute probabilities accurately, and approximate probabilities can only ever be found.

This is the *empirical* (or *relative frequency*) approach to probability.

This method cannot always be used.
For example, suppose a company wishes to determine the probability that matches they produce  will light.
To determine an accurate probability, matches must be struck, and then can no longer be sold, which may defeat the purpose the study.

As another example, consider the probability that the airbag in a car will prevent a serious injury in the passenger.
It is not ethical or financially viable to crash thousands of vehicles with passengers in them to see how many people break bones.
(Fortunately, car manufacturers use dummies to represent people and crash small numbers of cars to get some indications of the probabilities).
In these situations, sometimes computer simulations can be used to approximate the probabilities.


::: {.example #SalkVaccine name="Salk vaccine"}
In 1954, Jonas Salk developed a vaccine against polio (@book:Williams:BioStats, \S1.1.3).
To test the effectiveness of the vaccine, the data in Table \@ref(tab:Polio) were collected.

The relative frequency approach can be used to estimate the probabilities of developing polio *with* the vaccine and *without* the vaccine (the control group):
\begin{align*}
   \Pr(\text{develop polio in control group}) 
   &= 115/201\,229 = 0.00057;\\
   \Pr(\text{develop polio in vaccinated group}) 
   &= 33/200\,745 = 0.00016.
\end{align*}
This shows that the estimated *probability* of contracting polio in the control group is about 3.5 times greater than in the control group.
The precision of these sample estimates could be quantified by producing a confidence interval for the proportions.

Rather than using probabilities, we would also use *odds*:
\begin{align*}
   \text{Odds}(\text{develop polio in control group}) 
   &= \frac{115}{201,229} = 0.000571;\\
   \text{Odds}(\text{develop polio in vaccinated group}) 
   &= \frac{33}{200,745} = 0.000164.
\end{align*}
This shows that the estimated *odds* of contracting polio in the control group is about 3.5 times greater than in the control group.
In this context, the *odds ratio* is about 3.5.
:::


```{r Polio, echo=FALSE}
VaccTable <-  array( dim = c(2, 2))
VaccTable[1, ] <- c(200745, 33)
VaccTable[2, ] <- c(201229, 115)

colnames(VaccTable) <- c("No. treated",
                         "Paralytic cases")
rownames(VaccTable) <- c("Vaccinated",
                         "Control")

knitr::kable(VaccTable,
             caption = "The number of paralytic cases for two groups of children: one group of controls and another vaccinated with the Salk polio vaccine")
```




::: {.example #CoinToss name="Tossing coins"}
Repeating random process large numbers of times can be impractical and tedious.
However, sometimes a computer can be used to *simulate* the random processes.
Consider using a computer can be used to simulate large numbers of coin tosses.

Using $\Pr(\text{Toss head}) = 0.5$, R is used to simulate 500 tosses.
After each toss, the probability of obtaining a head using all the available information was computed at each toss.
For one such simulation, the running probabilities are shown in Fig. \@ref(fig:SimTosses).
:::


```{r SimTosses, echo=TRUE, fig.cap = "A simulation of tossing a fair coin $1000$ times. The probability of getting a head is computed from the data after each toss."}
set.seed(966141) # For repeatability
NumTosses <- 500 # Simulated tossing a coin 500 times
Tosses <- rbinom(n = NumTosses,  # This many tosses...
                 size = 1,       # ... one toss at a time...
                 prob = 0.5)     # ...where P(Head) = 0.5
RunningTosses <- seq(1, NumTosses)  # Sequence of toss number
PropHeads <- cumsum(Tosses) / RunningTosses  # P(Heads) at each toss

plot(PropHeads,
     xlab = "Toss number",
     ylab = "Proportion of heads",
     type = "l",
     lwd = 2,
     ylim = c(0, 1),
     las = 1,
     col = "blue")
abline( h = 0.5,
        col = "grey")
```

::: {.example #MaximumTemp name="Maximum temperature"}
Using data supplied by the Queensland Department of Primary Industries (QDPI) from 1 Jan 1889 to 21 July 2002, the maximum temperatures recorded for January on 3534 days.
Of these, 302 maximum temperatures are greater than 30$^\circ$.

An estimate of the probability that a day in January has a maximum temperature greater than 30$^\circ$ is $302/3534 =  0.08545$, or about 8.5\%.
:::


Using the empirical approach shows why probabilities are between 0 and 1 (inclusive), since  proportions are always between 0 and 1 (inclusive).


## Classical approach

The *classical approach* requires being able to define a sample space containing a set of *equally-likely* outcomes.
In practice, this is only true for trivial experiments, like tossing coins, rolling dice, and dealing cards.
For the classical approach, for a random process with $n$ *equally-likely* outcomes, all are assigned probability $1/n$.


:::{.example #TossingDice name="Tossing dice"}
When a standard die is tossed, six equally-likely outcome comprise the sample space: 
\[
   S = \{ {1},{2},{3},{4},{5},{6}\}.
\]
The probability $\Pr(\text{an even number is thrown})$ can be computed by counting those outcomes in the sample space that are even, and dividing by the total number of outcome in the sample space (six).
The probability is $3/6 = 0.5$.
:::


::: {.example #Lotto name="Lotto"}
In a game of Oz Lotto, [seven numbered balls are drawn from balls numbered 1 to 47](https://www.thelott.com/oz-lotto/how-to-play).

There is no reason to suspect that any one number should be more or less likely to occur than any other number.
Any set of seven numbers is just a likely to occur as any other set of seven numbers.

Listing the sample space is difficult as there are a very arge number of options for selecting seven numbers from 47.s
:::




## Subjective approach

'Subjective' probabilities are estimated after identifying the information that may influence the probability, and then evaluating this information. 
The final (subjective) probability may, for example, be computed using mathematical models that use the information.
When different people or systems identify different information as relevant, and combine them differently, different subjective probabilities eventuate.

Some examples include:

* What proportion of the Australian public will vote for the Labor Party at the next election?
* What is the chance an investment will be a success?
* How likely is it that Auckland will have above average rainfall next year?


::: {.example #ChanceRain name="The chance of rain"}
What is the likelihood of rain in Charleville (a town in Queensland) during April?
Many farmers could give a subjective estimate of the probability based on their experience and the conditions.

Using the classical approach to determine the probability is not possible.
There may be two outcomes---it will rain, or it will not rain---but these are almost certainly not *equally likely*.

A relative frequency approach can be adopted.
Using data supplied by the DPI\footnote{The Department of Primary Industries.} from 1882 to 1994 (113 years), rain fell in 96 years.
An *approximation* to the probability is therefore $96/113 = 0.85$, or $85$\%.
:::



## Axiomatic approach

An **axiom** is a self-evident truth that does not require proof, or cannot be proven.

Perhaps surprisingly, only three axioms of probability are needed, from which all other results in probability can be proven.


:::{.definition #ThreeAxioms name="Three axioms of probability"}
Consider a sample space $S$ for a random process.
For every event $A$ (a subset of $S$), a number $\Pr(A)$ can be assigned which is called the *probability* of event $A$.

The three axioms of probability are:

1. $\Pr(A) \ge 0$.
2. $\Pr(S) = 1$.
3. If $A_1$, $A_2$, $\dots$ form a sequence of pairwise mutually exclusive events in $S$, then
   \[
      \Pr(A_1 \cup A_2 \cup A_3 \cup \dots) = \sum_{i = 1}^\infty \Pr(A_i).
   \]
:::

In simple terms, these three axioms state:

1. Probabilities are never negative.
2. The probability that something in the sample space will occur is is one.
   (Recall that the sample space lists every possible outcome.)
3.  For [*mutually exclusive* events](#def:MutuallyExclusive), the probability of the *union* of events is the sum of the individual probabilities.


While this approach can sometimes help to assign probabilities, its main purpose is to formally define the rules that apply to probabilities.
Probabilities must obey the rules specified in these axioms.

These axioms of probability can also be used to develop all other probability formulae.

::: {.example #UsingAxions name="Using the axioms"}
Consider proving that $\Pr(\emptyset) = 0$.
While this may appear 'obvious', it is not one of the three axioms.

By definition, the empty set $\emptyset$ contain no points; hence $\emptyset \cup A = A$ for any event $A$.
 
Also, $\emptyset\cap A = \emptyset$, as $\emptyset$ and $A$ are [mutually exclusive](#def:MutuallyExclusive) (that is, they have no elements in common).
Hence, by the [third axiom](#def:ThreeAxioms)
\begin{equation}
   \Pr(\emptyset\cup A) = \Pr(\emptyset) + \Pr(A)
   (\#eq:ByThirdAxiom)
\end{equation}
But since $\emptyset \cup A = A$, then $\Pr(\emptyset \cup A) = \Pr(A)$, and so $\Pr(A) = \Pr(\emptyset) + \Pr(A)$ from \@ref(eq:ByThirdAxiom).
Hence $\Pr(\emptyset) = 0$.
:::

While this may have seemed obvious, *all* probability formulae can be developed just from assuming the three axioms of probability.




## Rules of probability

Many useful results can be deduced from the axioms.
They allow probabilities to be computed in more complicated situations.

::: {.theorem #CompRule name="Complementary rule of probability"}
For any event $A$, the probability of 'not $A$' is

\[
   \Pr(\overline{A}) = 1 - \Pr(A).
\]
:::

:::{.proof}
By the definition of the *complement* of an event (XREF), $\overline{A}$ and $A$ are mutually exclusive.
Hence, by the [third axiom](#defThreeAxioms), $\Pr(\overline{A} \cup A) = \Pr(\overline{A}) + \Pr(A).

AND SO ON
:::




:::{.theorem #ProbAddition name="Addition rule of probability"}
For *any* two events $A$ and $B$, the probability of either $A$ **or** $B$ occurring is 
\[
   \Pr(A\cup B) = \Pr(A) + \Pr(B) - \Pr(A\cap B).
\]
:::

:::{.proof}
See Exercise ???
:::


If the two events are *mutually exclusive*, we have a corollary of Theorem \@ref(thm:ProbAddition).

:::{.corollary #ProbAddition}
If the two events $A$ and $B$ are *mutually exclusive*, then the probability of either $A$ **or** $B$ is

\[
   \Pr(A\cup B) = \Pr(A) + \Pr(B).
\]
:::

:::{.proof}
See Exercise ???
:::


Some other results that follow from the axioms are the following.

* $\Pr(\emptyset) = 0$.
* $0 \leq \Pr(A) \leq 1$.
* For events $A$ and $B$, $\Pr(A\cup B) \leq \Pr(A) + \Pr(B)$.
* For events $A$ and $B$, if $A\subseteq B$ then $\Pr(B\cap \overline{A}) = \Pr(B) - \Pr(A)$.
* For events $A$ and $B$, if $A\subseteq B$ then $\Pr(A) \leq \Pr(B)$.

:::{.proof}
See Exercises ???
:::




## Equally-likely outcomes

CANT THIS INFO BE MOVED TO CLASSICAL PROB SECTION???

For the calculation of probabilities for events in a finite sample space, sometimes sample points can be described so that we have equally-likely outcomes (and hence the classical approach to the assignment of probabilities is appropriate).

Associating probabilities with events in this situation is essentially counting sample points.
Example \@ref(exm:TossingDice) is a simple demonstration of the principle which we now formalise.


:::{.theorem #EquallyLikely name="Equally-likely events"}
Suppose that a sample space $S$ consists of $k$ equally likely elementary events $E_1$, $E_2$, $\ldots$, $E_k$, and $A = \{ E_1, E_2, \ldots, E_r\}$, $(r\leq k)$.
Then

\[
   \Pr(A) = \frac{n(A)}{n(S)}.
\]
:::

This method of calculating the probability of an event is sometimes called the *sample-point method*.
Take care: errors are frequently made by failing to list all the sample points in $S$.

Methods of counting the points in a sample space are discussed in Section \@ref(Counting).


## Conditional probability and independence {#CondProbIndependence}

### Conditional probability {#CondProb}

Assume that a sample space $S$ for the experiment has been constructed, an event $A$ has been identified, and its probability, $\Pr(A)$, has been determined.
We then receive additional information that some event $B$ has occurred.
Possibly, this new information can change the value of $\Pr(A)$.


We now need to determine the probability that $A$ will occur, given that $B$ has already occurred.
We call this probability the *conditional probability of $A$ given $B$*, and denote it by $\Pr(A \mid B)$.


:::{.example #ConditionalPrinIntro name="The idea of conditional probability"}
Suppose I roll a die.
Define event $A$ as 'rolling a 6'.
Then, you could determine that $\Pr(A) = 1/6$ (using the classical approach).

However, suppose I provide you with extra information.
I tell you that event $B$ has already occurred, where $B$ is the event 'the number rolled is even'.

With this extra information, you know only three number could possibly have been rolled; the *reduced sample space* is now
\[
   S_R= \{2, 4, 6 \}.
\]
All of these outcomes are equally likely.
The probability that the number is a six is now $\Pr(A|B) = 1/3$.
:::


::: {.example #Rainfall name="Rainfall"}
In Example~\ref{EG:prob:assigning:chrain}, the chance of obtaining rain during April in Charleville was computed to be $0.85$ using the empirical approach.

However, research suggested that the chance of rainfall may depend on the value of the Southern Oscillation Index (SOI).
@climate:stone:1992 defined five phases of the SOI that can be attributed to any given month.

For the month of April, the empirical probabilities of observing rainfall in Charleville for various SOI Phases are shown in Table \@ref(tab:CharlevilleRain).

The probability of observing rain depends on the SOI phase that month:
\begin{align*}
   \text{For SOI Phase 1:}
   & \Pr(\text{rain} \mid \text{Phase 1}) = 0.56\\
   \text{For SOI Phase 2:}
   & \Pr(\text{rain} \mid \text{Phase 2}) = 0.96.
\end{align*}
:::



```{r CharlevilleRain, echo=FALSE}
RainTable <-  array( dim = c(3, 5))
RainTable[1, ] <- c(9, 24, 12, 27, 24)
RainTable[2, ] <- c(16, 25, 15, 28, 29)
RainTable[3, ] <- round(RainTable[1, ] / RainTable[2, ], 2)

colnames(RainTable) <- c("Phase 1",
                         "Phase 2",
                         "Phase 3",
                         "Phase 4",
                         "Phase 5")
rownames(RainTable) <- c("Days of rain",
                         "Number of days",
                         "Probability of rain")

knitr::kable(RainTable,
             caption = "The (empirical) probabilities of rainfall at Charleville during April, conditional on the SOI phases during that month.")
```




::: {.example #Planes name="Planes"}
Consider the difference between these two probabilities:

1. $\Pr(\text{a person dies} \mid \text{person falls out of an airborne plane with no parachute})$; and
2. $\Pr(\text{person falls out of an airborne plane with no parachute} \mid \text{a person dies})$.

Consider the first.
If you are told that somepone falls out of an airborne plane with no parachute, the probability that they die is very high.

Consider the second.
If you are told that some has died, it is very unlikely the the cause is a fall from a plane.

Thus, the first probability is very close to one, and the second is very close to zero.
:::


Two methods exist for computing conditional probability: first principles, or a formal definition of $\Pr(A \mid B)$.

For the first, we simply consider the original sample space $S$, remove the sample points inconsistent with the new information that $B$ has occurred, form a new sample space, say $S^*$, and recompute the probability of event $A$ relative to $S^*$.

$S^*$ is called the *reduced sample space*.

This method is appropriate when the number of outcomes is relatively small.
The following definition applies more generally.

::: {.definition #ConditionalProb name="Conditional probability"}
Let $A$ and $B$ be events in $S$ with $\Pr(B) > 0$. 
Then
\[
   \Pr(A \mid B) = \frac{\Pr(A\cap B)}{\Pr(B)}
\]
:::
The definition automatically takes care of the sample space reduction noted earlier.


:::{.example}
COND PROB exame. REUSE above, with notation.
:::


### Multiplication rule

As a consequence of Definition \@ref(def:ConditionalProb), we have the following theorem.

:::{.theorem #MultRule name="Multiplication rule for probabilities"}
For any events $A$ and $B$, the probability of $A$ and $B$ is
\begin{align*}
     \Pr(A\cap B)
     &= \Pr(A) \Pr(B \mid A)\\
     & =\Pr(B) \Pr(A \mid B).
\end{align*}
:::

This rule can be generalised to any number of events.
For example, for three events $A, B, C$,
\begin{equation}
  \Pr(A\cap B\cap C) = \Pr(A)\Pr(B\mid A)\Pr(C\mid A\cap B).
\end{equation}



### Independent events {#Independence}

The important idea of *independence* can now be defined.

::: {.definition #Independence name="Independence"}
Two events $A$ and $B$ are said to be *independent* if
\[
  \Pr(A\cap B) = \Pr(A)\Pr(B).
\]
Otherwise the events are said to be *dependent*.
:::


:::{.proof}
???
:::



Provided $\Pr(B) > 0$, we see from Definitions \@ref(def:ConditionalProb) and \@ref(def:Independence) that $A$ and $B$ are independent if, and only if, $\Pr(A \mid B) = \Pr(A)$.
This statement of independence is sensible in that the first probability is the probability of $A$ occurring if $B$ has already occurred.
The second is the probability of $A$ occurring without any knowledge of whether $B$ has occurred or not. 
If these are equal, then the fact that $B$ has occurred has made no difference to the probability that $A$ has occurred, which is precisely what is meant by *independence*.

The idea of independence can be generalised to more than two events.
For three events, the following definition of *mutual independence* applies, which naturally extends to any number of events.

::: {.definition #MutualIndependence name="Mutual independence"}
Three events $A$, $B$ and $C$ are *mutually independent* if, and only if,
\begin{align*}
     \Pr(A\cap B) & = \Pr(A)\Pr(B).\\
     \Pr(A\cap C) & = \Pr(A)\Pr(C).\\
     \Pr(B\cap C) & = \Pr(B)\Pr(C).\\
     \Pr(A\cap B\cap C) & = \Pr(A) \Pr(B) \Pr(C).
     \end{align*}
:::
Three events can be *pairwise* independent in the sense of Definition  \@ref(def:Independence), but not are not *mutually independent*.

The following theorem concerning independent events is sometimes useful.

:::{.theorem #Independence name="Independent events"}
If $A$ and $B$ are independent events, then

* $A$ and $\overline{B}$ are independent.
* $\overline{A}$ and $B$ are independent.
* $\overline{A}$ and $\overline{B}$ are independent.
:::


### Independence and mutually exclusive events

[Mutually exclusive](def:MutuallyExclusive) and [independent](def:Independence) events sometimes get confused.

The simple events defined by the outcomes in a sample space are mutually exclusive, since only one can occur in any realisation of the random process.
Mutually exclusive events have no common outcomes: for example, achieving both an A grade and a C grade for this course is not possible.
Obtaining one excludes the possibility of the other... so whether one occurs *depen ds* on whetehr the other has occurred.

In contrast, if two events are independent, then whether or not one occurs does not affect the chance of the other happening.
If event $A$ can occur, then $B$ happening will not influence the chance of $A$ happening if they are independent, so it certainly does not exclude the possibility of the other occurring.


::: {.example #Independence name="Independence"}
Independent events refer to events that have no impact on each other.

For example, *how* I get to work tomorrow (walk or ride my bicycle) has no bearing on whether or not I have a busy day at work.
They are independent.

If I decide to walk, I might have a busy day... or I might not.
If I walk, this does *not* exclude the possibility of having a busy day at work; in fact, it has no bearing on whether my day is busy or not.
:::


Confusion between mutual exclusiveness and independence arises sometimes because the sample space is not clearly identified.

Consider a random process involving tossing a coin twice. (POINT TO EARLIER EX)
We have the sample space 
\[
   S_2 = \{(H, H), (H, T), (T, H), (T, T)\}
\]
and these outcomes are mutually exclusive, each with probability 1/4 (using the classical approach).
For example, $\Pr(H, H) = 1/4$.

An alternative way of looking at this random process is to think of repeating the process of tossing a coin once.
For one toss of a coin, the sample space 
\[
   S_1 = \{H, T\}
\]
and $\Pr(H) = 1/2$ is the probability of getting a head on the *first* toss.
This is also the probability of getting a head on the *second* toss.

The events 'getting a head on the first toss' and 'getting a head on the second toss' are **not mutually exclusive**, because both events can occur together: the event $(H, H)$ is an outcome in $S_2$.
Whether or not the outcomes $(H, H)$ occurred *simultaneously*, because the two coins were tossed at the one time, or *sequentially*, in that one coin was tossed twice, is irrelevant.

Our interest is in the *joint* outcomes from two tosses.
It is best to think of getting a head on the 'first' toss as the event
\[
   E_1 = \{ (H, H), (H, T) \}
\]
and of getting a head on the 'second' toss as the event 
\[
   E_2 = \{ (H, H), (H, T) \}
\]
where $E_1$ and $E_2$ are events defined on $S_2$.
This makes it clear that $E_1$ and $E_2$ are not mutually exclusive because $E_1\cap E_2 \ne \emptyset$.

The two events $E_1$ and $E_2$ are *independent* because, regardless of whether or not a head occurs on one of the tosses, the probability of a head occurring on the other is still 1/2... otherwise coins must have memories or can talk to each other...

Seeing that the events are independent provides another way of calculating the probability of the two heads occurring 'together': $1/2\times 1/2 = 1/4$, since the probabilities of independent events multiply.


::: {.example #Mendell name="Mendell"}
Mendell [@BIB:Mendel:hybrids] conducted some famous experiments in genetics.

In one study, Mendel crossed a pure line of round yellow peas with a pure line of wrinkled green peas.
Table \@ref(tab:PeaTable) shows what happened in the *second* generation.
For example, $\Pr(\text{round peas}) = 0.7608$.
Biologically, we would expect about $75$\% to be round; the data appear reasonably sound in this respect.

```{r PeaTable, echo=FALSE}
PeaTable <- array(dim = c(2, 2) )

colnames(PeaTable) <- c("Yellow", 
                        "Green")
rownames(PeaTable) <- c("Rounded", 
                        "Wrinkled")

PeaTable[1, ] <- c(0.5665,
                   0.1942)
PeaTable[2, ] <- c(0.1817,
                   0.0576)
                   
knitr::kable(PeaTable,
             caption = "The second generation results from Mendel's experiment, crossing a pure line of round yellow peas with a pure line of wrinkled green peas")

```

Is the type of pea (round or wrinkled) independent of the colour?
That is, if the pea is round, does it have any effect in the colour of the pea?

To test independence, one form of the formula is $\Pr(\text{round} \mid \text{yellow}) = \Pr(\text{round})$.
In other words, the fact that the pea is yellow does not affect that probability that the pea is round.
From Table \@ref(tab:PeaTable):

\begin{align*}
   \Pr(\text{round}) &= 0.7608,\\
   \Pr(\text{round} \mid \text{yellow}) &= 0.5665/0.7482 = 0.757.
\end{align*}

These two probabilities are very close.
Given that the data in the Table is only a *sample* (from the population of all peas), it seems reasonable that the colour and shape of the peas are independent.
:::


### Partitioning the sample space {#SSPartitions}

The concepts introduced in this section allow us to determine the probability of an event using the *event-decomposition approach*, which we now discuss.
To do so, express the event of interest, say event $A$, as a composition (unions and/or intersections), then apply the laws of probability to find $\Pr(A)$.
We first need some definitions.

::: {.definition #Partitioning name="Partitioning"}
The events $B_1, B_2, \ldots , B_k$ are said to represent a *partition* of the sample space $S$ if

1. $B_i \cap B_j = \emptyset$ for all $i \neq j$.
2. $B_1 \cup B_2 \cup \ldots \cup B_k = S$.
3. $\Pr(B_i) > 0$ for all $i$.
:::
In simple terms, these state:

1. The events are mutually exclusive (have no common elements).
2. The events consider together comprise the entire sample space (that is, no outcome is left out).
3. No event has zero probability of occurring.

The second of these is often referred to as the events being *exhaustive*.

The implication is that when the random process is performed, one and only one of the events $B_i$ ($i = 1, \ldots, k)$ occurs.

We use this concept in the following theorem.

:::{.theorem #TotalProb name="Theorem of total probability"}
Let $A$ be an event in $S$ and $\{B_1, B_2, \ldots , B_k\}$ a partition of $S$.
Then
\begin{align*}
   \Pr(A) 
   &= \Pr(A \mid B_1) \Pr(B_1) + \Pr(A \mid B_2)\Pr(B_2) + {}\\
   &\qquad \ldots +\Pr(A \mid B_k)\Pr(B_k).
\end{align*}
:::

:::{.proof}
The proof follows from writing $A = (A\cap B_1) \cup (A\cap B_2) \cup \ldots \cup (A\cap B_k)$, where the events on the RHS are mutually exclusive.
The [third axiom](#def:ThreeAxioms) of probability together with the multiplication rule yield the result.
:::


### Bayes' theorem {#BayesTheorem}

If an event is known to have occurred, and the sample space is partitioned, a result known as *Bayes' theorem* enables us to determine the probabilities associated with each of the partitioned events.


:::{.theorem #Bayes name="Bayes' theorem"}
Let $A$ be an event in $S$ such that $\Pr(A) > 0$ and $\{ B_1, B_2, \ldots , B_k\}$ a partition of $S$.
Then
\[
   \Pr(B_i \mid A) = \frac{\Pr(B_i) \Pr(A \mid B_i)}
                          {\displaystyle \sum_{j = 1}^k \Pr(B_j)\Pr(A \mid B_j)}
\]
for $i = 1, 2, \dots, k$.
:::

:::{.proof}
This is a direct application of Definition \@ref(def:ConditionalProb), the multiplication rule and Theorem \@ref(thm:TotalProb).
:::

Bayes' theorem has many uses in many disciplines, as it uses conditional probabilities that are easy to find or estimate ($\Pr(A \mid B_j$), to compute a probability that is *not* easy to find or estimate ($\Pr(B_i \mid A)$.

The theorem is the basis of a branch of statistics known as *Bayesian statistics* which involves using pre-existing evidence in drawing conclusions from data.


::: {.example #Cancer name="Cancer"}
BETTER EG??

The following example about cervical cancer is taken from data collected by Graham and Shotz~\cite{BIB:Graham:cancer}.

In the study, women *known* to have cervical cancer and women known to *not have* cervical cancer are asked about their age at first pregnancy.
Then, $\Pr(\text{age at first pregnancy} \mid \text{get cervical cancer})$ is easy to estimate, since the presence or absence of cervical cancer is 'given'.

But a more useful probability might be $\Pr(\text{get cervical cancer} \mid \text{age at first pregnancy})$.
For convenience, define $CC$ to be the event that a woman gets cervical cancer, and $Y$ be the event that the woman was under 25 at first pregnancy.

From the study, the following probabilities were obtained:
\begin{align*}
   \Pr(Y \mid CC) 
   &= 0.857\\
   \Pr(Y \mid C \overline{C}) 
   &= 0.640\\
   \Pr(CC) 
   &= 0.134
\end{align*}
(Do not be alarmed by these figures; they are gathered only from women aged 50 to 59 in Buffalo, New York who had at least one child.)

From this information, we wish to compute, for example $\Pr(CC \mid Y)$; that is, 'reverse' the probability.
This is more useful, since most of the time the age of a woman at first pregnancy is known (or 'given'), and the chance of getting cervical cancer IN THE FURURE?? is of interest.

To do this, we use Bayes' theorem.
First, every woman in the study either has or does not have cervical cancer (OR WILL GET??).

This is a *partition* of the sample space: the sample space has been split into two groups that encompass the *whole* sample space.
In each group, some women will have had their first pregnancy under 25, and some when older than 25.
See the top figure in Figure~\ref{FG:prob:bayes:ccancer}.

\begin{figure}
\begin{center}
%\includegraphics[scale=0.7]{../pics/prob/bayesvd.eps}
\caption{The Venn diagram for Example~\ref{EG:prob:bayes:ccancer}.
The top diagram shows the partitioning of the sample space on the basis
of having or not having cervical cancer (CC).
The middle diagram shows those women *with* cervical cancer who were under 25
at first pregnancy;
the bottom diagram then adds those women *without* cervical cancer who were under 25
at first pregnancy.
Combining the two pieces gives the total probability that a woman in the
study was under 25 at first pregnancy as $0.66904$.
(Note that the diagram has not been drawn to scale.)}
\label{FG:prob:bayes:ccancer}
\end{center}
\end{figure}

The situation may be clearer using a *tree diagram*; see Figure~\ref{FG:prob:bayes:ccancer:tree}.
In either case, Bayes' theorem can then be used to determine
\begin{align*}
   \Pr(Y \cap CC)
   &= \Pr(Y \mid  CC) \times \Pr(CC)\\
   &= 0.857 \times 0.134 = 0.1148.
\end{align*}
Likewise
\begin{align*}
   \Pr(Y \cap \overline{CC})
   &= \Pr(Y \mid  \overline{CC}) \times \Pr(\overline{CC})\\
   &= 0.640 \times 0.866 = 0.5542.
\end{align*}
Then the probability of a woman in the study being under 25 at first pregnancy is
\begin{align*}
   \Pr(Y)
   &= \Pr(Y\cap CC) + \Pr(Y\cap \overline{CC})\\
   &= 0.1148 + 0.5542 = 0.6690.
\end{align*}

\begin{figure}
\begin{center}
\setlength{\unitlength}{0.7mm}
\begin{picture}(100,100)
% Lines
\put(0,50){\line(1,1){20}}
\put(0,50){\line(1,-1){20}}
\put(40,70){\line(2,1){30}}
\put(40,70){\line(2,-1){30}}
\put(40,30){\line(2,1){30}}
\put(40,30){\line(2,-1){30}}
% Labels/text
\put(30,100){\makebox(0,0){\small Cervical}}
\put(30,94){\makebox(0,0){\small cancer}}
\put(85,100){\makebox(0,0){\small Age at}}
\put(85,94){\makebox(0,0){\small first pregnancy}}
\put(30,70){\makebox(0,0){\small $CC$}}
\put(30,30){\makebox(0,0){\small $CC'$}}
\put(75,85){\makebox(0,0)[l]{\small Aged $\le 25$}}
\put(75,55){\makebox(0,0)[l]{\small Aged $>25$}}
\put(75,45){\makebox(0,0)[l]{\small Aged $\le 25$}}
\put(75,15){\makebox(0,0)[l]{\small Aged $>25$}}
% Probs
\put(7,67){\makebox(0,0){\small 0.134}}
\put(7,33){\makebox(0,0){\small 0.866}}
\put(55,83){\makebox(0,0){\small 0.857}}
\put(55,57){\makebox(0,0){\small 0.143}}
\put(55,43){\makebox(0,0){\small 0.640}}
\put(55,17){\makebox(0,0){\small 0.360}}
\end{picture}
\caption{A tree diagram for Example~\ref{EG:prob:bayes:ccancer}.}
\label{FG:prob:bayes:ccancer:tree}
\end{center}
\end{figure}


Then, using Bayes' theorem again,
\begin{align*}
   \Pr(CC\mid Y)
   &= \frac{\Pr(CC\cap Y)}{\Pr(Y)}\\
   &= \frac{0.1148}{0.6690} = 0.1716.
\end{align*}
:::



## Computing probabilities {#SC:compprobs}

A tree diagram (see Figure~\ref{FG:prob:bayes:ccancer:tree}) is just one of several tools that can assist in calculating and manipulating probabilities.
Typically there is more than one way of arriving at a correct answer and as experience grows you will become adept at selecting the best method for a particular problem.
Some examples are given below to illustrate the various approaches.

WE JUST USED A TREE BEFORE. REARRANGE ORDER??


### Tree diagrams

Tree diagrams are useful when an experiment can be seen, or thought of, as occurring in steps or stages.


CHANGE THIS EXAMPLE, it is ODD

::: {.example #MathsStudent name="Mathematics students"}
In an article by Anderson~\cite{BIB:Anderson:gender}, 124 first year Honours mathematics students at a university in the UK were asked the question:

> The point $z$ lies in the fourth quadrant (i.e., $-\pi/2 < \text{arg}(z) < 0$) of the complex plane.
> $z^*$ denotes the complex conjugate of $z$.
> Prove or disprove $\text{arg}(z + z^*) = 0$.

The expectation was that most should have been able to correctly answer the question.
The data from the last table on page~499 of the article has been used to construct a tree diagram,
where the first stage or step can be considered the gender of the person to whom the test is given, and the next step is how the given person answers the question; see Figure~\ref{FG:prob:mathstree}.

\begin{figure}
\begin{center}
\setlength{\unitlength}{0.7mm}
\begin{picture}(130,100)
% Lines
\put(0,50){\line(1,1){20}}
\put(0,50){\line(1,-1){20}}
\put(40,70){\line(2,1){30}}
\put(40,70){\line(2,-1){30}}
\put(40,70){\line(1,0){30}}
\put(40,30){\line(2,1){30}}
\put(40,30){\line(2,-1){30}}
\put(40,30){\line(1,0){30}}
% Labels/text
\put(30,70){\makebox(0,0){\small Male}}
\put(30,30){\makebox(0,0){\small Female}}
\put(75,85){\makebox(0,0)[l]{\small $0.76\times0.82=0.6232$}}
\put(125,85){\makebox(0,0)[l]{\small Correct}}
\put(75,70){\makebox(0,0)[l]{\small $0.76\times 0.11= 0.0836$}}
\put(125,70){\makebox(0,0)[l]{\small Not answered}}
\put(75,55){\makebox(0,0)[l]{\small $0.76\times0.07=0.0532$}}
\put(125,55){\makebox(0,0)[l]{\small Incorrect}}
\put(75,45){\makebox(0,0)[l]{\small $0.24\times 0.70=0.1680$}}
\put(125,45){\makebox(0,0)[l]{\small Correct}}
\put(75,30){\makebox(0,0)[l]{\small $0.24\times0.17 = 0.0408$}}
\put(125,30){\makebox(0,0)[l]{\small Not answered}}
\put(75,15){\makebox(0,0)[l]{\small $0.24\times0.13 = 0.0312$}}
\put(125,15){\makebox(0,0)[l]{\small Incorrect}}
\put(30,100){\makebox(0,0){\small \textbf{Gender}}}
\put(75,100){\makebox(0,0)[l]{\small \textbf{Probability}}}
\put(125,100){\makebox(0,0)[l]{\small \textbf{Answer}}}

% Probs
\put(7,67){\makebox(0,0){\small 0.76}}
\put(7,33){\makebox(0,0){\small 0.24}}
\put(57,83){\makebox(0,0){\small 0.82}}
\put(60,73){\makebox(0,0){\small 0.11}}
\put(57,57){\makebox(0,0){\small 0.07}}
\put(57,43){\makebox(0,0){\small 0.70}}
\put(60,33){\makebox(0,0){\small 0.17}}
\put(57,17){\makebox(0,0){\small 0.13}}
\end{picture}
%\includegraphics[scale=0.50]{../pics/prob/mathstree.eps}
\caption{The tree diagram for the data in
Example~\ref{EG:prob:computing:tree}.}
\label{FG:prob:mathstree}
\end{center}
\end{figure}


So, for example, $\Pr(\text{correct} \mid \text{male}) = 0.82$, and $\Pr(\text{not answered} \mid \text{female}) = 0.17$.
Note that the probabilities are usually given *on* the branches and the events at the *end* of the branches.
Apart from the initial probabilities, the probabilities given are *conditional*, depending on which branch the probabilities are placed.

Now, the probability $\Pr(\text{male} \mid \text{correct})$ can be computed as
$(0.76 \times 0.82)/(0.76 \times 0.82 + 0.24\times 0.70) = 0.788$.
:::


### Tables

When there are two variables of interest, tables are a convenient way of summarizing the information.
Although tables can be used to represent experiments using conditional probabilities, it is usual to use the table to represent the whole sample space.


AGAIN, GET BETTER EXAMPLE!!!

::: {.example #PublicService name="Public service"}
The following table summarizes the number of men and women in the Senior Executive Service of the Australian Public Service in 1994.
The data is from Townsend and McLennan~\cite{BIB:Townsend:women}.
Band~1 is the lowest of the three Bands.


\begin{center}
\begin{tabular}{lcc}
 & \textbf{Women} & \textbf{Men} \\
\hline
Band~1 & 231 & 1031 \\
Band~2 & 47 & 332 \\
Band~3 & 7 & 79
\\
\hline
\textbf{Total} & 285 & 1442
\end{tabular}
\end{center}

The counts can be turned into probabilities (by dividing by the total number, $285 + 1442 = 1727$), or left as they are.

Then, for example, the probability that a randomly chosen Senior Executive is female is $285/1727 = 0.16$.
Likewise, the probability that a randomly chosen male Senior Executive is higher than Band~1 is $(332 + 79)/1442 = 0.29$.
:::



### Venn diagrams

Venn diagrams can be useful when there are two events, sometimes three, but become unworkable for more than three.
Often, tables can be used to better represent situations that have been shown in Venn diagrams.


AGAIN: NEW EXAMPLE!


::: {.example #LabourForce name="Labour force"}
Townsend and McLennan~\cite[p~84]{BIB:Townsend:women} report on the Australian Labour Force in 1995.
They infer that the proportion of the work force that is male is $0.568$; the proportion that is under~25 is $0.218$; and that $0.113$ are males *and* under 25.
This information can be used to construct Venn diagrams to summarise the sample space as there are two variables, gender (either Male or Female) and age (either under 25, or 25 and over).
See Figure~\ref{FG:prob:labourvd}.
The same information can be compiled into a Table; see Table~\ref{TB:prob:labourtab}.

\begin{figure}
\begin{center}
%\includegraphics[scale=0.65]{../pics/prob/labourvd.eps}
\caption{The Venn diagram for Example~\ref{EG:prob:Venn}.}
\label{FG:prob:labourvd}
\end{center}
\end{figure}

What proportion of the labour force were males over 25 in 1995?
This can be answered using numerous methods: The Venn diagram, the table, or formulae.
The answer can be taken directly from the Table to give $0.455$.
Using the Venn diagram, the Male set consists of $0.133$ that belong in the Under 25 set, so the remainder must be over 25, so the probability is again $0.455$.

To use the formula, define $M$ to be Male, and $Y$ to be Under 25.
Then, $\Pr(M) = 0.568$, $\Pr(Y) = 0.218$ and $\Pr(M \cap Y) = 0.113$.
Now, $\Pr(M \cap \overline{Y}) + \Pr(M\cap Y) = \Pr)M)$ (the Theorem of Total Probability), so that $\Pr(M \cap \overline{Y}) = 0.568 - 0.113 = 0.455$.


\begin{table}
\begin{center}
\begin{tabular}{cccc}
& \multicolumn{2}{c}{\textbf{Gender}} & \\
\cline{2-3}
\textbf{Age} & Male & Female & Total \\
\hline
$<25$ & \textbf{0.113} & 0.104 & \textbf{0.218} \\
$\ge 25$ & 0.455 & 0.327 & 0.782 \\
\hline
Total & \textbf{0.568} & 0.432 & 1.000
\end{tabular}
\caption{The table for Example~\ref{EG:prob:Venn}.
The numbers in bold are given with the data;
the rest were deduced.}
\label{TB:prob:labourtab}
\end{center}
\end{table}

Try the three methods to compute the proportion of females over 25.
:::


### Sample spaces

Sometimes the most convenient way to compute probabilities is to list the sample space.
This only works for small discrete sample spaces, and works best when each of the outcomes in the sample space are equally likely.

::: {.example #TwoDice name="Rolling two dice"}
Consider rolling two standard dice and noting the *sum* of the numbers shown.
The sample space is listed in Table \@ref(tab:TwoDice).


```{r TwoDice, echo=FALSE}
Die1 <- 1:6
Die2 <- 1:6

DieSum <- Die1 %o% Die2

rownames(DieSum) <- paste("Die 1:", 1:6)
colnames(DieSum) <- paste("Die 2:", 1:6)

knitr::kable(DieSum,
             caption = "The sum of rolling two dice")
```

\begin{center}
\begin{tabular}{ccccccc}
 & \multicolumn{6}{c}{\textbf{Die B}}
  \\
 \cline{2-7}
\textbf{Die A} & {1} & {2} & {3} & {4} & {5} & {6}\\
\hline
{1} & 2 & 3 & 4 & 5 & 6 & 7 \\
{2} & 3 & 4 & 5 & 6 & 7 & 8 \\
{3} & 4 & 5 & 6 & 7 & 8 & 9 \\
{4} & 5 & 6 & 7 & 8 & 9 & 10 \\
{5} & 6 & 7 & 8 & 9 & 10 & 11 \\
{6} & 7 & 8 & 9 & 10 & 11 & 12
\end{tabular}
\end{center}

Then, $\Pr(\text{sum is {7}}) = 6/36$ is found by counting the equally likely outcomes that sum to seven.
:::

When the number of elements in the sample space is large, principles and formulae exist which facilitate counting.
Some of these are described in the next section.


## Counting techniques {#Counting}

The number of elements in a set is often large, and a complete enumeration of the set is unnecessary if all we want to do is to count the number of elements in it.


### Multiplication principle

If we have $m$ ways to perform act $A$ and if, for each of these, there are $n$ ways to perform act $B$, then there are $m\times n$ ways to perform the acts $A$ *and* $B$. 
This is called the *multiplication principle*.

:::{.definition #MultiplicationPrinciple name="Multiplication principle"}
With $m$ elements $a_1, a_2, \ldots , a_m$ and $n$ elements $b_1, b_2, \ldots, b_n$ it is possible to form $mn$ pairs containing one element from each group.
:::

The principle can be extended to any number of sets.
For example: For three sets of elements $a_1, a_2, \ldots , a_m$; $b_1, b_2, \ldots , b_n$ and $c_1, c_2, \ldots , c_p$, the number of distinct triplets containing one element from each set is equal to $mnp$.


### Permutations

Another important counting problem deals with different permutations of a finite set.
The word *permutation* in this context is simply an ordering of the set.

Suppose a set has $n$ elements. 
To order these, we must first choose the first element of the ordering, which can be done in $n$ different ways.
The second element must then be chosen, which can be done in $(n - 1)$ ways (since it cannot be the same as the first).
There are then $(n - 2)$ ways for the third, and so on. 

We find (using the multiplication principle) that there are $n(n - 1)(n - 2)\ldots 2 \times 1$ different ways to order the $n$ elements. 
This is denoted by $n!$ and called 'n factorial':
\[
   n! = n(n - 1)(n - 2) \ldots (2)(1)
\]
where $n\geq 1$, and we define $0! = 1$.

EXPLAIN WHY 0! =  in a box??


In some cases, it is necessary to know the number of ways in which the first $r$ elements of an ordering may be chosen. 

For this problem, the first element in the ordering may be chosen in $n$ different ways, the second in $(n -1)$ ways, the third in $(n - 2)$ ways, and so on... down to the $rth$, which may be chosen in $(n -r + 1)$ ways. 

This number is denoted by $^nP_r$, and we write
\[
   ^nP_r = n(n-1)(n-2)\ldots (n - r + 1) = \frac{n!}{(n - r)!}.
\]
This expression is referred to as *the number of permutations of $r$ elements from a set with $n$ elements*.


### Combinations

In some cases, order is not important when choosing a subset. 
A *combination* of $r$ elements from a set $S$ is a subset of $S$ with exactly $r$ elements.

Now we need to find the number of combinations of $r$ elements from a set with $n$ distinct elements, and we will denote it by $^nC_r$.
The number of permutations is given by~(\ref{EQN:perms}), but of course the number of combinations must be smaller, since each combination gives rise to several permutations.
In fact, each combination of $r$ elements can be ordered in $r!$ different ways, and so gives rise to $r!$ permutations.
Hence, the number of permutations must be $r!$ times the number of combinations.
We have then,
\[
   ^nC_r = \frac{n(n - 1)\ldots (n - r + 1)}{r!} = \frac{n!}{(n - r)!r!}
\]
This is often written as ${n \choose r}$.


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The difference between *permutations* and *combinations* is important!

With permutations, the *selection order* is important, whereas *selection order is not important* with combinations.

In addition, both formulae apply when *there is no replacement* of the items.
:::


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Notation for combinations and permutations is varied.

Some notation for permutations include $nPr$, $^nP_r$, $P_n^r$ or $P(n,r)$.

Notation for combinations include $nCr$, $^nC_r$, $C_n^r$, ${n\choose r}$ or $C(n,r)$.
:::


::: {.example #ChooseDigits name="Selecting digits"}
Consider the set of integers ${1, 3, 5, 7}$.
Choose two numbers, *without replacement*, and call the first $a$ and the second $b$.
If we then compute $a\times b$, there are $^4C_2 = 6$ possible answers since the *selection order is not important* (e.g., $3 \times 7$ gives the *same* answer as $7 \times 3$).

However, if we compute $a\div b$, there are $^4P_2 = 12$ possible answers, since the *selection order is important* (e.g., $3 \div 7$ gives a *different* answer than $7 \div 3$).
:::


::: {.example #ChooseMice name="Choosing mice"}
Consider a biologist planning an experiment using *mdx* mice (mice with a strain of Duchene muscular dystrophy).

Measurements of heart weights need to be taken at $3$ weeks, $6$ weeks and $12$ weeks.
There are twenty mice in the experiment.
To take the measurements, the mice need to be sacrificed.

If the biologist needs to select six mice at $3$ weeks, how many ways are there to select the mice?

Since the mice cannot be replaced (they are sacrificed), and the order is not important, there are
\[
   {20\choose 3} = \frac{20!}{3!\, 17!} = 1140
\]
ways of selecting the sample.
:::





### Sampling with or without replacement

The definitions of $^nP_r$ and $^nC_r$ above refer to the situation where the choices at successive stages are made *without replacement* or *without repetition*. 
That is, after an element is chosen, it cannot be select again.

We will now consider:

1. the number of ordered selections,
2. the number of unordered selections,

when $r$ elements are chosen from $n$ *with replacement* or *with repetition*.

The number of *ordered selections* of $r$ objects chosen from $n$ *with replacement* is $n^r$.
The first object can be selected in $n$ ways, the second can be selected in $n$ ways, etc., and by the multiplication principle, we have $n^r$.

The remaining case of the number of ways $r$ objects can be chosen from $n$ *with replacement* and *without regard to order* is somewhat more difficult and won't be attempted here.
(The number of ways is actually ${n + r - 1 \choose r}$.)


### Binomial theorem

The binomial expansion
\[
  (a + b)^n = \sum^{n}_{r = 0} {n \choose r} a^r b^{n - r}
\]
for $n$ a positive integer, is often referred to as the *Binomial Theorem* and hence ${n \choose r}$ is referred to as a binomial coefficient.

This series, and associated properties, is sometimes useful in counting.
Some of these properties are stated below.

1. ${n \choose r} = {n \choose n-r}$, for $r = 0, 1, \ldots, n$.
2. As a special case of the above, ${n \choose 0} = 1 = {n \choose n}$.
3. $\sum_{r = 0}^n {n \choose r} = 2^n$.




## Introducing statistical computing

Computers and computer packages are essential tools in the application of statistics to real problems. 
In this book, you will be introduced to the statistical package **R**. 
It will be used to illustrate various concepts and should help you understand the theory.

In particular, **R** will be used to verify theoretical results obtained.
To do this, a technique called *computer simulation* will be used. 

Simulation can also be used to solve problems for which it may be difficult (or impossible) to obtain a theoretical result. 
Sometimes these numerical solutions to intractable analytical problems is termed *Monte Carlo simulation*.
That term was coined at Los Almos during construction of the bomb in 1943 when computers were in their infancy.
NEED THAT LAT BIT? IS IT EVEN TRUE? CITE?


### The gameshow problem {#Gameshow}

USE "MONTY HALL"

A gameshow contestant is told there is a car behind one of three doors, and a goat behind each of the other doors. 
The contestant is asked to select a door. 

The host of the show (whoknows where the car is) now opens one of the doors *not* selected by the contestant, and reveals a goat. 
The host now gives the contestant the choice of retaining the door chosen first or switching and choosing the the other (unopened) door. 
What is the contestants best strategy?

1. Always retain the first choice.
2. Always change and select the other door.
3. Choose either unopened door at random.


Only a brief outline of the method is given here. 
A more complete solution is given later (see Exercise~\ref{QN:gameshow}).

1. Generate a random sequence of length 1000 consisting of the integers 1,2 and 3. 
  (These numbers represent the door that the car is behind on each of 1000 nights.)
2. Generate another such sequence to represent the contestants *first* choice on each of the 100 nights.
3. The number of times the numbers in the two columns *do* agree represents the number of times the contestant will win *if the contestant doesn't change doors*.
   If the numbers in the two columns *don't* agree then the contestant will win *only if the contestant decides to change doors*.


For the 1000 nights simulated, contestants would have won the car 30 times if they retained their first choice which means they would have won 70 times if they had changed. 
(Does this agree with your intuition?) 
This implies (correctly!) that the best strategy is to change. 
You might like to try doing the simulation for yourself.

(The correct theoretical probability of winning if you retain the original door is 1/3 but increases to 2/3 if you change. 
This is not a trivial theoretical problem!)  
We obtained a reasonable estimate of these probabilities from the simulation, 30/100 and 70/100. 
These estimates could be expected to improve for larger sample sizes.)

```{r echo=TRUE}
set.seed(93671) # For reproducability
CarDoor <- sample(1:3, 
                  size = 1000,
                  replace = TRUE)
FirstChoice <- sample(1:3,
                  size = 1000,
                  replace = TRUE)

WinFirstChoice <- sum( CarDoor == FirstChoice)
WinSecondChoice <- sum( CarDoor != FirstChoice)

c(WinFirstChoice, WinSecondChoice) / 1000
```

## Looking ahead

The study of probability is basic to the study of modern statistics.
Consider the following example, the data coming from the Journal of Applied Physiology (1984), 1020--1023.
(Source: Devore, Jay and Peck, Roxy (1993){\em Statistics: The Exploration
and Analysis of Data},(2nd ed).)


### The experiment {#CAO}

REEXPRESS AS HTEST

Chronic airflow obstruction (CAO) severely limits the exercise capability of sufferers. 
Maximum exercise ventilation for each of 21 CAO patients was determined under two different experimental conditions. 
Fifteen patients recorded their best ventilation under experimental Condition 1.

Does this mean that one of the experimental condition gives better results than the other?

We might be tempted to say that *clearly* experimental Condition 1 is better since 15 of 21 did better. 
What is wrong with this reasoning? 

Let us suppose that a patient actually performs equally well under either experimental condition. 
Then it is a matter of chance under which experimental condition a patient is recorded as performing best.
The original question can now be restated as:

> Is it likely that 15 (or more) CAO patients will appear to do better under experimental Condition 1 (or 2), if in fact there is no difference between the effect of the two?}

Let us tackle the problem experimentally. 
The problem above is similar to that of tossing a coin: we could let a head represent a patient doing better under Condition 1, a tail as better under Condition 2. 
Tossing the coin 21 times then gives us one possible outcome for our experiment. 

If we repeat this a large number of times, then we can observe how many times we get 15 or more *patients* doing better on Condition 1 (or Condition 2) just by chance. 
(**Note**: If there is really no difference the results could go in either direction, not just the direction observed in the ONE experiment described above.) 
Suppose we carried out the experiment 1000 times, we should be able to make some definite conclusion. 
However, it is of course not really feasible to actually throw a coin this number of times.
We get around this problem by simulating the experiment on a computer using R. 

We let 0 represent a patient doing better on experimental Condition 1, and by a 1 a patient doing better on Condition 2. 
We can then generate a sequence of 1's and 0's representing the results of 21 patients. 
This can be repeated 1000 times.
The results of one such *simulation* experiment are given below:

FIX!!!!


```{r echo=TRUE}
set.seed(416893) # For reproducibility

numSimulations <- 1000 # The number of simulations
recordResults <- array( dim = numSimulations)

for (i in 1:1000){   # Do 1000 simulations, of:
   Results <- rbinom(21,       # 21 patients
                     size = 1, # Two outcomes: 0 (Cond 1 better) and 1 (Cond 2 better)
                     p = 0.5)
   recordResults[i] <- sum(Results)   
}

table(recordResults)
```

Let $X$ represent the number of times (out of 21) that CAO patients under Condition 1 do better than under Condition 2.
In Table \@ref(tab:CAOTable), the `Count` column then gives the number of trials (out of 1000) in which there were exactly $x$ CAO patients doing better under Condition 1.
This is given as a percentage in the third column.

```{r CAOTable, echo=FALSE}
tabResults <- table(recordResults)

CAOTable <- array( dim = c(7, 7))

colnames(CAOTable) <- c("Number",
                        "Count",
                        "Percentage",
                        " ", # Spacer
                        "Number",
                        "Count",
                        "Percentage")
                        
CAOTable[, 1] <- names(tabResults)[1:7]
CAOTable[, 5] <- names(tabResults)[8:14]

CAOTable[, 2] <- tabResults[1:7]
CAOTable[, 6] <- tabResults[8:14]

CAOTable[, 3] <- round( as.numeric(CAOTable[, 2]) / numSimulations * 100, 1)
CAOTable[, 7] <- round( as.numeric(CAOTable[, 6]) / numSimulations * 100, 1)

knitr::kable(CAOTable,
             caption = "The results of the CAO simulation")
                       
```
We can now make an informed answer to the original question.

Notice that $29 + 9 = 38$ (or 0.038) of the result in 15 or more CAO patients doing better on Condition 1, while $22 + 10 + 3 + 2 = 37$ (or 0.037) of the experiments result in 6 or fewer of the CAO patients doing better on Condition 2.
That is, $38 + 37 = 75$ out of the 1000 experiments resulted in an outcome as extreme as the one observed in the actual experiment, an estimated probability of 0.075 that a result this extreme would occur purely by chance if there is in fact NO DIFFERENCE in effect of the two experimental conditions.

If the probability is above 0.05 (that is 5\%), we usually say the case of a difference in effect has not been shown on the grounds that we can't be sure it has not occurred by chance alone. 
(5\% would mean we expect it to occur by chance 1 out of 20 times, a rate which is not unreasonable to expect to happen.)

Our conclusion here would be that there is insufficient evidence to conclude a difference in effect of the two experimental conditions.


**Comments**

1. The above conclusion relies on estimating an appropriate probability.
2. The calculations involved using a computer to simulate the problem.
3. Very little theoretical knowledge of probability was necessary although we did assume that the probability of getting a head on each toss of a fair coin was 0.5.
4. In this case if we had known more about probability modelling simulation would not have been necessary, as a satisfactory theoretical model can be found for this problem. 
   (This could then be applied in many other similar situations.)
   A knowledge of probability theory would have made our task much simpler here.
5. One of the aims in this course is to provide the tools for you to model different experimental situations.
6. **Final note:** Simulation is a very powerful tool. 
   In many complex situations, it may either provide the only method of proceeding or may be used to gain insight into the problem that allows some progress to be made by more conventional means. 
   It is also used to verify theoretical results.


We will return to this example later when we have the tools to find the probability model.






## Self-assessment exercises


:::{.exercise}
Given $\Pr(A) = 0.34$, $\Pr(B) = 0.5$ and $\Pr(A\cap B) = 0.15$, find

1. $\Pr(A\cup B)$.
2. $\Pr(\overline{A}\cap B)$.
3. $\Pr(\overline{A} \cup \overline{B})$.
4. $\Pr(A \mid B)$.
5. Are events $A$ and $B$ independent?
:::

\begin{answer}
You can use Venn diagrams to make the formulae clearer.
\begin{enumerate}
\item $\Pr{A\cup B}=\Pr{A} + \Pr{B} - \Pr{A\cap B} = 0.56$.
\item $\Pr{\overline{A}\cap B} = \Pr{B} - \Pr{A\cap B} = 0.26$.
\item $\Pr{\overline{A}\cup\overline{B}} = \Pr{\overline{A}} +
\Pr{\overline{B}} - \Pr{\overline{A}\cap\overline{B}} = 0.76$ or
$1-\Pr{A\cap B} = 0.76$.
\item $\Pr{A\mid B} = \Pr{A \cap B}/\Pr{B} =
0.24/0.50 = 0.48$.
\item Since $\Pr{A}\times \Pr{B} = 0.3\times
0.5 = 0.15\ne \Pr{A\cap B}$, $A$ and $B$ are not independent
events.
\end{enumerate}
\end{answer}


:::{.exercise]
A computer programmer is running a subroutine to solve the general quadratic equation $y = ax^2 + bx + c = 0$. 
This is an 'experiment' of choosing values for the constants $a$, $b$ and $c$ satisfying the quadratic equation.

1. Define the sample space $S$ for the experiment.
2. Define the event $A$: 'the equation has two equal real roots'.
:::

\begin{answer}
\begin{enumerate}
\item All real numbers are possible values for $a$, $b$ and $c$;
hence $S=\{ (a,b,c)\mid -\infty<a<\infty, -\infty<b<\infty,
-\infty<c<\infty\}$.
\item The solutions to a quadratic equation
are given by
\[
   x = \frac{-b \pm \sqrt{b^2 -4ac} }{2a}.
\]
For two equal roots, $b^2-4ac=0$. So event $A$ is defined as $A=\{
(a,b,c)\mid b^2-4ac=0\}$.
\end{enumerate}
\end{answer}




