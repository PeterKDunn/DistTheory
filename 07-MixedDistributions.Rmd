# Mixed distributions {#MixedDistributions}

::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
On completion of this module, you should be able to:

* recognise mixed random variables.
* ??? recognise the probability functions and underlying parameters of mixed variables.
* ??? know the basic properties of the above mixed distributions.
* ??? apply these distributions as appropriate to problem solving.
:::


## Introduction

Mixed random variables commonly occur, but are not often studied.
Mixed random variables appear in diverse applications such as insurance, agriculture, climatology, fishing, etc.

In most practical cases, a mixed random variable\ $X$ has a discrete probability mass at $X = 0$, and then are continuous for $X > 0$; this is the only type of mixed random variable we consider (though extensions to discrete masses occurring for other values of the random variable are often (but not always) similar).
For example:

* When modelling insurance, the zero probability corresponds to portfolios with zero claims; however, when claims are made, the total claim amount has a continuous distribution.
* When modelling rainfall, the zero probability corresponds to receiving zero rainfall; however, when rain does fall, the total rainfall recorded has a continuous distribution.
* When modelling fish catch, the zero probability corresponds to catching zero fish; however, when fish are caught, the mass of fish catch has a continuous distribution.

Continuous data with a discrete probability at zero can be modelled in various ways, depending on how the discrete probability at $X = 0$ is incorporated.
Three approaches are considered in this chapter.

*Censored models*\index{Censored models} (Sect.\ \@ref(CensoredModels)) assume the existence of an underlying *latent variable*, defined for all real values.\index{Latent variable}
However, values of the latent variable below zero cannot be observed (called *censoring*\index{Censoring}).
All the probabilities corresponding to values of the latent variable below zero are accumulated, and assigned to the probability of observing a value of zero.
The value of $X = 0$ represents *censored observations* of the latent variable.

*Hurdle models*\index{Hurdle models} (Sect.\ \@ref(HurdleModels)) treat the zeros as emerging from a two-step process.
Step one is a binary process, that models whether the event of interest (i.e., an insurance claim is made; rainfall is recorded; fish are caught) occurs.
Step two is a model for the continuous data of interest, conditional on the event of interest occurring.

Compound *Poisson-gamma models*\index{Compound Poisson-gamma models} (Sect.\ \@ref(TweedieModels)) combine the discrete and continuous components in a single probability model.
Unlike the hurdle model, the discrete and continuous parts are not modelled separately; the entire distribution is modelled using a single probability model specific for modeling mixed random variables.


## Censored model {#CensoredModels}

### Definitions {#CensoredModelsDefinitions}

\index{Censored models|(}
Censored models assume the existence of an unobserved *latent variable*,\index{Latent variable} say\ $z$ such that $z\in\mathbb{R}$, with probability function $f_Z(z)$.
Values of\ $Z$ below some threshold, say $z^*$ (commonly, $z^* = 0$), are not directly observed.
Instead, $X = \text{max}(Z^*, Z)$ is observed; that is, values of\ $Z$ less than\ $z^*$ are recorded as\ $z^*$.


:::{.example #TobitAlcoholSpend name="Latent variables and censoring"}
Consider a latent variable defined as the 'desire to purchase alcohol'\ $Z$, where the value $Z = 0$ represents indifference to purchasing alcohol.
Some people may have a *very* strong aversion to purchasing alcohol, so that the value of\ $Z$ is large and negative.
Some people may have a *mild* aversion to purchasing alcohol, so that the value of\ $Z$ is small but still negative.
In both cases, however, an aversion to purchasing alcohol is present, and no alcohol is purchased.

The observed variable of interest could be\ $Y$, the average weekly spend on buying alcohol in dollars.
When $Z \le 0$, we observe $X = 0$; however, when $Z > 0$, a continuous amount is spent on purchasing alcohol (Fig.\ \@ref(fig:AlcoholSpend)).
:::

```{r AlcoholSpend, echo=FALSE, fig.align="center", fig.cap="Left: the latent variable\\ $Z$, the desire to buy alcohol. Right: the observed variable\\ $X$, the average weekly spend on alcohol. The solid dot is the sum of all probabilities for which $Z \\le 0$.", fig.width=8, fig.height=4, out.width="100%"}
par(mfrow = c(1, 2))

############### Latent
zz <- seq(-3, 3.5, 
          length = 1000) + 1 # 1 is the ncp
z <- zz * 15

fz <- dt(zz, 
         df = 4, 
         ncp = 1)

plot(fz ~ z,
     type = "l",
     xlim = range(z),
     ylim = c(0, max(fz)),
     lwd = 3,
     col = plotColour1,
     axes = FALSE,
     main = expression(atop(Latent~variable~italic(Z)*":",
                            Desire~to~buy~alcohol)),
     xlab = expression(Latent~variable~italic(Z)),
     ylab = expression(Probability~fn.)
)
axis(side = 1)
box()
abline(v = 0,
       lty = 2,
       col = "grey",
       lwd = 2)

text(x = -18,
     y = max(fz) * 0.75, 
     label = "Aversion\nto buying\nalcohol",
     cex = 0.9)
text(x = 45,
     y = max(fz) * 0.75, 
     label = "Propensity\nto buying\nalcohol",
     cex = 0.9)


############### Observed
y0 <- pt( 0, 
          df = 4,
          ncp = 1)

plot(fz[z >= 0] ~ z[z >= 0],
     xlim = range(z),
     ylim = c(0, max(fz)),
     type = "l",
     lwd = 3,
     col = plotColour1,
     axes = FALSE,
     main = expression(atop(Observed~variable~italic(X)*":",
                            Average~weekly~spend~on~alcohol)),
     xlab = expression(Observed~variable~italic(X)),
     ylab = expression(Probability~fn.)
)

axis(side = 1)
axis(side = 2,
     at = round(y0, 2),
     las = 2)
box()

# Grey where latent variable is less than zero
lines(x = z[z < 0],
      y = fz[z < 0],
      col = "grey",
      lwd = 2,
      lty = 3)

abline(v = 0,
       lty = 2,
       col = "grey",
       lwd = 2)

# Points for Y = 0
points(x = 0,
       y = y0,
       pch = 19)

#points(x = Z_to_Y(0),
#       y = dt(0, 
#              df = 4,
#              ncp = 1),
#       pch = 1)
text(x = 28,
     y = max(fz)/6,
     label = "Prob. that no\nalcohol purchased",
     pos = 1,
     cex = 0.9)
arrows(x0 = 28,
       y0 = max(fz)/6,
       x1 = 0,
       y1 = pt(0, 
              df = 4,
              ncp = 1),
       angle = 15,
       length = 0.15)

```


In this context, the value of the observed variable\ $X$ is called *censored*.


:::{.definition #Censoring name="Censoring"}
A variable is called *censored*\index{Censoring} if its value is only observed when its above or below a certain threshold.

*Left censoring*\index{Censoring!left} occurs when the true (latent) value is less than or equal to a known threshold, but the exact value is unknown.
We only know that the true (latent) value is *below* a certain threshold.

*Right censoring*\index{Censoring!right} occurs when the true (latent) value is greater than or equal to a known threshold, but the exact value is unknown.
We only know that the true 9latent) value is *above* a certain threshold.
:::


:::{.example #AlcoholLeftCensoring name="Left censoring"}
The latent variable 'desire to purchase alcohol' used in Example\ \@ref(exm:TobitAlcoholSpend) is *left censored*.\index{Censoring!left}
:::


:::{.example #AlcoholLeftCensoring ame="Right censoring"}
In survival analysis,\index{Survival analysis} the time it takes insects to die (say\ $X$) may be studied.
If the study ends at time\ $t^*$, the time of death for any insects still alive is some value larger than $t^*$; that is, $X\ge t^*$ but the exact time of death remains unknown.
The time to death is *right censored*.\index{Censoring!right}
:::



::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Censoring*\index{Censoring} is not the same as *truncation*.\index{Truncation}

*Censoring* retains observations, but the exact value remains unknown.
*Truncation* removes observations whose value falls above or below a threshold.
:::



Usually $z^* = 0$ (as in Example\ \@ref(exm:TobitAlcoholSpend)), so that any value of\ $Z \le 0$ is recorded as\ $z = 0$.
That is, we observe the random variable\ $X$ such that
$$
  X = 
  \begin{cases}
    \Pr(Z < 0) & \text{if $Z \le 0$};\\
    Z          & \text{if $Z > 0$}. 
  \end{cases}
$$
This means the probability function of\ $X$ is
$$
  f_X(x) = 
  \begin{cases}
    0       & \text{if $X < 0$}\\
    F_Z(0)  & \text{if $X = 0$}\\
    f_Z(z)  & \text{if $X > 0$}
  \end{cases}
$$
where $F_Z(z)$ is the distribution function of\ $Z$.
The probability function for $X\mid X > 0$, the continuous part of the distribution only, is
\begin{equation}
  f_{X\mid X>0}(x) 
  = \frac{f_Z(x)}{\Pr(Z > 0)} 
  = \frac{f_Z(x)}{1 - F_Z(0)}
  (\#eq:PDFpositiveConditional)
\end{equation}
where again $F_Z(z)$ is the distribution function of\ $Z$.

The distribution function of\ $X$ is
$$
  F_{X\mid X>0}(x) =
  \begin{cases}
    0             & \text{for $x < 0$}\\
    F_Z(0)        & \text{for $x = 0$}\\ 
    F_Z(x)        & \text{for $x > 0$}
  \end{cases}
$$



:::{.example #TobitExamplesLatent2 name="Latent variables and censoring"}
Consider the number of hours worked (which can be observed), which must take a non-negative value.
We could assume an underlying, unobserved latent variable such as 'willingness to work'.
Negative values for 'willingness to work', no matter how small or how large, all result in zero observed hours of work.
:::


### Properties {#CensoredModelsProperties}

The expected value of the censored random variable\ $X$ can be found first separating the discrete and continuous parts of the distribution:
\begin{align*}
  \operatorname{E}[X] 
  &= \operatorname{E}[X\mid X = 0] + \operatorname{E}[X\mid X > 0]\\
  &= \Pr(X = 0)\times 0 + \operatorname{E}[X\mid X > 0]\\
  &= \operatorname{E}[X\mid X > 0].
\end{align*}
Similarly,
$$
  \operatorname{E}[X^2] 
  = \operatorname{E}[X^2 \mid X > 0]
  = \int_0^\infty x^2 \cdot f_{X\mid X>0}(x)\, dx,
$$
from which the variance can be obtained.
The same approach also gives the MGF as
$$
  M_X(t) = M_{X\mid X > 0}(t).
$$
Clearly, further progress with these expressions requires knowing the distribution of\ $X$ and hence the distribution of the latent variable\ $Z$.
It is common, but by no means universal, for the latent variable to be described by a normal distribution (when the models are also called *Tobit models*).\index{Tobit models}


:::{.example #TobitExample0 name="Censored model"}
Consider a latent variable\ $Y$, and an observed variable\ $X = \text{max}(0, Z)$.
Suppose that\ $Z$ has the normal distribution\index{Normal distribution} (Fig.\ \@ref(fig:TobitPic0), left panel))
$$
  Z \sim N(\mu = 0, \sigma^2 = 1),
$$
so that $\operatorname{E}[Z] = 0$ and $\operatorname{var}[Z] = 1$.
That is, $Z$ has a standard normal distribution (Sect\ \@ref(StandardNormal)), and so
$$
  \Pr(Z < 0) = \Phi(0) = 0.5.
$$
Recall the notation: $\Phi(\cdot)$ is the distribution function for a standard normal variate, and $\phi(\cdot)$ is the density function for a standard normal variate.

Then, define the random variable\ $X$ as
$$
  f_X(x) = 
  \begin{cases}
    0          & \text{if $Z < 0$};\\
    \Phi(0)    & \text{if $Z = 0$};\\
    \phi(x)    & \text{if $Z > 0$},
  \end{cases}
$$
as shown in Fig.\ \@ref(fig:TobitPic0) (right panel).

From Equation\ \@ref(eq:PDFpositiveConditional),
$$
  f_{X\mid X > 0}(x) 
  = \frac{\phi(x)}{1 - \Phi(0)}
  = 2 \phi(x)
$$
for $X > 0$.
From this expression, 
$$
  \operatorname{E}[X] 
   = \operatorname{E}[X \mid X > 0] 
  = 2 \int_0^\infty x\cdot \phi(x)\, dx 
  = \frac{2}{\sqrt{2\pi}} 
  \approx 0.7979,
$$
integrating the expression for $\phi(x)$ (Equation\ \@ref(eq:StandardNormalPMF)).
Similarly, using integration by parts,
$$
  \operatorname{E}[X^2] 
   = \operatorname{E}[X^2 \mid X > 0] 
  = 2 \int_0^\infty x^2\cdot \phi(x)\, dx 
  = 1/2.
$$
Combining, this means that 
$$
  \operatorname{var}[X] 
  = \frac{1}{2} - \left(\frac{2}{\sqrt{2\pi}}\right)^2 
  = \frac{1}{2} - \frac{1}{\pi} 
  \approx 0.182.
$$
:::



```{r TobitPic0, echo=FALSE, fig.align="center", fig.cap="A censored model, using a normal distribution for the continuous component, with the threshold value at $Z = 0$.", fig.width=8, fig.height=4, out.width="90%"}
par( mfrow = c(1, 2))

x.mean <- 0
x.sd <- 1
p <- pnorm(0,
            mean = x.mean,
            sd = x.sd)

x <- seq(from = x.mean - (3.5 * x.sd),
         to =   x.mean + (3.5 * x.sd),
         length = 1000)

y <-  dnorm(x,
            mean = x.mean,
            sd = x.sd)

plot(y ~ x,
     xlim = range(x),
     ylim = c(0, 0.5),
     type = "n",
     axes = FALSE,
     xlab = expression(Latent~variable~italic(Z)),
     ylab = expression(Prob.~"function"),
     main = expression( atop(A~censored~model*":",
                             the~latent~model~italic(Z))),
     lwd = 3)
axis(side = 1)

# Shade for X < 0
xNeg <- x[ x <= 0]
yNeg <- y[ x <= 0]

polygon( x = c(xNeg, rev(xNeg)),
         y = c(yNeg, rep(0, length(yNeg))),
         col = "lightgrey",
         border = NA) # Omit border

# Different colours for x >= 0 and x < 0
lines( y[x > 0] ~ x[x > 0],
       lwd = 2,
       col = "black")
lines( y[x <= 0] ~ x[x <= 0],
       lwd = 2,
       col = "darkgrey")

# x = 0
abline(v = 0,
       col = "grey",
       lty = 2)

box()


# Explanatory labels
arrows(x0 = -2,
       x1 = -1,
       y0 = 0.2,
       y1 = 0.08,
       length = 0.15,
       angle = 15)
text(x = -2,
     y = 0.2,
     pos = 3,
     cex = 0.9,
     label = expression(atop(Where,
                             italic(Z)<0) ) )

################################################################################

plot(y[x > 0] ~ x[x > 0],
     xlim = range(x),
     ylim = c(0, 0.5),
     type = "l",
     axes = FALSE,
     xlab = expression(Observed~variable~italic(X)),
     ylab = expression(Prob.~"function"),
     main = expression( atop(A~censored~model*":",
                             the~censored~model~italic(X))),

     lwd = 3)
axis(side = 1)
axis(side = 2,
     at = p)
box()


points(x = 0,
       y = p,
       pch = 19)


# Explanatory labels
arrows(x0 = 2.25,
       x1 = 0,
       y0 = 0.4,
       y1 = p,
       length = 0.15,
       angle = 15)
text(x = 2.25,
     y = 0.4,
     pos = 1,
     cex = 0.9,
     label = expression( atop(Discrete~prob.,
                              at~italic(X)==0) ) )


# arrows(x0 = 4,
#        x1 = 3,
#        y0 = 0.3,
#        y1 = dnorm(3, mean = x.mean, sd = x.sd),
#        length = 0.15,
#        angle = 15)
# text(x = 4,
#      y = 0.3,
#      pos = 3,
#      cex = 0.9,
#      label = expression( atop(Normal~distribution)) ) 

# X < 0 part
lines( y[x <= 0] ~ x[x <= 0],
       lwd = 1,
       lty = 3,
       col = "darkgrey")

# x = 0
abline(v = 0,
       col = "grey",
       lty = 2)


```





:::{.example #TobitExample name="Censored model"}
EXERISE??

Consider a latent variable\ $Y$, and an observed variable\ $X = \text{max}(0, Y)$.
Suppose that\ $Y$ has the normal distribution\index{Normal distribution} (Fig.\ \@ref(fig:TobitPic), left panel))
$$
  Y \sim N(\mu = 1.5, \sigma^2 = 1),
$$
so that $\operatorname{E}[Y] = 1.5$ and $\operatorname{var}[Y] = 1$.
Note that 
$$
  \Pr(Y < 0) = \Pr\big(Z < (0 - 1.5)/1\big) = \Phi(-1.5) \approx 0.0668,
$$
using $Z$ as a standard normal variate (Sect.\ \@ref(StandardNormal)).
To use the functions $\Phi(\cdot)$ and $\phi(\cdot)$, the standardised version of\ $Y$ must be used; that is, $Z = (Y - 1.5)/1 = (Y - 1.5)$ in these functions.

Then, define the random variable\ $X$ as
$$
  f_X(x) = 
  \begin{cases}
    0                & \text{if $X < 0$};\\
    \Phi(-1.5)       & \text{if $X = 0$};\\
    \phi(x - 1.5)    & \text{if $X > 0$},
  \end{cases}
$$
as shown in Fig.\ \@ref(fig:TobitPic) (right panel)).

From Equation\ \@ref(eq:PDFpositiveConditional),
$$
  f_{X\mid X > 0}(x) 
  = \frac{\phi(x- 1.5)}{1 - \Phi(-1.5)}
  \approx 1.148\dots \times \phi(x)
$$
for $X > 0$.
From this expression, 
\begin{align*}
  \operatorname{E}[X] 
   = \operatorname{E}[X \mid X>0] 
  &= \int_0^\infty ???\,dx \\
  & \text{FIX!}
\end{align*}
Similarly, 
$$
  \operatorname{var}[X] 
  = \operatorname{var}[X \mid X>0]
  = ???
$$
:::



```{r TobitPic, echo=FALSE, fig.align="center", fig.cap="A censored model, using a normal distribution for the continuous component, with the threshold value at $X = 0$.", fig.width=8, fig.height=4, out.width="90%"}
par( mfrow = c(1, 2))

x.mean <- 1.5
x.sd <- 1
p <- pnorm(0,
            mean = x.mean,
            sd = x.sd)

x <- seq(from = x.mean - (3.5 * x.sd),
         to =   x.mean + (3.5 * x.sd),
         length = 1000)

y <-  dnorm(x,
            mean = x.mean,
            sd = x.sd)

plot(y ~ x,
     xlim = c(-2, 5),
     type = "n",
     axes = FALSE,
     xlab = expression(Latent~variable~italic(Z)),
     ylab = expression(Prob.~"function"),
     main = expression( atop(A~mixed~distribution*":",
                             the~latent~model~italic(Z))),
     lwd = 2)
axis(side = 1)

# Shade for X < 0
xNeg <- x[ x <= 0]
yNeg <- y[ x <= 0]

polygon( x = c(xNeg, rev(xNeg)),
         y = c(yNeg, rep(0, length(yNeg))),
         col = "lightgrey",
         border = NA) # Omit border

# Different colours for x >= 0 and x < 0
lines( y[x > 0] ~ x[x > 0],
       lwd = 2,
       col = "black")
lines( y[x <= 0] ~ x[x <= 0],
       lwd = 2,
       col = "darkgrey")

# x = 0
abline(v = 0,
       col = "grey",
       lty = 2)

box()


# Explanatory labels
arrows(x0 = -1,
       x1 = -0.5,
       y0 = 0.2,
       y1 = 0.08,
       length = 0.15,
       angle = 15)
text(x = -1,
     y = 0.2,
     pos = 3,
     cex = 0.9,
     label = expression(atop(Where,
                             italic(Z)<0) ) )

################################################################################

plot(y[x > 0] ~ x[x > 0],
     xlim = c(-2, 5),
     type = "l",
     axes = FALSE,
     xlab = expression(italic(X)),
     ylab = expression(Prob.~"function"),
     main = expression( atop(A~mixed~distribution*":",
                             the~censored~model~italic(X))),

     lwd = 2)
axis(side = 1)
box()


points(x = 0,
       y = p,
       pch = 19)


# Explanatory labels
arrows(x0 = 1.5,
       x1 = 0,
       y0 = p,
       y1 = p,
       length = 0.15,
       angle = 15)
text(x = 1.6,
     y = p,
     pos = 1,
     cex = 0.9,
     label = expression( atop(Discrete~part,
                              at~italic(X)==0) ) )


# arrows(x0 = 4,
#        x1 = 3,
#        y0 = 0.3,
#        y1 = dnorm(3, mean = x.mean, sd = x.sd),
#        length = 0.15,
#        angle = 15)
# text(x = 4,
#      y = 0.3,
#      pos = 3,
#      cex = 0.9,
#      label = expression( atop(Normal~distribution)) ) 

# X < 0 part
lines( y[x <= 0] ~ x[x <= 0],
       lwd = 1,
       lty = 3,
       col = "darkgrey")

# x = 0
abline(v = 0,
       col = "grey",
       lty = 2)


```



\index{Censored models|)}




## Hurdle models {#HurdleModels}

### Definitions {#HurdleModelsDefinitions}

\index{Hurdle models|(}
A *hurdle model*\index{Hurdle models} treats the zero values of the random variable\ $X$ as emerging from a two-step process.
The first step uses a Bernoulli distribution (Sect.\ \@ref(BernoulliDistribution))\index{Bernoulli distribution} to model a random variable\ $Y$ that defines whether an event of interest occurs:
$$
  \Pr(Y) = 
  \begin{cases}
    1 - p    & \text{if the event of interest \emph{does not} occur;}\\
    p        & \text{if the event of interest \emph{does} occur.}
  \end{cases}
$$
If the event does occur (i.e., conditional on $X > 0$), with probability $1 - p$, then the continuous component is modelled using a probability density function $f^+_X(x)$ defined for positive real values only (such as an exponential distribution or a gamma distribution).

The probability function for the mixed random variable\ $X$ is therefore
$$
   f_X(x) = 
   \begin{cases} 
      1 - p           & \text{if $x = 0$}\\
      p\cdot f^+_X(x)    & \text{if $x > 0$,}
   \end{cases}
$$
where $f^+_X(x) = f_{X \mid X > 0}(x)$ is the density function for the continuous distribution defined for $x\in\mathbb{R}_{+}$.
The distribution function is
$$
   F_X(x) = 
   \begin{cases} 
      0                             & \text{if $x < 0$}\\
      1 - p                         & \text{if $x = 0$}\\
      (1 - p) + p\cdot F^+_X(x)    & \text{if $x > 0$,}
   \end{cases}
$$
where $F^+_X(x) = F_{X\mid X > 0}(x)$ is the distribution function for the continuous distribution defined for $x\in\mathbb{R}_{+}$.


:::{.example #HurdleExample name="Hurdle model"}
Consider the mixed random variable\ $X$, with probability function $f_X(x)$.
Suppose that, when $X > 0$, an exponential distribution\index{Exponential distribution} is used to describe the distribution; that is
$$
  f^+_X(x) = \frac{1}{\lambda}\exp(-x/\lambda)\quad\text{for $x > 0$}.
$$
Then, using $p = 0.7$ and $\lambda = 1/2$, the probability function of\ $X$ is
$$
  f_X(x)
  =
    \begin{cases}
       0.3                   & \text{if $x = 0$}\\
       0.35\cdot \exp(-x/2)  & \text{if $x > 0$;}
    \end{cases}
$$
see Fig.\ \@ref(fig:HurdlePic).
:::


```{r HurdlePic, echo=FALSE, fig.align="center", fig.cap="A hurdle model, showing an exponential distribution for the continuous component.", fig.width=8, fig.height=4, out.width="90%"}
p <- 0.7
x.rate = 2

x <- seq(0, 3,
         length = 100)
y <-  p * dexp(x, 
               rate = x.rate)
                     

par( mfrow = c(1, 2))
plot(y ~ x,
     type = "l",
     axes = FALSE,
     ylim = c(0,
              max( c(y, 1 - p) ) ),
     xlab = expression(italic(X)),
     ylab = expression(Prob.~"function"),
     main = expression(atop(Mixed~distribution,
                            hurdle~ model)),
     lwd = 2)
axis(side = 1)
axis(side = 2,
     at = c(0, 
            1 - p),
     las = 2)
box()

points(x = 0, # Included
       y = 1 - p,
       pch = 19)
points(x = 0, # Excluded
       y = max(y),
       pch = 1)

# Explanatory labels
arrows(x0 = 0.35,
       x1 = 0,
       y0 = 0.17,
       y1 = 1 - p,
       length = 0.15,
       angle = 15)
text(x = 0.35,
     y = 0.17,
     pos = 1,
     label = expression(Pr*"("*italic(X)==0*")" ) )


arrows(x0 = 1.5,
       x1 = 1,
       y0 = 0.8,
       y1 = dexp(x = 1, 
                 rate = x.rate) * p,
       length = 0.15,
       angle = 15)
text(x = 1.5,
     y = 0.8,
     pos = 3,
     label = expression( Exponential~distribution) )


#############################################

Fy <- (1 - p)  + p * pexp( x,
                           rate = x.rate)
plot(Fy ~ x,
     type = "l",
     axes = FALSE,
     ylim = c(0, 1),
     xlim = c(-1, max(x)),
     xlab = expression(italic(X)),
     ylab = expression(Distribution.~"function"),
     main = expression(atop(Mixed~distribution,
                            hurdle~ model)),
     lwd = 2)
lines(x = c(-1, 0),
      y = c(0, 0),
      lwd = 2)
points(x = 0, 
       y = 0,
       pch = 1) # Not incuded


axis(side = 1)
axis(side = 2,
     at = c(0, 
            1 - p, 
            1),
     las = 2)
box()

points(x = 0, # Included
       y = 1 - p,
       pch = 19)

```




### Properties {#HurdleModelsProperties}

The expected value of the random variable\ $X$ can be found first separating the discrete and continuous parts of the distribution:
\begin{align*}
  \operatorname{E}[X] 
  &= \operatorname{E}[X\mid X = 0] + \operatorname{E}[X\mid X > 0]\\
  &= (1 - p)\times 0 + p \operatorname{E}[X\mid X > 0]\\
  &= p \mu^+,
\end{align*}
where $\mu^+$ denotes $\operatorname{E}[X\mid X > 0]$, the expected value of the distribution defined for $X > 0$.
Similarly,
$$
  \operatorname{E}[X^2] 
  = \operatorname{E}[X^2 \mid X > 0]
  = p (\mu^2)^+,
$$
where $(\mu^2)^+$ denotes $\operatorname{E}[X^2\mid X > 0]$.
Then, the variance of\ $X$ is
\begin{align*}
  \operatorname{var}[X]
  &=  p[(\mu^2)^+ - p(\mu^+)^2]\\
  &=  p(\sigma^2)^+ + p(1 - p)(\mu^+)^2.
\end{align*}
where $\sigma^2 = \operatorname{var}[X \mid X > 0]$
The same approach also gives the MGF as
\begin{align*}
  M_X(t) 
  &= (1 - p) + p\cdot M_{X^+}(t)\\
  &= (1 - p) + p\cdot M_{X\mid X > 0}(t),
\end{align*}
where $M_{X^+}(t)$ is the MGF of the distribution defined for $X > 0$.

Clearly, further progress with these expressions requires knowing the distribution of\ $X | X > 0$



:::{.example #HurdleGamma name="Hurdle model, using gamma distribution"}
Consider a random variable\ $X$ such that $p = 0.75$ (and hence $\Pr(X = 0) = 1 - p = 0.25$), and where the distribution when $X > 0$ follows a gamma distribution (Sect.\ \@ref(GammaDistribution)) having $\alpha = 2$ and $\beta = 1$, with the density function
$$
  f_X^{+}(x; \alpha, \beta) 
  = f_{X\mid X > 0}(x; \alpha, \beta) 
  = \frac{1}{\Gamma(2)} x \exp(-x)
  \quad\text{for $x > 0$}.
$$
For this gamma distribution, using results from Sect.\ \@ref(GammaDistribution), $\mu^+ = \operatorname{E}[X\mid X > 0] = \alpha\beta = 2$ and $\operatorname{var}[X\mid X > 0] = \alpha\beta^2 = 2$.
Then, the probability function for\ $X$ is
$$
  f_{X}(x) 
  = 
  \begin{cases}
     0.25                                & \text{for $x = 0$}\\
     0.75 \times f_X^{+}(x; \alpha, \beta) & \text{for $x > 0$.}
  \end{cases}
$$
Then 
\begin{align*}
  \operatorname{E}[X] 
   &= p\cdot \mu^+ 
    = 0.75 \times 2 
    = 1.5\\
  \operatorname{var}[X] 
   &= p(\sigma^2)^+ + p(1 - p)(\mu^+)^2
   = 0.75\times 2 + 0.75\times 0.25\times 1.5^2
   \approx 1.921.
\end{align*}
:::



```{r HurdleGamma, echo=FALSE, fig.align="center", fig.cap="A hurdle model, using a gamma distribution for the continuous component.", fig.width=8, fig.height=4, out.width="90%"}
p <- 0.75
x.shape <- 2 # shape = alpha
x.scale <- 1 # scale = beta

x <- seq(0, 5,
         length = 100)
y <-  p * dgamma(x, 
                 shape = x.shape,
                 scale = x.scale)
                     

par( mfrow = c(1, 2))
plot(y ~ x,
     type = "l",
     axes = FALSE,
     ylim = c(0,
              max( c(y, 1 - p) ) ),
     xlab = expression(italic(X)),
     ylab = expression(Prob.~"function"),
     main = expression(atop(Hurdle~model,
                            probability~"function")),
     lwd = 2)
axis(side = 1)
axis(side = 2,
     at = c(0, 
            1 - p),
     las = 2)
box()

points(x = 0, # Included
       y = 1 - p,
       pch = 19)
points(x = 0, # Excluded
       y = y[1],
       pch = 1)



#############################################

Fy <- (1 - p)  + p * pgamma(x, 
                            shape = x.shape, 
                            scale = x.scale)
plot(Fy ~ x,
     type = "l",
     axes = FALSE,
     ylim = c(0, 1),
     xlim = c(-1, max(x)),
     xlab = expression(italic(X)),
     ylab = expression(Distribution.~"function"),
     main = expression(atop(Hurdle~model,
                            distribution~"function")),
     lwd = 2)
lines(x = c(-1, 0),
      y = c(0, 0),
      lwd = 2)
points(x = 0, 
       y = 0,
       pch = 1) # Not incuded


axis(side = 1)
axis(side = 2,
     at = c(0, 
            1 - p, 
            1),
     las = 2)
box()

points(x = 0, # Included
       y = 1 - p,
       pch = 19)
```





\index{Hurdle models|)}


## Compound Poisson-gamma distributions {#TweedieModels}

\index{Compound Poisson-gamma models|(}
Compound Poisson--gamma distribution take a different approach to modelling mixed random variables: Compound Poisson--gamma distributions model mixed random variables as a Poisson sum of independent gamma distributions.
Suppose the number of events observed (which is discrete) is\ $N$, such that
$$
  N \sim \text{Pois}(\lambda).
$$
That is, an event occurs\ $N$ times, but occurs at random following a Poisson distribution.
Given that\ $N$ has a Poisson distribution, it follows (from Sect.\ \@ref(PoissonDistribution)) that
$$
  \Pr(N = 0) = \exp(-\lambda)
$$
is the probability that zero events are observed (i.e., $N = 0$).
If, however, $N > 0$, then for $i = 1, 2, \dots, N$, a continuous random variable\ $Y_i$ is observed, such that
$$
   Y_i \sim \text{Gam}(\alpha_i, \beta).
$$
If $N = 0$, then no events $Y_i$ are observed at all; however, if $N > 0$ then\ $N$ events are observed and
$$
  X = \sum_{i = 1}^N Y_i
$$
has a continuous distribution.

Let
$$
  N \sim \text{Pois}(\lambda)
  \quad\text{and}\quad
  Y_i \sim \text{Gam}(\alpha, \beta),
$$
Then, 
$$
  X = 
  \begin{cases}
    0                   & \text{if $N = 0$};\\
    \sum_{i = 1}^N Y_i  & \text{if $N > 0$}.
  \end{cases}
$$
The distribution of\ $X$ has a probability mass at $X = 0$ where $\Pr(Y = 0) = \Pr(N = 0) = \exp(-\lambda)$.

The distribution of the Poisson sum of gamma distributions has a probability function that cannot be written down in closed form, but has a very simple MGF.
The probability function is
\begin{align*}
  f_X(x) 
  &= \sum_{n = 1}^\infty \Pr(N = n) \times f_{X\mid N = n}(x)\\
  &= \sum_{n = 1}^\infty  \frac{\exp(-\lambda)\lambda^n}{n!} \times \frac{\beta^{n\alpha}}{\Gamma(n\alpha)} x^{n\alpha - 1} \exp(-\beta x) \\
  &= \exp(-\lambda - \beta x) \sum_{n = 1}^\infty \frac{\lambda^n}{n!} \frac{\beta^{n\alpha}}{\Gamma(n\alpha)} x^{n\alpha - 1} 
\end{align*}
when $x > 0$.

To find the MGF, first consider the value of\ $N$ as fixed; then, $X = Y_1 + Y_2 + \cdots + Y_N$ the MGF of\ $X$ is 
$$
  M_{X\mid N}(t) = \operatorname{E}[\exp(tX)\mid N].
$$
Since the MGF of a sum of independent random variables is the product of their MGFs (Theorem\ \@ref(thm:MGFIndependent)), we can assume that $N$ takes some specific value\ $n$ and write
\begin{align*}
  M_{X\mid N}(t) 
  &= \operatorname{E}\left[ \exp\big(t(Y_2 + Y_2 + \cdots + Y_n)\big)\right] \\
  &= \prod_{i = 1}^n \operatorname{E}[\exp(t Y_i)] \\
  &= \left( M_Y(t)\right)^n
\end{align*}
So the MGF of $X$ (rather than $X\mid N$ as above) is
\begin{align*}
  M_X(t) 
  &= \operatorname{E}\left[ \operatorname{E}[ \exp(tX\mid N)]\right] \\
  &= \operatorname{E}\left[ M_{X\mid N}(t))\right] \\
  &= \operatorname{E}\left[ M_Y(t))^N\right] \\
\end{align*}
and so
$$
  M_X(t)=\exp\!\left\{\lambda\left[\Big(\frac{\beta}{\beta-t}\Big)^{\!\alpha}-1\right]\right\},\qquad t<\beta
$$

---

We have
$$
M_X(t) = \mathbb{E}[e^{tX}] 
        = \mathbb{E}\!\left[ \big(M_Y(t)\big)^{N} \right].
$$
Writing the expectation as a sum over the possible values of\ $N$,
$$
  M_X(t) 
  = \sum_{n=0}^\infty \big(M_Y(t)\big)^{n} \, \Pr(N = n).
$$
Since $N \sim \mathrm{Pois}(\lambda)$,
$$
  \Pr(N = n) = \frac{\exp(-\lambda) \lambda^n}{n!}.
$$
Substituting this expression into XREF
\begin{align*}
  M_X(t) 
  &= \sum_{n = 0}^\infty 
  \big(M_Y(t)\big)^{n} \cdot \frac{\exp(-\lambda) \lambda^n}{n!}\\
  &= \exp(-\lambda) \sum_{n = 0}^\infty \frac{\left[\lambda \, M_Y(t)\right]^n}{n!}.
\end{align*}
Using the series expansion $\sum_{n = 0}^\infty z^n/n! = \exp(z)$ (from Equation\ \@ref(eq:Exponential)) with $z = \lambda M_Y(t)$, this gives
\begin{align*}
  M_X(t) 
  &= \exp(-\lambda) \cdot \exp\big(\lambda M_Y(t)\big)\\
  &= \exp\{\lambda(M_Y(t) - 1) \\
  &= \exp\!\left\{\lambda\left[\Big(\frac{\beta}{\beta-t}\Big)^{\!\alpha}-1\right]\right\},
\end{align*}
provided $t < \beta$.

---



From the MGF we can deduce
\begin{align*}
  \operatorname{E}[X] 
  &= \lambda\alpha\/\beta\\
  \operatorname{var}[X]
  &= \lambda\alpha(\alpha + 1)/\beta^2.
\end{align*}



:::{.example #PoissonGammaExample name="Poisson--gamma distribution"}
Suppose 
$$
  N\sim\text{Pois}(\lambda = 3)
  \quad\text{and}\quad
  Y_i \sim\text{Gam}(\alpha = 5/3, \beta = 2/3).
$$
The mean and variance of\ $X$ is
\begin{align*}
  \operatorname{E} 
  &= \lambda\alpha\/\beta
   = 3\times \frac{5}{3}\times\frac{2}{3} = 3.333\text{(SHOULD BE 1!)}\\
  \operatorname{var} 
  &= \lambda\alpha(\alpha + 1)\/\beta^2
   = 3\times (5/3\times 8/3)/(5/3)^-2 = \text{SHOULD BE 1}
\end{align*}
Then the Poisson-gamma distribution is...
:::


<!-- The parameters in the (alpha, beta, lambda) space:
\alpha = (2 - \xi)/(\xi - 1) [Not a function of (phi, mu)]
\beta = \phi(\xi - 1) / \mu^{\xi - 1}
\lambda = \mu^(2-\xi) / ( \phi (2-\xi))


So for instance:
alpha = 12 => xi = 5/3
alpha = 20 => xi = 22/21

-->


```{r PoissonGammaExamples, echo=FALSE, fig.align="center", fig.cap="Two compound Poisson--gamma models, both with mean and varaince set to $1$. The solid dot at $X = 0$ represents the discrete probability.", fig.width=8, fig.height=4, out.width="90%"}
par( mfrow = c(1, 2))

x <- seq(from = 0,
         to =   5,
         length = 1000)

xi <- 22/21
alpha <- 20

mu <- 1
phi <- 1

alpha <- (2 - xi)/(xi - 1)
lambda <- mu^(2 - xi) / ( phi * (2 - xi))
beta <- phi * (xi - 1) / mu^(xi - 1)

cat(alpha, beta, lambda, "\n")

y <-  dtweedie(y = x,
               xi = xi,
               mu = mu,
               phi = phi)

plot(y[x > 0] ~ x[x > 0],
     type = "l",
     ylim = c(0, max(y)), 
     axes = FALSE,
     xlab = expression(italic(x)),
     ylab = expression(Prob.~"function"),
     main = expression(atop(Poisson*"-gamma"~distribution,
                            with~alpha==20)),
     lwd = 2)
axis(side = 1)

points(x = 0,
       y = dtweedie(y = 0,
                    xi = xi,
                    mu = mu, 
                    phi = phi),
       pch = 19)
box()

#tweedie.convert(xi = xi,
#                mu = mu, 
#                phi = phi)


############################ 

xi <- 5/3 # ALPHA = 0.5
alpha <- 0.5

mu <- 1
phi <- 1

alpha <- (2 - xi)/(xi - 1)
lambda <- mu^(2 - xi) / ( phi * (2 - xi))
beta <- phi * (xi - 1) / mu^(xi - 1)

cat(alpha, beta, lambda, "\n")


y <- dtweedie(y = x,
              xi = xi,
              mu = mu,
              phi = phi)


plot(y[x > 0] ~ x[x > 0],
     type = "l",
     ylim = c(0, max(y)), 
     axes = FALSE,
     xlab = expression(italic(x)),
     ylab = expression(Prob.~"function"),
     main = expression(atop(Poisson*"-gamma"~distribution,
                            with~alpha==0.5)),
     lwd = 2)
axis(side = 1)
box()


points(x = 0,
       y = dtweedie(y = 0,
                    xi = xi,
                    mu = mu,
                    phi = phi),
       pch = 19)
box()

#tweedie.convert(xi = xi,
#                mu = mu, 
#                phi = phi)

```

```{r}

## SIMULATION
num_Sims <- 1000
set.seed(75101) # For reproducibility

# Set parameters
lambda <- 2
alpha <- 2
beta <- 1
  
N <- rpois(num_Sims,
           lambda = lambda)
X <- array( dim = num_Sims)

for (i in 1:num_Sims){
  if ( N[i] == 0) {
    X[i] <- 0 
  } else {
     X[i] <- sum( rgamma(N[i], 
                         shape = alpha,
                         scale = beta) )
  }
}



MASS::truehist(X [X > 0],
               las = 1,
               xlab = expression(italic(X)),
               ylab = expression(Density),
               col = plotColour1)
points(x = 0,
       y = length(X[X==0]))
  
```
\index{Compound Poisson-gamma models|)}



:::{.example #RainfallModelling name="Modelling monthly rainfall"}
Modelling rainfall. 
Using hurdle from Stern and Coe, Chandler and Wheater? Tobit thing from IWSM, and Poisson--gamma, 
:::



## Simulation {#MixedVariablesSimulation}


## Exercises  {#MixedDistributionsExercises}


Selected answers appear in Sect.\ \@ref(AnswersChapUnknownAsYet).


:::{.exercise #LatentVar}
 4. Medical Costs
Observed variable: Annual medical expenses.

Latent variable ($z$): Underlying health need or risk.

Censoring: Many people incur $0$ expenses in a given year, despite possibly having latent health risks or needs.

Interpretation: People with latent need below some threshold never seek care (e.g. due to costs, access, or asymptomatic cases), leading to observed $0$.
:::

:::{.exercise #LatentVar2}
5. Credit Card Balances
Observed variable: Balance at end of month.

Latent variable ($z$): Willingness or propensity to use credit.

Censoring: Some users consistently pay in full and carry no balance.

Interpretation: Some people have low latent demand for borrowing; observed balance is zero if the latent borrowing desire is below threshold.
:::

