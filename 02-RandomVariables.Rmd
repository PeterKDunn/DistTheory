# Distribution of random variables {#RandomVariables}

::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
Upon completion of this module you should be able to:

* understand the concept of univariate random variables
* distinguish between discrete, continuous and mixed random variables both for discrete and continuous cases
* determine the probability function of random variables defined for an experiment
* determine the distribution function of a random variable from its probability function and apply it to the computation of probabilities of defined events
* plot the probability function and distribution function of a random variable
* understand the concept of a mixed random variable and manipulate its probability function
:::

## Introduction

In Module \@ref(Probability)}, the tools of probability were used to assist in answering questions about phenomena involving uncertainty.
The sample space was defined as the set of all possible outcomes and an event was defined as a subset of the sample space.
Probabilities were associated with events.
The outcomes themselves could be numeric, as in tossing a die, or non-numeric, as in tossing a coin.

Interestingly it turns out that it is advantageous to restrict ourselves to numerical outcomes from experiments.
This may sound unnecessarily restrictive, but is not.
After all, we are quite at liberty to number all the outcomes in the sample space, thereby converting non-numeric elements to numeric ones.
So, for example, heads could be denoted 1 and tails 2 in the sample space associated with tossing a coin.

This might sounds a bit unnecessary, and in the case of coin tossing it probably is.
However by restricting ourselves to numeric outcomes we can make use of the powerful concepts that are associated with numbers.
In particular the concepts of discreteness, continuousness, types of infinity, limits, etc. are available.
So what might appear to be a restrictive step is in reality the key to unlocking some powerful ideas and results that make probability theory and in turn, statistical theory, a force to be reckoned.

Of course, in most scientific, engineering and business applications, our interests are in assigning probabilities to numeric outcomes.
For example,

* Probabilities can be assigned to different amounts of money made by an investment
* Probabilities can be assigned to the proportion of people that contract a given disease
* Probabilities can be assigned to observing different water levels at a certain river crossing
* Probabilities can be assigned to matching DNA sequences when their genome sequences are almost identical
* Probabilities can be assigned to recording certain rainfall amounts.


The point however is that some experiments give rise to just a limited number of outcomes (eg tossing a die), some give rise to an unlimited number of discrete outcomes (eg the number of attempts needed to win a lottery) and some give rise to a range of possible outcomes over some interval (eg water levels, rainfall, tomorrow's maximum temperature).
The differences amongst these types of sample spaces is what drives us to thinking in terms of discrete numbers (such as integers) and continuous numbers (such as the reals).

To make the connection we define something called a *random variable* on the sample space.
This is simply a way of converting the elements of the sample space into numbers.
Depending on the type of sample space, this random variable can be discrete, continuous, or a mixture of both.
Regardless, it is useful and important to be able to describe the possible values of the random variable and the probability associated with these values.
This is called the *distribution of the random variable* and is the concept underlying the name of this course.

As an example, when a fair die is rolled, the classical approach to probability can be used to determine the theoretical probabilities $\Pr(\text{roll\ a\ \epsdice{1}}) = \Pr(\text{roll\ a\ \epsdice{2}}) = \cdots = \Pr(\text{roll a \epsdice{6}}) = 1/6$.
If we define a random variable $X$ in this experiment as the number of pips showing on the die then we see, for example, that $X = 1$ for the outcome $\epsdice{1}$. 
Consequently we have $\Pr(X = 1) = \Pr(X = 2) = \dots = \Pr(X = 6) = 1/6$ and this describes the distribution of the random variable $X$ for this experiment.

This random variable $X$ is discrete and the distribution of $X$ is an example of a *discrete uniform distribution* for obvious reasons.
We learn more about this distribution in Section~\ref{SC:specdiscrete:uniform}.

When a die is rolled repeatedly, and the relative frequency is determined for each value of $X$, we don't of course get 1/6 for each.
We recognise the discrete uniform distribution is a theoretical distribution based on the principle of indifference as described in section~\ref{SS:classical}.
The observed distribution of relative frequencies based on actual dice tossing will only approximate the theoretical distribution.
How well the two match we would be justified in thinking depends on how many times the die is tossed and how balanced it is.
This is an investigation we pursue later.

The theoretical distribution is said to *model* the experiment.
Hence the discrete uniform distribution is a model for dice tossing.
The classical approach to assignment of probabilities gives us a model in this case.
For other experiments other models will be appropriate.

This module discusses the concept of the random variable and the distribution of probabilities amongst the values of a random variable.
Further modules describe specific distributions useful in modelling experiments.


## Random variables {#RandomVariables}

Colloquially, a random variable is a numerical-valued variable. 
A random variable may be *continuous*, *discrete* or a combination of the two.
Some examples follow the more formal definition below.

:::{.definition #DomainRange name="Domain and range"}
A random variable $X$ is a *real-valued function* mapping each element of the sample space into a real number. 
The *domain* of a random variable is the sample space, and the *range space* or *value set* is the set of real numbers taken by function.
:::

The random variable $X$ can be thought of as a rule assigning a number to each and every outcome in the sample space.

Using functional notation we see that a function $X$ assigning to every sample point $s\in S$ a real number $X(s)$ is a random variable.
Further, since $X$ is a function, to every $s\in S$ there corresponds exactly one value $X(s)$.
The domain of $X$ is the set $S$ and the range space is the set $\{X(s)\mid s\in S\}$.

Commonly, *random variable* is abbreviated to rv.

A *discrete* random variable (rv) is defined on a discrete sample space.
Examples of discrete random variables include:

* The number of mice in a cohort of twenty that develop an illness
* The number of rain events occurring during a week
* The amount of money in a person's pocket
* The shoe size of a person
* The number of attempts needed to win Lotto
* The number of offspring successfully reared by an endangered species of bird
* The gender (after coding) of the next customer.

The last example might need explaining.
The sample space for the associated experiment contains two points `female' and `male'; i.e., $S = \{\text{female},\text{male}\}$. 
A random variable though must be numeric so if 'Gender' is to be a random variable we must associate the outcomes in the sample space with numerical values; e.g., an arbitrary coding such as 0 for 'female' and 1 for 'male' achieves this.
We can then write $X(\text{female}) = 0$ and $X(\text{male}) = 1$ where $X$ denotes the random variable 'Gender'.
Notice the range space or value set of $X$ is $\{0,1\}$ which we might denote as $R_X$.

NOTE CODE IS ARBITRARY!

Often we dispense with formal functional notation when defining random variables and write, for example,
\[
   X = 
   \begin{cases} 
      0 & \text{if female}\\
      1 & \text{if male}
    \end{cases}
\]

Incidentally don't confuse the *definition* of a random variable with the *values* of the random variable.
In the last example, the rv 'Gender' can have two values, female or male coded as 0 or 1. 
'Male' or 0 is not a rv; it is one *value* of the rv 'Gender'.

Loosely speaking, a *continuous* random variable is one that can never be measured exactly. 
If a random variable can assume any value or a set of values in an interval, then it is called *continuous*. 
For example, consider your height. 
Your height could be recorded as 174\,cm, but with better measuring instruments it may be 174.023\,451\,006\,cm, and even more decimals are possible
with even better instruments! 
Even though height may be written down to the nearest centimetre or even millimetre, height itself is still a continuous measure. 
In addition, your height does not change by a distinct amount. 
My baby daughter grows continually; she doesn't grow in jumps of 1cm, for example! 
Examples of continuous random variables include:

* The volume of waste water treated at a sewage plant per day
* The amount of money made (or lost) by an investment over 12 months
* The weight of hearts in normal rats
* The lengths of the wings of butterflies
* The lifetime of diseased mice after taking an experimental drug
* The yield of barley from a large paddock
* The amount of rainfall recorded each year
* The time taken to perform a psychological test.



Mixed random variables are less common. 
Typically, they consist of a quantity that can be measured exactly (discrete) sometimes and inexactly (continuous) at other times. 
Consider, for example, the time spent waiting at a set of traffic lights before proceeding.
If the light is already green when you arrive, you can drive straight through and have to wait exactly zero seconds (the discrete part). 
If the light is red when you arrive, you have to wait a continuous amount of time before it turns green and you go.
Hence, the time spent waiting is a mixed random variable.


::: {.example #BabyBoom name="Baby Boom data"}
The *Sunday Mail* newspaper (Brisbane, Australia) on 21
December 1997 gave data giving the birth weight, gender, and time
of birth of 44 babies born in the 24-hour period of 18 December
1997 at the Mater Mother's Hospital in Brisbane, Australia. The
gender of the babies is a discrete random variable; the birth
weight and time of birth are continuous. The data can be used to
determine the number of births each hour (discrete) and the time
between births (continuous).
:::

::: {.example #TossingCoinOutcomes name="Tossing coin outcpmes"}
Consider tossing a coin twice and observing the outcome of the two
tosses. Since a random variable is a *real-valued function*,
simply observing the outcome as $\{\head, \tail\}$, for example,
is not a rv. We could define the rv of interest, say $H$, as the
*number* of heads on the two tosses of the coin. The
*sample space* for the experiment is $S = \{ (\tail\tail),
(\tail\head), (\head\tail), (\head\head)\}$. 
The connection between the sample space and $H$ is shown in Table \@ref(tab:CoinsSampleSpace).

In this case, the range of $H$ is $R_H = \{0, 1, 2\}$.
:::


```{r CoinsSampleSpace, echo=FALSE}
rvTable <- array( dim = c(4, 3))
colnames(rvTable) <- c("Elements of $S$",
                       "Function $H$",
                       "Value of $H$")

rvTable [1, ] <- c("$(TT) = s_1$",
                   "$H(s_1)$, the number of heads in $s_1$",
                   "0")
rvTable [2, ] <- c("$(TH) = s_2$",
                   "$H(s_2)$, the number of heads in $s_2$",
                   "1")
rvTable [3, ] <- c("$(HT) = s_3$",
                   "$H(s_3)$, the number of heads in $s_3$",
                   "1")
rvTable [4, ] <- c("$(HH) = s_4$",
                   "$H(s_4)$, the number of heads in $s_4$",
                   "2")
knitr::kable(rvTable,
             align = "c",
             caption = "The random variable $H$ maps each element in the sample space $S$ to a real number")
```

Methods for describing random variables and how probabilities are
assigned or distributed amongst the values of a random variable
occupies much of this course.

One of the reasons for distinguishing between discrete and
continuous random variables is that the ways we can describe the
distribution of probabilities depend to some extent on this
distinction.



## Univariate distributions {#Univariate}

This section focuses on methods of describing the distribution of
probabilities amongst the values of a random variable.
We need to consider separately discrete and continuous rvs.


### The probability function {#ProbabilityFunction}

The *probability function* is a function that indicates how probabilities are assigned to the values of a discrete rv; that is, a rv with range space that is finite or countably infinite.


::: {.definition #ProbabilityFunction name="Probability function"}
Let the range space of the discrete rv $X$ be $R_X$.
With each $x\in R_X$ we associate a number 

\[
   p_X(x) = \Pr(X = x)
\]
The function $p_X$ is called the *probability function* of $X$.
:::


The probability function for discrete rvs is often called the *probability mass function*.


::: {.definition #ProbabilityDistribution name="Probability distribution"}
If $R_X =\{ x_1,x_2,\dots,x_n, \dots \}$, the set  $\{ (x_i,p_X(x_i);\quad i=1,2,\dots\}$
is called the *probability distribution* of the discrete rv $X$.
:::

Sometimes the probability function is dented $p(x)$ rather than $p_X(x)$.
Using the subscript is recommended to avoid confusion in situations where a number of random variables are on the go.
So if we are dealing with the discrete rv's $X$ and $Y$ we can denote their respective probability distributions by $p_X$ and $p_Y$ respectively.
We use this subscript idea where appropriate throughout this course.

Essentially the probability distribution of a random variable is a description of the range space or value set of the variable and the associated assignment of probabilities.
The above definition only applies to a **discrete rv**.

The probability distribution of a discrete rv $X$ can be represented by a formula, a table or a graph which displays the probabilities $p(x)$ corresponding to each $x\in R_X$.


::: {.example #Independence name="Independence"}
Five balls numbered 1, 2, 3, 4, 5 are in a box.
Two balls are selected at random.
Find the probability distribution of the *larger* of the two numbers.
\[ 
    S =\{ (1,2),(1,3),(1,4),(1,5),(2,3),(2,4), (2,5), (3,4), (3,5), (4,5)\}
\]
and all 10 points are equally likely.

Let rv $X$ be the *larger* of the 2 numbers chosen.
Then $R_X =\{2,3,4,5]$ and
\begin{align*}
     \Pr(X = 2) &= \Pr((1,2)) = 1/10\\
     \Pr(X = 3) &= \Pr((1,3) \text{ or }  (2,3)) = 2/10\\
     \Pr(X = 4) &= \Pr((1,4) \text{ or } (2,4) \text{ or } (3,4)) = 3/10\\
     \Pr(X = 5) &= \Pr((1,5) \text{ or } (2,5) \text{ or } (3,5)\text{ or } (4,5)) = 4/10.
\end{align*}
This is the probability distribution of $X$ but it can be expressed more neatly as a formula:
\[ 
   \Pr(X = x) = (x - 1)/10, \quad x = 2, 3, 4, 5, 
\]
or shown in a table (below) or as a graph as in Fig. \@ref(fig:ProbDist1).
:::


$x$          | 2   | 3   | 4   | 5
------------------------------------
$\Pr(X = x)$ | 0.1 | 0.2 | 0.3 | 0.4

```{r ProbDist1, echo=FALSE, fig.align="center", fig.cap="CAPTION"}
plot( x = 2:5,
      y = c(0.1, 0.2, 0.3, 0.4),
      xlim = c(1.75, 5.25),
      ylim = c(0, 0.4),
      type = "h",
      las = 1,
      lty = 1,
      lwd = 1,
      col = "grey",
      main = "The proability distribution of $X$",
      xlab = "Values of the rv  X",
      ylab = "The probability function ???"
)
points( x = 2:5,
        y = c(0.1, 0.2, 0.3, 0.4),
        pch = 19)

```
 

*Computer exercise* Write an \R\ function to allow you to simulate
the distribution in this example.

::: {.example #TossingHeads name="Tossing heads"}
Suppose a fair coin is tossed twice.
Then the *sample space* is $S = \{\head\head, \head\tail, \tail\head, \tail\tail\}$.

Let $H$ be the *number* of heads observed.
$H$ is a (discrete) random variable, and the range of $H$ is $R_H = \{0, 1, 2\}$, representing the values that $H$ can take.
The probability function maps each of these values to the associated probability.
Using techniques from Module~\ref{SC:prob}, the probabilities can be computed and given as a list:
\begin{align*}
   \Pr(H = 0) =\,& \Pr{\text{no heads}} = 0.25\\
   \Pr(H = 1) =\,& \Pr{\text{one head}} = 0.5\\
   \Pr(H = 2) =\,& \Pr{\text{two heads}} = 0.25.
\end{align*}
This information can be presented as a table:

$h$          |  0   |  1   |  2 
------------------------------------
$\Pr(H = h)$ | 0.25 | 0.5  |  0.25


As a function, the probability function could be written as
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
               0.25 & \text{if $h = 0$}\\
               0.5 & \text{if $h = 1$}\\
               0.25 & \text{if $h = 2$}\\
               0 & \text{otherwise}
              \end{cases}
\]
(Recall that the upper case $H$ refers to the *name* of the rv.)
For the more adventurous, it could also be given as
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
                  (0.5)0.5^{|h-1|} & \text{for $h=0$, $1$ or $2$}\\
                  0 & \text{otherwise}
              \end{cases}
\]
Graphically, the probability function could be shown as in Figure~\ref{FG:rvs:heads}.
For discrete distributions, the pf can be displayed using the 'stick' approach in this figure, or a histogram.

Note that $\sum_{t \in \{0, 1, 2\}} p_H(t) = 1$ and $p_H(h)\ge0$ for all $h$ as required of a pf.
:::



```{r ProbDistributionCoin, echo=FALSE, fig.align="center", fig.cap="CAPTION"}
plot( x = 1:3,
      y = c(0.25, 0.50, 0.25),
      ylim = c(0, 0.55),
      type = "h",
      las = 1,
      col = "grey",
      main = "The proability distribution of $X$",
      xlab = "Values of the rv  X",
      ylab = "The probability function ???"
)

points( x = 1:3,
        y = c(0.25, 0.5, 0.25),
        pch = 19)

```


The following properties of the probability function are implied by the definition.

1. $p_X(t)\ge0$ for all values of $t$; that is, probabilities are never negative;
2. $\displaystyle \sum_{t\in R_X}  p_X(t) = 1$ where $R_X$ is the range of $X$; that is, the probability function accounts for all possible sample points    in the sample space;
3. $p_X(t) = 0$ if $t\not\in R_X$;
4. For an event $A$ defined on a sample space $S$, the probability of event $A$ is computed using
   \[
      \Pr{A} = \sum_{t\in A} p_X(t).
   \]

Don't be put off by the use of $t$ in these properties; $x$, $y$ or any other letter could also have been used.The letter simply represents a particular value of the rv.

THIS SHOULD BE EARLIER:

The distinction between upper and lower case letters though when discussing rv's is worth noting.Consider the notation $p_X(x)$ used to define the probability function.
The upper case $X$ is the *name* of the random variable; the lower case $x$ is a *particular value* that the random variable $X$ may take.
For example, if I roll a standard die, the random variable of interest may be 'the number on the top face', which may be called $X$.
Then, the *values* that this random variable can take are $x=1$, $x=2$ through to $x=6$.
So the notation $\Pr(X = 1)$ means:

> the probability that the number of the top face (that is, $X$) will be equal (that is, the equal to sign ${}={}$) to the particular value $1$.

In general, upper case (usually Roman, not Greek) letters refer to the *name* of a random variable; lower case Roman letters refer to the values the variable can take.

There are times when it's difficult to know whether its the rv itself or a value of the rv that is being referred to.
Don't lose any sleep over it.



### The probability density function {#ProbabilityDensityFunction}

We run into a major difficulty when attempting to use a probability function to describe the distribution of a continuous rv; that is, a rv that can take on every value in a bounded or unbounded interval.

The problem arises because probability behaves like mass.
In the discrete case we imagine mass can be distributed over a number (possibly countably infinite) of distinct points where each point has non-zero mass.
This is sufficient to tell us all we need to know about the mass or probability associated with any set of points.

In the continuous case, mass cannot be thought of as an attribute of a point but rather of a region surrounding a point in that as an object is shrunk to a single point its mass also shrinks to zero.
The only way we can retain information about how 'massive' an object is at a point is to consider its mass per unit volume in the neighbourhood of that point and consider what happens as the volume of the neighbourhood shrinks to zero.
This measure does not go to zero.
And it is familiar to all of us as (mass) density.

Not only does density have meaning at a point, it allows us to determine the mass of an object by integration if we know the density at every point throughout the mass.

Similarly, to describe the probability distribution for a continuous rv requires us to know the probability density at every point in the range space.
The function describing this density is naturally called the *probability density function* or pdf.
Once the pdf is known we can determine by integration the probability associated with any event defined on the range space.

Many texts either don't explicitly define the pdf or define it indirectly.
The definition given below relates directly to the idea of a density as described above but doesn't tell us much about how to actually find the function.


::: {.definition #ProbabilityDensityFunction name="Probability density function"}
The *probability density function* (pdf) of the continuous rv $X$ is a function $f_X$ such that
\[
   \Pr(a < X \le b) = \int_a^b f_X(x)\,dx
\]
for any interval $(a, b]$ (where $a < b$) on the real line.
:::


We are usually only concerned with $a,b\in R_X$ but it makes sense to think of the pdf as defined for all $x$, insisting that $f_X(x) = 0$ for $x\notin R_x$.
This definition focuses on the idea that areas under the graph of the pdf represent probabilities and leads to the following properties.

The following properties of the probability density function are implied by the definition.

1. $f_X(x) \ge 0$ for all $-\infty < x < \infty$.
2. $\int_{-\infty}^\infty f_X(x)\,dx = 1$.
3. For an event $E$ defined on a sample space $S$, the probability of event $E$ is computed using
   \[
      \Pr(E) = \int_{E} f_X(x)\, dx
   \]
4. $\Pr(a < X \le b) = \Pr(a < X < b) = \Pr(a \le X < b) = \Pr(a \le X \le b) = \int_a^b f_X(x)\,dx$
5. From the mean value theorem in calculus it follows that
   \[ 
      \Pr(x < X < x + \Delta x) = \int ^{x + \Delta x}_x f(t)\, dt = \Delta xf(\xi ), \quad x < \xi < x + \Delta x.
   \]
6. For $\Delta x$ small,
   \begin{equation}
     \Pr(x < X < x +\Delta x)\simeq f(x)\Delta x.
   \end{equation}

Properties 1 and 2 are sufficient to prove that a function is a pdf; ie if we're asked to show that some function $g(x)$ is a pdf all we need do is show that $g(x) \ge 0$ for all $-\infty < x < \infty$ and that $\int_{-\infty}^\infty g(x)\,dx = 1$.

Property 4 results from noting that if $X$ is a continuous rv, $\Pr(X = a ) = 0$ for any and every value~$a$ for the same reason that a point has mass zero.

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
It's important to remember that the value of a pdf at some point $x$ does not represent a probability, but rather a probability density, and as such can have any non-negative value of arbitrary size.
:::

Properties 5 and 6 directly relate the idea of a density to that of a probability.
These properties often find use in making approximations and in theoretical work.

::: {.example #ProbabilityDensityFunction name="Probability density function"}
Consider the continuous rv $W$ with the pdf
\[
   f_W(w) = 2w\quad\text{for $0 < w < 1$}
\]
There are two ways to compute the probability $\Pr(0 < W < 0.5)$.
One is to use the pdf:
\begin{align*}
   \Pr(0 < W < 0.5)
   &= \int_0^{0.5} 2w\, dw\\
   &= w^2\Big|_0^{0.5}\\
   &= 0.25
\end{align*}
Alternately, the probability can be computed *geometrically*.
The pdf is shown in Fig. \@ref(fig:ContinuousPDF).
The region corresponding to $\Pr(0 < W < 0.5)$ is triangular; integration simply finds the area of this region.
The area can also be found using the area of a triangle: the length of the base times the height, divided by two.
So the area shaded is
\[
   \underbrace{0.5}_{\text{base}} \times \overbrace{1}^{\text{height}} /2 = 0.25,
\]
and the answer is the same as before.
:::



```{r ContinuousPDF, echo=FALSE, fig.align="center", fig.caption="CAPTION"}
plot( x = c(-0.5, 1.5),
      y = c(0, 2),
      type = "n",
      las = 1,
      main = "The proability distribution of $W$",
      xlab = "Values of the rv W",
      ylab = "The probability function ???"
)

polygon( x = c(0, 0.5, 0.5, 0),
         y = c(0, 1, 0, 0),
         col = "grey")
lines( x = c(-0.5, 0, 1),
       y = c(0, 0, 2),
       lwd = 2)
lines( x = c(1, 1.5),
       y = c(0, 0),
       lwd = 2)
points(1, 2, 
       pch = 1)
points(1, 0, 
       pch = 19)
```


\begin{figure}
\begin{center}
\includegraphics[scale=0.5,angle=270]{../pics/rvs/conteg.eps}
\caption{The pdf of the rv $W$ from Example~\ref{EG:rvs:conteg}.
The shaded region is $\Pr{0<W<0.5}$.}
\label{FG:rvs:conteg}
\end{center}
\end{figure}



### The distribution function {#DistributionFunction}

Another way of describing rvs is using a *distribution function* (df), also called a *cumulative distribution function* (cdf).
We will use the df description in this course.

The df gives the probability that a random variable $X$ is less than or equal to a given value $t$.

::: {.definition #DistributionFunction name="Distribution function"}
For any rv $X$ the *distribution function*, $F_X(x)$, is given by
\[
     F_X(x) = \Pr(X \leq x) \quad \text{for $-\infty < x < \infty$}
\]
:::
Note that the distribution function applies to discrete or continuous or mixed (see below) rvs.

Two important points to note:

1. The definition includes a less than *or equal to* sign.
2. The distribution function is defined for *all* values of $x$.


If $X$ is a discrete rv with range space $R_x$, the df,
\begin{align*}
     F_X(x)
     &= \Pr(X \leq x)\\
     &= \sum_{x_i \leq x} \Pr(X = x_i)\text{ for }x_i\in R_x,\text{ and }-\infty < x < \infty.
\end{align*}
If $X$ is a continuous rv, the df,
\begin{align*}
     F_(x)
     &= \Pr(X \leq x)\\
     &= \int^x_{-\infty} f(t)\,dt \text{ for } -\infty < x < \infty.
\end{align*}


::: {.example #TossingHeads2 name="Tossing heads"}
Consider the simple example in Example \@ref(exm:TossingHeads).
The probability function for $H$ is given in that Example in numerous forms.
To determine the df, first note that when $t < 0$, the accumulated probability is zero; hence, $F_H(t) = 0$ when $t < 0$.
At $t = 0$, the probability of $0.25$ is accumulated, and no more probability is accumulated until $t = 1$.
Thus, $F_H(t) = 0.25$ for $0 \le t< 1$.
Continuing, the df is 
\[
   F_H(t) = \begin{cases}
               0 & \text{for $t<0$}\\
               0.25 & \text{for $0\le t<1$}\\
               0.75 & \text{for $1\le t<2$}\\
               1 & \text{for $t\ge 2$}
            \end{cases}
\]
Note that the variable $t$ is used where $-\infty < t < \infty$.
The df can be produced graphically, being careful to clarify what happens at $X = 1$, $X = 2$ and $X = 3$ using open or filled circles (see Fig. \@ref(fig:HeadsDF)).
:::



```{r HeadsDF, echo=FALSE, fig.cap="A graphical representation of the distribution function for Example \\ref(exm:TossingHeads2). The filled circles contain the given point, while the empty circles omit the given point."}
plot( x = c(-0.5, 5.5),
      y = c(0, 1.05),
      type = "n",
      las = 1,
      main = "The proability distribution of $H$",
      xlab = "Values of the rv  H",
      ylab = "The probability function ???"
)

abline(h = c(0, 1),
       col = "grey")


lines( x = c(-0.5, 0),
       y = c(0, 0),
       lty = 2,
       lwd = 2)
lines( x = c(0, 1),
       y = c(0.25, 0.25),
       lwd = 2)
lines( x = c(1, 2),
       y = c(0.75, 0.75),
       lwd = 2)
lines( x = c(2, 3),
       y = c(1, 1),
       lwd = 2)
lines( x = c(3, 4),
       y = c(1, 1),
       lwd = 2,
       lty = 2)


points(0, 0, 
       pch = 1)
points(0, 0.25, 
       pch = 19)

points(1, 0.25, 
       pch = 1)
points(1, 0.75, 
       pch = 19)

points(2, 0.75, 
       pch = 1)
points(2, 1, 
       pch = 19)

```




::: {.example #ProbabilityFunction name="Probability function"}
Consider a continuous rv $V$ with pdf
\[
   f_V(v) = \begin{cases}
               v/2 & \text{for $0 < v < 2$}\\
               0 & \text{otherwise}
            \end{cases}
\]
The df is zero whenever $v\le 0$.
For $0 < v < 2$,
\[
   F_V(v) = \int_0^v t/2\,dt = v^2/4.
\]
Whenever $v\ge 2$, the df is one.
So the df is
\[
   F_V(v) = \begin{cases}
               0 & \text{if $v\le 0$}\\
               v^2/4 & \text{if $0< v<2$}\\
               1 & \text{if $v\ge 2$}
             \end{cases}
\]
\Note: For the integral, *do not write*
\[
   \int_0^v v/2\,dv
\]
It makes no sense to have the *variable* of integration as a limit on the integral and also in the function to be integrated.
Either write the integral as given in the example, or write $\int_0^t v/2\,dv = t^2/4$ and then change the variable from $t$ to $v$.
:::

Note that if a random variable $X$ is discrete, then the df will have points of discontinuity.
If the variable is continuous then the df will be continuous.

These and other properties of the df are stated below.

1. $0\leq F_X(x)\leq 1$ because $F_X(x)$ is a probability.
2. $F_X(x)$ is a non-decreasing function of $x$.\\
   If $x_1 <x_2$ then $\{ x:x\leq x_1\} \subset \{ x:x\leq x_2\}$\\
  So $F_X(x_1)=\Pr{X\leq x_1}\leq \Pr{X\leq x_2}=F_X(x_2)$
3. Denoting $\displaystyle{\lim_{x\to \infty} F_X(x)}$ by $F_X(\infty )$ and $\displaystyle{\lim_{x\to -\infty} F_X(x)}$ by $F_X(-\infty )$ we have $F_X(\infty )=1$ and $F_X(-\infty )=0$.
4. $\Pr{a<X \leq b}=F_X(b)-F_X(a)$
5. If $X$ is discrete then $F_X(x)$ is a step-function but if $X$ is continuous $F_X$ will be a continuous function for all $x$.

We can use (2.2) to find $F_X(x)$ given $\Pr(X = x)$ or (3.4) to find $F_X(x)$ given $f_X(x)$ but we need to be able to proceed in the other direction as well.
That is, given $F_X(x)$ how do we find $\Pr{X=x}$ for $X$ discrete or $f_X(x)$ for $X$ continuous?

* It can be seen from the graph of the df in Example~\ref{EG:rvs:heads2} that the values of $x$ where a 'jump' in $F_X(x)$ occurs are the points in the
range space and the probability associated with a particular point in $R_X$ is the 'height' of the jump there.
That is,
\begin{equation}
      p_X(x_j) = \Pr(X = x_j) = F_X(x_j) - F_X(x_{j - 1})
\end{equation}

* For $X$ continuous, from the Fundamental Theorem of Calculus,
  \begin{equation}
     f_X(x) = \frac{dF_X(x)}{dx} \quad \text{where the derivative exists.}
\end{equation}



### Mixed random variables {#MixedRandomVariables}

Some rvs are neither continuous nor discrete, but have parts of both.
These rvs are called *mixed random variables*.

::: {.example #MixedRandomVariable name="Mixed random variable"}
In a factory producing diodes, a fraction of the diodes $p$ fail immediately.
The distribution of the lifetime (in hundred of days), say $Y$, if the diodes is given by a discrete part at $y = 0$ for which $\Pr(Y = 0) = p$ and a continuous part for $y > 0$ described say by the pdf
\[
   f_Y(y) = (1 - p) \exp(-y) \quad \text{if $y > 0$.}
\]
(Strictly speaking $f_Y(y)$ is not a proper pdf because it doesn't integrate to one but we can see that the total probability is
\[
   0.4 + \int_0^\infty 0.6\exp(-y) \, dy = 0.4 + 0.6 = 1
\]
as required.)

Consider a diode for which $p = 0.4$.
The probability distribution is displayed in Figure \@ref(fig:Diode) (left panel) where a solid dot is included to show the discrete part.

```{r Diode, echo=FALSE, fig.align="center", fig.caption="CAPTION"}
par( mfrow = c(1, 2))

p <- 0.4
x <- seq(0, 4, 
         length = 100)
fy <- (1 - p) * exp( - x)
fy[1] <- 1 - p

Fy <- 0.4 + 0.6 * (1 - exp(-x ) )
F[1] <- p

plot(fy ~ x,
     lwd = 2,
     type = "l",
     xlab = "Y",
     ylab = "fY",
     main = "Probability function",
     las = 1)
points( x = 0,
        y = 0.4,
        pch = 1)
points( x = 0,
        y = 0.6,
        pch = 19)


plot(Fy ~ x,
     ylim = c(0, 1),
     lwd = 2,
     type = "l",
     xlab = "Y",
     ylab = "FY",
     main = "Distribution function",
     las = 1)
points( x = 0,
        y = Fy[1],
        pch = 19)
points( x = 0,
        y = 0.4,
        pch = 1)

```

We see there are difficulties representing the probability distribution in this mixed case because we need to combine a probability distribution and a pdf.
These difficulties are circumvented by using the distribution function.
The df of $Y$ is
\[
   F_Y(y) = \begin{cases}
               0 & \text{if $y < 0$}\\
               0.4 & \text{if $y = 0$}\\
               0.4 + 0.6(1 - \exp(-y)) & \text{if $y > 0$}
            \end{cases}
\]
:::


