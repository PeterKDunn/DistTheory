# Distribution of random variables {#DistributionRandomVariables}

::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
Upon completion of this chapter, you should be able to:

* distinguish between discrete, continuous and mixed random variables both for discrete and continuous cases.
* determine the probability function of random variables defined for an experiment.
* determine the distribution function of a random variable from its probability function and apply it to the computation of probabilities of defined events.
* plot the probability function and distribution function of a random variable.
* understand the concept of a mixed random variable and manipulate its probability function.
:::

## Introduction

In Chap. \@ref(Probability), the tools of probability were used to assist in answering questions about phenomena involving uncertainty.
The sample space was defined as the set of all possible outcomes and an event was defined as a subset of the sample space.
Probabilities were associated with events.
The outcomes themselves could be numeric, as in tossing a die, or non-numeric, as in tossing a coin.

Interestingly, it is advantageous to restrict ourselves to *numerical* outcomes from random processes.
This may sound unnecessarily restrictive, but is not.
After all, we could number all the outcomes in the sample space, thereby converting non-numeric elements to numeric ones.
So, for example, heads could be denoted 1 and tails 2 in the sample space associated with tossing a coin.

This might sounds a bit unnecessary and, in the simple case of coin tossing, it probably is.
However using numeric outcomes means we can make use of the powerful concepts that are associated with numbers.
In particular the concepts of discreteness, continuousness, types of infinity, limits, etc. are available.
So what might appear to be restrictive is really the key to unlocking some powerful ideas and results that make probability theory and in turn, statistical theory, incredibly useful.

Of course, in most scientific, engineering and business applications, our interests are in assigning probabilities to numeric outcomes.
For example,

* Probabilities can be assigned to different amounts of money made by an investment
* Probabilities can be assigned to the proportion of people that contract a given disease
* Probabilities can be assigned to observing different water levels at a certain river crossing
* Probabilities can be assigned to matching DNA sequences when their genome sequences are almost identical
* Probabilities can be assigned to recording certain rainfall amounts.

While some experiments give rise to just a limited number of outcomes (e.g., tossing a die), some give rise to an unlimited number of discrete outcomes (e.g., the number of attempts needed to win a lottery), and some give rise to a range of possible outcomes over some interval (e.g., water levels in a dam, rainfall, tomorrow's maximum temperature).
The differences amongst these types of sample spaces is what drives us to thinking in terms of discrete numbers (such as integers) and continuous numbers (such as the reals).

To do this, we define a *random variable* on the sample space, which is a way of converting the elements of the sample space into numbers.
Depending on the type of sample space, this random variable can be discrete, continuous, or a mixture of both.
Regardless, it is useful and important to be able to describe the possible values of the random variable and the probability associated with these values.
This is called the *distribution of the random variable*.


CHECK THE ORDER ON CONCEPTS IN HERE...


:::{.example #DieToss name="Rolling dice"}
When a fair die is rolled, the classical approach to probability can be used to determine the theoretical probabilities 
\begin{align*}
     & \Pr(\text{roll a 1}) = \Pr(\text{roll a 2}) \\
   = &\cdots = \Pr(\text{roll a 6}) = 1/6.
\end{align*}
Define the random variable $X$ as the number of pips showing on the die.
Then, $X = 1$ for the outcome ${1}$. 
Consequently:
\[
   \Pr(X = 1) = \Pr(X = 2) = \dots = \Pr(X = 6) = 1/6
\]
and this is a *model* for describing the distribution of the random variable $X$ for this experiment.
:::


NEED FORMAL DEFN OF *MODEL*?

The idea of a *model* is a theoretical concept.
In practice, when a die is rolled repeatedly, the number of times that each face is observed will not always be 1/6.
The distribution given above is the ideal situation, or the situation as the number of rolls approaches infinity.

The theoretical distribution is said to *model* the experiment.
The classical approach to assignment of probabilities gives us a model in this case.
For other experiments, other models will be appropriate.

This chapter discusses the concept of the *random variable* and the *distribution* of probabilities amongst the values of a random variable.
Later chapters describe specific distributions useful for modelling.


## Random variables {#RandomVariables}

Colloquially, a random variable is a numerical-valued variable. 
A random variable may be *continuous*, *discrete* or a combination of the two.


:::{.definition #DomainRange name="Domain and range"}
A random variable $X$ is a *real-valued function* mapping each element of the sample space onto a real number. 

The *domain* of a random variable is the sample space, and the *range space* or *value set* is the set of real numbers taken by function.
:::

The random variable $X$ can be seen as a rule assigning a number to each and every outcome in the sample space.

Using functional notation, a function $X$ is a random variable if it assigns a real number $X(s)$ to every sample point $s\in S$.
Further, since $X$ is a function, to every $s\in S$ there corresponds exactly one value $X(s)$.
The domain of $X$ is the set $S$ and the range space is the set $\{X(s)\mid s\in S\}$.

Commonly, *random variable* is abbreviated to rv.


### Discrete random variables {#DiscreteRVs}

A *discrete* random variable (rv) is defined on a *discrete* sample space.
Examples of discrete random variables include:

* The number of mice in a cohort of twenty that develop an illness.
* The number of rain events occurring during a week.
* The amount of money in a person's pocket.
* The shoe size of a person.
* The number of attempts needed to win Lotto.
* The number of offspring successfully reared by an endangered species of bird.
* The gender (after coding) of the next customer.

The last example might need explaining.
The sample space for the associated experiment contains two points 'female' and 'male'; i.e., 
\[
   S = \{\text{female}, \text{male}\}.
\]
A random variable, though, must be numeric.
So to be a random variable, 'Gender' must associate the outcomes in the sample space with numerical values.
This can be achieved using an arbitrary coding, such as 0 for 'female' and 1 for 'male'.

We can then write $X(\text{female}) = 0$ and $X(\text{male}) = 1$, where $X$ denotes the random variable 'Gender'.
Notice the range space or value set of $X$ is $\{0,1\}$ which we might denote as $R_X$.

NOTE CODING IS ARBITRARY!

Often we dispense with formal functional notation when defining random variables and write, for example,
\[
   X = 
   \begin{cases} 
      0 & \text{if Gender is female}\\
      1 & \text{if Gender is male}
    \end{cases}.
\]


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Don't confuse the *definition* of a random variable with the *values* of the random variable.

In the last example, the rv 'Gender' can have two values: 'Female' (codeds as 0) or 'Male' (coded as 1). 
'Male', or 0, is not a rv; it is one *value* of the rv 'Gender'.
:::


### Continuous random variables {#ContinuousRVs}

Loosely speaking, a *continuous* random variable is one that can never be measured exactly. 
If a random variable can assume any value, or a set of values, in an interval, then it is called *continuous*. 

For example, consider your height. 
Your height could be recorded as 174\,cm, but with better measuring instruments it may be 174.023\,451\,006\,cm... and even more decimals are possible with even better instruments! 

Even though height may be written down to the nearest centimetre or even millimetre, height itself is still a continuous measure. 
In addition, height does not vary by a distinct amount. 
My baby daughter grows continually; she doesn't grow in jumps of 1cm, for example! 


ADD THING ABOUT MY HIEGHT THE SAME... BUT HT VARIES FROM INDIVIDUAL TO INDIVIDUAL

Examples of continuous random variables include:

* The volume of waste water treated at a sewage plant per day.
* The amount of money made (or lost) by an investment over 12 months.
* The weight of hearts in normal rats.
* The lengths of the wings of butterflies.
* The lifetime of diseased mice after taking an experimental drug.
* The yield of barley from a large paddock.
* The amount of rainfall recorded each year.
* The time taken to perform a psychological test.


### Mixed random variables {#MixedRVs}

Mixed random variables are less common. 

Typically, they consist of a quantity that can be measured exactly (discrete) sometimes and inexactly (continuous) at other times. 

For example, consider the time spent waiting at a set of traffic lights before proceeding.
If the light is green when you arrive, you can drive straight through; the wait time is exactly zero seconds (this is the discrete component). 
If the light is red when you arrive, you have to wait a continuous amount of time before it turns green.
Hence, the time spent waiting is a mixed random variable.


::: {.example #BabyBoom name="Baby Boom data"}
The *Sunday Mail* newspaper (Brisbane, Australia) on 21 December 1997 gave data giving the birth weight, gender, and time of birth of 44 babies born in the 24-hour period of 18 December 1997 at the Mater Mother's Hospital in Brisbane, Australia. 

For these variables:

* The gender of the babies is a *discrete* random variable; 
* The birth weight is a continuous random variable; and
* The time of birth is a continuous random variable.

The data can be used to determine other random variables, such as:

* The number of births each hour (discrete); and 
* The time between births (continuous).
:::


::: {.example #TossingCoinOutcomes name="Tossing coin outcpmes"}
Consider tossing a coin twice and observing the outcome of the two tosses. 

Since a random variable is a *real-valued function*, simply observing the outcome as $\{H, T\}$, for example, is not a rv. 

We could define the rv of interest, say $H$, as the *number* of heads on the two tosses of the coin.
The *sample space* for the experiment is 
\[
   S = \{ (TT), (TH), (HT), (HH)\}.
\]
The connection between the sample space and $H$ is shown in Table \@ref(tab:CoinsSampleSpace).

In this case, the range of $H$ is $R_H = \{0, 1, 2\}$.
:::


```{r CoinsSampleSpace, echo=FALSE}
rvTable <- array( dim = c(4, 3))
colnames(rvTable) <- c("Elements of $S$",
                       "Function $H$",
                       "Value of $H$")

rvTable [1, ] <- c("$(TT) = s_1$",
                   "$H(s_1)$, the number of heads in $s_1$",
                   "0")
rvTable [2, ] <- c("$(TH) = s_2$",
                   "$H(s_2)$, the number of heads in $s_2$",
                   "1")
rvTable [3, ] <- c("$(HT) = s_3$",
                   "$H(s_3)$, the number of heads in $s_3$",
                   "1")
rvTable [4, ] <- c("$(HH) = s_4$",
                   "$H(s_4)$, the number of heads in $s_4$",
                   "2")
knitr::kable(rvTable,
             align = "c",
             caption = "The random variable $H$ maps each element in the sample space $S$ to a real number")
```


Methods for describing random variables, and how probabilities are assigned or distributed amongst the values of a random variable, occupies much of this book.

One reasons for distinguishing between discrete, continuous and mixed random variables is that the ways we can describe the distribution of probabilities depend to some extent on this distinction.



## Univariate distributions {#Univariate}

This section focuses on methods of describing the distribution of probabilities amongst the values of one random variable.
Discrete and continuous rvs are considered separately.

ADD MIXED?

* Tweedie
* OTHER? 


### The probability function {#ProbabilityFunction}

The *probability function* is a function that indicates how probabilities are assigned to the values of a discrete rv; that is, a rv with range space that is finite or countably infinite.


::: {.definition #ProbabilityFunction name="Probability function"}
Let the range space of the discrete rv $X$ be $R_X$.
With each $x\in R_X$, associate a number 

\[
   p_X(x) = \Pr(X = x)
\]
The function $p_X$ is called the *probability function* of $X$.
:::


The probability function for discrete rvs is often called the *probability mass function*.


::: {.definition #ProbabilityDistribution name="Probability distribution"}
If
\[
   R_X =\{ x_1, x_2, \dots, x_n, \dots \},
\]
the set
\[
   \{ (x_i, p_X(x_i); \quad i = 1, 2,\dots\}
\]
is called the *probability distribution* of the discrete rv $X$.
:::

Sometimes the probability function is denoted $p(x)$ rather than $p_X(x)$.
Using the subscript is recommended to avoid confusion in situations where a number of random variables are considered at once; if we are dealing with the discrete rv's $X$ and $Y$, the respective probability distributions can be denoted by $p_X$ and $p_Y$ respectively.
We use this subscript idea where appropriate throughout this course.

The probability distribution of a random variable is a description of the range space, or value set, of the variable and the associated assignment of probabilities.

The probability distribution of a discrete rv $X$ can be represented by a formula, a table or a graph which displays the probabilities $p(x)$ corresponding to each $x\in R_X$.


::: {.example #Independence name="Independence"}
Five balls numbered 1, 2, 3, 4, 5 are in a box.
Two balls are selected at random.

To find the probability distribution of the *larger* of the two numbers, first list the sample space:
\[ 
    S =\{ (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)\},
\]
and all 10 points are equally likely.

Let rv $X$ be the *larger* of the two numbers chosen.
Then $R_X = \{2, 3, 4, 5\}$ and
\begin{align*}
     \Pr(X = 2) &= \Pr((1,2)) = 1/10\\
     \Pr(X = 3) &= \Pr((1,3) \text{ or }  (2,3)) = 2/10\\
     \Pr(X = 4) &= \Pr((1,4) \text{ or } (2,4) \text{ or } (3,4)) = 3/10\\
     \Pr(X = 5) &= \Pr((1,5) \text{ or } (2,5) \text{ or } (3,5)\text{ or } (4,5)) = 4/10.
\end{align*}
This is the probability distribution of $X$, which can be also expressed as a formula:
\[ 
   \Pr(X = x) = (x - 1)/10, \quad x = 2, 3, 4, 5, 
\]
or shown in a table (Table \@ref(tab:LargestDie)) or as a graph as in Fig. \@ref(fig:ProbDist1).
For discrete distributions, the pf can be displayed using the 'stick'. REWORD!!!

:::

```{r LargestDie, echo=FALSE}
LargestDieTable <- array( dim = c(2, 4)) 

rownames(LargestDieTable) <- c("$x$",
                               "$\\Pr(X = x)$")

LargestDieTable[1, ] <- 2:5
LargestDieTable[2, ] <- ( (2:5) - 1 ) / 10

knitr::kable(LargestDieTable,
             caption = "A table showing the distribution of $X$, the largest number in two rolls of a die")
```



```{r ProbDist1, echo=FALSE, fig.align="center", fig.cap="CAPTION"}
plot( x = 2:5,
      y = c(0.1, 0.2, 0.3, 0.4),
      xlim = c(1.75, 5.25),
      ylim = c(0, 0.4),
      type = "h",
      las = 1,
      lty = 3,
      lwd = 1,
      col = "grey",
      main = expression( 
        paste( "The probability distribution of ", italic(X)) 
        ),
      xlab = expression( 
        paste("Values of the rv ", italic(X)) 
        ),
      ylab = expression( 
        paste( "The probability function ", italic(p)[italic(X)](italic(x)) )
      )
)
points( x = 2:5,
        y = c(0.1, 0.2, 0.3, 0.4),
        pch = 19)

```
 

MOVE TO EXERCISES??
*Computer exercise* Write an R function to allow you to simulate the distribution in this example.


::: {.example #TossingHeads name="Tossing heads"}
Suppose a fair coin is tossed twice.
Then the *sample space* is 
\[
   S = \{HH, HT, TH, TT\}.
\]
Let $H$ be the *number* of heads observed.
$H$ is a (discrete) random variable, and the range of $H$ is $R_H = \{0, 1, 2\}$, representing the values that $H$ can take.

The probability function maps each of these values to the associated probability.
Using techniques from Chap. \@ref(Probability), the probabilities can be computed as:
\begin{align*}
   \Pr(H = 0) &= \Pr(\text{no heads}) = 0.25\\
   \Pr(H = 1) &= \Pr(\text{one head}) = 0.5\\
   \Pr(H = 2) &= \Pr(\text{two heads}) = 0.25.
\end{align*}
As a function, the probability function could be written
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
               0.25 & \text{if $h = 0$}\\
               0.5 & \text{if $h = 1$}\\
               0.25 & \text{if $h = 2$}\\
               0 & \text{otherwise}
              \end{cases}
\]
(Recall that the upper case $H$ refers to the *name* of the rv.)
The more adventurous may write
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
                  (0.5)0.5^{|h - 1|} & \text{for $h = 0$, $1$ or $2$}\\
                  0 & \text{otherwise}
              \end{cases}
\]
This information can also be presented as a table (Table \@ref(tab:TwoDieRV)) or graph (Fig. \@ref(fig:ProbDistributionCoin)).

Note that $\sum_{t \in \{0, 1, 2\}} p_H(t) = 1$ and $p_H(h)\ge0$ for all $h$ as required of a pf.
:::


```{r TwoDieRV, echo=FALSE}
TwoDieTable <- array( dim = c(2, 3)) 

rownames(TwoDieTable) <- c("$h$",
                           "$\\Pr(H = h)$")

TwoDieTable[1, ] <- 0:2
TwoDieTable[2, ] <- c(0.25, 0.50, 0.25)

knitr::kable(TwoDieTable,
             caption = "A table showing the distribution of $H$, the number of heads in two rolls of a die")
```



```{r ProbDistributionCoin, echo=FALSE, fig.align="center", fig.cap="CAPTION"}
plot( x = 0:2,
      y = c(0.25, 0.50, 0.25),
      ylim = c(0, 0.55),
      type = "h",
      las = 1,
      lty = 3,
      col = "grey",
      main = expression(
        paste("The probability distribution of ", italic(H))
        ),
      xlab = expression(
        paste("Values of the rv ", italic(H) )
        ),
      ylab = expression(
        paste("The probability function ", italic(p)[italic(H)](italic(h)))
      )
)

points( x = 0:2,
        y = c(0.25, 0.5, 0.25),
        pch = 19)

```


The following properties of the probability function are implied by the definition.

1. $p_X(t) \ge 0$ for all values of $t$; that is, probabilities are never negative.
2. $\displaystyle \sum_{t \in R_X}  p_X(t) = 1$ where $R_X$ is the range of $X$; that is, the probability function accounts for all possible sample points in the sample space.
3. $p_X(t) = 0$ if $t \notin R_X$.
4. For an event $A$ defined on a sample space $S$, the probability of event $A$ is computed using
   \[
      \Pr{A} = \sum_{t\in A} p_X(t).
   \]

Don't be put off by the use of $t$ in these properties; $x$, $y$ or any other letter could also have been used.The letter simply represents a particular value of the rv.

THIS SHOULD BE EARLIER:


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The distinction between upper and lower case letters though when discussing rv's is worth noting.
Consider the notation $p_X(x)$ used to define the probability function.
The upper case $X$ is the *name* of the random variable; the lower case $x$ is a *particular value* that the random variable $X$ may take.
For example, if I roll a standard die, the random variable of interest may be 'the number on the top face', which may be called $X$.
Then, the *values* that this random variable can take are $x = 1$, $x = 2$ through to $x = 6$.
So the notation $\Pr(X = 1)$ means:

> the 'probability that the number of the top face' (that is, $X$) will be equal (that is, the equal to sign ${}={}$) to 'the particular value $1$'.

In general, upper case (usually Roman, not Greek) letters refer to the *name* of a random variable; lower case Roman letters refer to the values the variable can take.

There are times when it's difficult to know whether its the rv itself or a value of the rv that is being referred to.
Don't lose any sleep over it.
:::



### The probability density function {#ProbabilityDensityFunction}


FIX INTRO!



Using probability functions to describe the distribution of a continuous rv is tricky, because probability behaves like mass.
In the discrete case, we imagine mass can be distributed over a number (possibly countably infinite) of distinct points where each point has non-zero mass.
This is sufficient to tell us all we need to know about the mass or probability associated with any set of points.

However, in the continuous case, mass cannot be thought of as an attribute of a *point* but rather of a *region* surrounding a point.
The only way we can retain information about how 'massive' an object is at a point is to consider its mass per unit volume in the neighbourhood of that point and consider what happens as the volume of the neighbourhood shrinks to zero.
This measure does not go to zero.
And it is familiar to all of us as (mass) density.

Not only does density have meaning at a point, it allows us to determine the mass of an object by integration if we know the density at every point throughout the mass.

Similarly, to describe the probability distribution for a continuous rv requires us to know the probability density at every point in the range space.
The function describing this density is naturally called the *probability density function* or pdf.
Once the pdf is known we can determine by integration the probability associated with any event defined on the range space.

Many texts either don't explicitly define the pdf or define it indirectly.
The definition given below relates directly to the idea of a density as described above, but doesn't tell us how to find the function.


::: {.definition #ProbabilityDensityFunction name="Probability density function"}
The *probability density function* (pdf) of the continuous rv $X$ is a function $f_X(\cdot)$ such that
\[
   \Pr(a < X \le b) = \int_a^b f_X(x)\,dx
\]
for any interval $(a, b]$ (where $a < b$) on the real line.
:::


We are usually only concerned with $a, b\in R_X$, but it makes sense to think of the pdf as defined for all $x$, insisting that $f_X(x) = 0$ for $x\notin R_x$.
This definition states that *areas under the graph of the pdf represent probabilities* and leads to the following properties.

The following properties of the probability density function are implied by the definition.

1. $f_X(x) \ge 0$ for all $-\infty < x < \infty$.
2. $\int_{-\infty}^\infty f_X(x)\,dx = 1$.
3. For an event $E$ defined on a sample space $S$, the probability of event $E$ is computed using
   \[
      \Pr(E) = \int_{E} f_X(x)\, dx
   \]
4. $\Pr(a < X \le b) = \Pr(a < X < b) = \Pr(a \le X < b) = \Pr(a \le X \le b) = \int_a^b f_X(x)\,dx$
5. From the *Mean Value Theorem* in calculus,
   \[ 
      \Pr(x < X < x + \Delta x) = \int ^{x + \Delta x}_x f(t)\, dt = \Delta xf(\xi ), \quad x < \xi < x + \Delta x.
   \]
6. For $\Delta x$ small,
   \begin{equation}
     \Pr(x < X < x +\Delta x)\simeq f(x)\Delta x.
   \end{equation}

Properties 1 and 2 are sufficient to prove that a function is a pdf; ie if we're asked to show that some function $g(x)$ is a pdf all we need do is show that $g(x) \ge 0$ for all $-\infty < x < \infty$ and that $\int_{-\infty}^\infty g(x)\,dx = 1$.

Property 4 results from noting that if $X$ is a continuous rv, $\Pr(X = a ) = 0$ for any and every value $a$ for the same reason that a point has mass zero.

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
It's important to remember that the value of a pdf at some point $x$ does not represent a probability, but rather a probability density, and as such can have any non-negative value of arbitrary size.
:::

Properties 5 and 6 directly relate the idea of a density to that of a probability.
These properties often find use in making approximations and in theoretical work.


::: {.example #ProbabilityDensityFunction name="Probability density function"}
Consider the continuous rv $W$ with the pdf
\[
   f_W(w) = 2w\quad\text{for $0 < w < 1$}.
\]
There are two ways to compute the probability $\Pr(0 < W < 0.5)$.
One is to use the pdf:
\begin{align*}
   \Pr(0 < W < 0.5)
   &= \int_0^{0.5} 2w\, dw\\
   &= w^2\Big|_0^{0.5}\\
   &= 0.25
\end{align*}
Alternately, the probability can be computed *geometrically*.
The pdf is shown in Fig. \@ref(fig:ContinuousPDF).
The region corresponding to $\Pr(0 < W < 0.5)$ is triangular; integration simply finds the area of this region.
The area can also be found using the area of a triangle: the length of the base of the triangle, times the height of the rectangle, divided by two:
\[
   0.5 \times 1 /2 = 0.25,
\]
and the answer is the same as before.
:::



```{r ContinuousPDF, echo=FALSE, fig.align="center", fig.cap="The probability function for $W$"}
plot( x = c(-0.5, 1.5),
      y = c(0, 2),
      type = "n",
      las = 1,
      main = expression(
        paste("The proability distribution of ", italic(W))
        ),
      xlab = expression(
        paste("Values of the rv ", italic(W))
        ),
      ylab = expression(
        paste("The probability function ", italic(p)[italic(W)](italic(w)))
      )
)

polygon( x = c(0, 0.5, 0.5, 0),
         y = c(0, 1, 0, 0),
         col = "grey")
lines( x = c(-0.5, 0, 1),
       y = c(0, 0, 2),
       lwd = 2)
lines( x = c(1, 1.5),
       y = c(0, 0),
       lwd = 2)
points(1, 2, 
       pch = 1)
points(1, 0, 
       pch = 19)
```




### The distribution function {#DistributionFunction}

Another way of describing rvs is using a *distribution function* (df), also called a *cumulative distribution function* (cdf).
We will use the df description in this course.

The df gives the probability that a random variable $X$ is less than or equal to a given value $t$.

::: {.definition #DistributionFunction name="Distribution function"}
For any rv $X$ the *distribution function*, $F_X(x)$, is given by
\[
     F_X(x) = \Pr(X \leq x) \quad \text{for $-\infty < x < \infty$}
\]
:::
Note that the distribution function applies to discrete or continuous or mixed (see below) rvs.

Two important points to note:

1. The definition includes a less than *or equal to* sign.
2. The distribution function is defined for *all* values of $x$.


If $X$ is a discrete rv with range space $R_x$, the df,
\begin{align*}
     F_X(x)
     &= \Pr(X \leq x)\\
     &= \sum_{x_i \leq x} \Pr(X = x_i)\text{ for }x_i\in R_x,\text{ and }-\infty < x < \infty.
\end{align*}
If $X$ is a continuous rv, the df,
\begin{align*}
     F_(x)
     &= \Pr(X \leq x)\\
     &= \int^x_{-\infty} f(t)\,dt \text{ for } -\infty < x < \infty.
\end{align*}


::: {.example #TossingHeads2 name="Tossing heads"}
Consider the simple example in Example \@ref(exm:TossingHeads).
The probability function for $H$ is given in that Example in numerous forms.
To determine the df, first note that when $t < 0$, the accumulated probability is zero; hence, $F_H(t) = 0$ when $t < 0$.
At $t = 0$, the probability of $0.25$ is accumulated, and no more probability is accumulated until $t = 1$.
Thus, $F_H(t) = 0.25$ for $0 \le t< 1$.
Continuing, the df is 
\[
   F_H(t) = \begin{cases}
               0 & \text{for $t<0$}\\
               0.25 & \text{for $0\le t<1$}\\
               0.75 & \text{for $1\le t<2$}\\
               1 & \text{for $t\ge 2$}
            \end{cases}
\]
Note that the variable $t$ is used where $-\infty < t < \infty$.
The df can be produced graphically, being careful to clarify what happens at $X = 1$, $X = 2$ and $X = 3$ using open or filled circles (see Fig. \@ref(fig:HeadsDF)).
:::



```{r HeadsDF, echo=FALSE, fig.cap="A graphical representation of the distribution function for Example \\ref(exm:TossingHeads2). The filled circles contain the given point, while the empty circles omit the given point."}
plot( x = c(-0.5, 4),
      y = c(0, 1.05),
      type = "n",
      las = 1,
      main = expression(
        paste("The probability distribution of ", italic(H))
        ),
      xlab = expression(
        ),
      ylab = expression(
        paste("The probability function ",italic(p)[italic(H)](italic(h)))
      )
)

abline(h = c(0, 1),
       col = "grey")


lines( x = c(-0.5, 0),
       y = c(0, 0),
       lty = 2,
       lwd = 2)
lines( x = c(0, 1),
       y = c(0.25, 0.25),
       lwd = 2)
lines( x = c(1, 2),
       y = c(0.75, 0.75),
       lwd = 2)
lines( x = c(2, 3),
       y = c(1, 1),
       lwd = 2)
lines( x = c(3, 4),
       y = c(1, 1),
       lwd = 2,
       lty = 2)


points(0, 0, 
       pch = 1)
points(0, 0.25, 
       pch = 19)

points(1, 0.25, 
       pch = 1)
points(1, 0.75, 
       pch = 19)

points(2, 0.75, 
       pch = 1)
points(2, 1, 
       pch = 19)

```




::: {.example #ProbabilityFunction name="Probability function"}
Consider a continuous rv $V$ with pdf
\[
   f_V(v) = \begin{cases}
               v/2 & \text{for $0 < v < 2$}\\
               0 & \text{otherwise}
            \end{cases}
\]
The df is zero whenever $v\le 0$.
For $0 < v < 2$,
\[
   F_V(v) = \int_0^v t/2\,dt = v^2/4.
\]
Whenever $v\ge 2$, the df is one.
So the df is
\[
   F_V(v) = \begin{cases}
               0 & \text{if $v\le 0$}\\
               v^2/4 & \text{if $0< v<2$}\\
               1 & \text{if $v\ge 2$}
             \end{cases}
\]
A picture of the df is shown in Fig. \@ref(fig:DFCont).
:::

```{r DFCont, echo=FALSE, fig.align="center", fig.cap="The distribution function of $V$"}
vb <- seq(0, 2,
         length = 100)
vbDF <- ( vb ^ 2 ) / 4

plot( x = c(-2, 4),
      y = c(0, 1),
      type = "n",
      xlab = expression(italic(v)),
      ylab = "Distribution function",
      las = 1)
lines( x = c(-2, -1),
       y = c(0, 0),
       lwd = 3,
       lty = 2)
lines( x = c(-1, 0),
       y = c(0, 0),
       lwd = 3,
       lty = 1)
lines( vbDF ~ vb,
       lwd = 3)
lines( x = c(2, 3),
       y = c(1, 1),
       lwd = 3)
lines( x = c(3, 4),
       y = c(1, 1),
       lwd = 3,
       lty = 2)
```


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
For the integral, *do not write*
\[
   \int_0^v v/2\,dv.
\]
It makes no sense to have the *variable* of integration as a limit on the integral and also in the function to be integrated.
Either write the integral as given in the example, or write $\int_0^t v/2\,dv = t^2/4$ and then change the variable from $t$ to $v$.
:::


Properties of the df are stated below.

1. $0\leq F_X(x)\leq 1$ because $F_X(x)$ is a probability.
2. $F_X(x)$ is a non-decreasing function of $x$.
   If $x_1 < x_2$ then $\{ x:x\leq x_1\} \subset \{ x:x\leq x_2\}$.
   So $F_X(x_1) = \Pr(X \leq x_1)\leq \Pr(X\leq x_2) = F_X(x_2)$.
3. Denoting $\displaystyle{\lim_{x\to \infty} F_X(x)}$ by $F_X(\infty )$ and $\displaystyle{\lim_{x\to -\infty} F_X(x)}$ by $F_X(-\infty )$ we have $F_X(\infty ) = 1$ and $F_X(-\infty) = 0$.
4. $\Pr(a < X \leq b) = F_X(b) - F_X(a)$.
5. If $X$ is discrete, then $F_X(x)$ is a step-function but if $X$ is continuous $F_X$ will be a continuous function for all $x$.

We can use (2.2) to find $F_X(x)$ given $\Pr(X = x)$ or (3.4) to find $F_X(x)$ given $f_X(x),$ but we need to be able to proceed in the other direction as well.
That is, given $F_X(x)$, how do we find $\Pr(X = x)$ for $X$ discrete or $f_X(x)$ for $X$ continuous?

* As seen from the graph of the df in Example \@ref(exm:TossingHeads2), the values of $x$ where a 'jump' in $F_X(x)$ occurs are the points in the range space and the probability associated with a particular point in $R_X$ is the 'height' of the jump there.
That is,
\begin{equation}
      p_X(x_j) = \Pr(X = x_j) = F_X(x_j) - F_X(x_{j - 1})
\end{equation}

* For $X$ continuous, from the Fundamental Theorem of Calculus,
  \begin{equation}
     f_X(x) = \frac{dF_X(x)}{dx} \quad \text{where the derivative exists.}
\end{equation}



### Mixed random variables {#MixedRandomVariables}

Some rvs are neither continuous nor discrete, but have parts of both.
These rvs are called *mixed random variables*.

::: {.example #MixedRandomVariable name="Mixed random variable"}
In a factory producing diodes, a fraction of the diodes $p$ fail immediately.
The distribution of the lifetime (in hundred of days), say $Y$, if the diodes is given by a discrete part at $y = 0$ for which $\Pr(Y = 0) = p$ and a continuous part for $y > 0$ described say by the pdf
\[
   f_Y(y) = (1 - p) \exp(-y) \quad \text{if $y > 0$.}
\]
(Strictly speaking $f_Y(y)$ is not a proper pdf because it doesn't integrate to one but we can see that the total probability is
\[
   0.4 + \int_0^\infty 0.6\exp(-y) \, dy = 0.4 + 0.6 = 1
\]
as required.)

Consider a diode for which $p = 0.4$.
The probability distribution is displayed in Figure \@ref(fig:Diode) (left panel) where a solid dot is included to show the discrete part.

```{r Diode, echo=FALSE, fig.align="center", fig.cap="The probability function and distribution function for the diodes example"}
par( mfrow = c(1, 2))

p <- 0.4
x <- seq(0, 4, 
         length = 100)
fy <- (1 - p) * exp( - x)
fy[1] <- 1 - p

Fy <- 0.4 + 0.6 * (1 - exp(-x ) )
F[1] <- p

plot(fy ~ x,
     lwd = 2,
     type = "l",
     xlab = expression(italic(Y)),
     ylab = expression(italic(f)[italic(y)](italic(y))),
     main = "Probability function",
     las = 1)
points( x = 0,
        y = 0.4,
        pch = 19)
points( x = 0,
        y = 0.6,
        pch = 1)


plot(Fy ~ x,
     ylim = c(0, 1),
     lwd = 2,
     type = "l",
     xlab = expression(italic(Y)),
     ylab = expression(italic(F)[italic(y)](italic(y))),
     main = "Distribution function",
     las = 1)
points( x = 0,
        y = Fy[1],
        pch = 19)
points( x = 0,
        y = 0.4,
        pch = 1)

```

We see there are difficulties representing the probability distribution in this mixed case because we need to combine a probability distribution and a pdf.
These difficulties are circumvented by using the distribution function.
The df of $Y$ is
\[
   F_Y(y) = \begin{cases}
               0 & \text{if $y < 0$}\\
               0.4 & \text{if $y = 0$}\\
               0.4 + 0.6(1 - \exp(-y)) & \text{if $y > 0$}
            \end{cases}
\]
:::


