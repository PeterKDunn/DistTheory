# Distribution of random variables {#DistributionRandomVariables}

::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
Upon completion of this chapter, you should be able to:

* distinguish between discrete, continuous and mixed random variables.
* determine the probability function of random variables defined for a random process, and apply it to the computation of probabilities of defined events.
* determine the distribution function of a random variable from its probability function, and apply it to the computation of probabilities of defined events.
* plot the probability function and distribution function of a random variable.
:::


## Introduction

While some random processes have a limited number of outcomes (e.g., tossing a die), some have an unlimited number of discrete outcomes (e.g., the number of attempts needed to win a lottery), and some have a range of possible outcomes over some interval (e.g., tomorrow's maximum temperature).
The differences amongst these types of sample spaces lead to thinking in terms of discrete numbers (such as integers) and continuous numbers (such as the reals).

To do this, we define a *random variable* on the sample space.


## Random variables {#RandomVariables}

Chap. \@ref(Probability) introduced the language and tools of probability to describe uncertainty.
The concept of the [*sample space*](#def:SampleSpace) was introduced, which describes the possible outcomes of a [*random process*](#def:Process).
Often, however, the elements of the sample space are not of direct interest... especially if a discrete sample space contains many elements.
Combinations of these sample space elements are usually of greater interest and more convenient to work with.

For example, the sample space for the observing the rolls of two dice (Example \@ref(exm:TwoDice)) contains 36 elements.
We may be interested in the *sum* of the two rolls anyway, rather than which elements in the sample space gave rise to the sum.
That is, we may be more interested in *whether* we roll a sum of 5 than *how* that sum of 5 was obtained.
We can 'collect' various elements of the sample space together and treat them as a collective of what we are interested in.

More generally, collecting elements of the sample space together is useful, and we can assign a real number to that collection.
This leads to the idea of a *random variable*.

**NOT SURE THAT IS ALL CORRECT SO CHECK**


:::{.definition #RandomVariable name="Random variable"}
A *random variable* is some function that assigns a real number (say, $X(s)$) to each outcome $s$ in the sample space $S$.

That is, its *domain* (i.e., input) is elements of the sample space of a random process, and the results is a real value. 
:::

Since $X$ is a function, every $s\in S$ is assigned to exactly one value $X(s)$.
(The converse is not true: many values of $s\in S$ may be assigned to the same value of $X(s)$.)

*Random variable* may be abbreviated to rv.

:::{.definition #DomainRange name="Domain and range space"}
The *domain* of a random variable is the sample space, and the *range space* or *value set* is the set of real numbers taken by function.

The *range space* for a random variable $X$ is often denoted $R_X$.
:::

The domain of $X$ is the set $S$ and the range space is the set $\{X(s)\mid s\in S\}$.

The variable is *random* since its value depends upon the outcome of the random process.

A capital letter (such as $Y$) is usually used to denote the *description* of the random variable, while lower-case letters (such as $y$) are used to describe the *values* of the random variable.
For example, if we write $Y = 3$, this means:

* 'The sum of the roll of two dice...' (that is, $Y$)
* '...is equal to...' (that is, the ${} = {}$ sign)
* '... the value 3.' (that is, he specific value $3$)



:::{.example #TwoDiceRV name="Sum of two dice rolls"}
Consider observing the rolls of two dice.
The sample space contains 36 elements (Example \@ref(exm:TwoDice)), and could be denoted as $(r_1, r_2)$, where $r_1$ and $r_2$ are the results of roll 1 and 2 respectively. 
The sample space is listed in Table \@ref(tab:TwoDice).

Then, we could define the random variable $Y$ on this sample space as:
\[
   Y = r_1 + r_2.
\]
In this way, every outcome in the sample space is assigned a real value.
Then, for example, the elements of $S$ assigned to $Y = 4$ are
\[ 
   (1, 3), (2, 2), (3, 1).
\]
Notice that many elements of the sample space can be assigned to the same value of the random variable.

The (real) values that $Y$ can take are $2, 3, \dots 12$.
:::

Sample space elements   | Value of random variable
------------------------|---------------
(1, 1)                  |  2
(1, 2), (2, 1)          |  3
(1, 3), (2, 2), (3, 1)  |  4
$\vdots$                | $\vdots$
(6, 6)                  | 12


:::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
*Random variables* are different than *variables* used in (for example) algebra.
In algebra, a "variable" is the value of an unknown quantity.
:::


:::{.example #DrawTwoCards name="Drawing two cards"}
Consider drawing two cards from a standard, well-shuffled pack of cards, and observing the colour of the card (B: Black; R: Red).
The sample space $\Omega$ is:
\[
   \Omega = \{ (BB), (BR), (RR), (RB)\}.
\]
Many random variables could be defined on this sample space; for example:
\begin{align*}
   T&: \text{The number of black cards drawn};\\
   M&: \text{The number of red cards drawn on the first draw};\\
   D&: \text{The number of black cards drawn,}\\
    &\quad \text{minus the number of red cards drawn}.
\end{align*}
All of these assign a real number to each element of $\Omega$.
The random variable $D$, for instance, is defined as:

Sample space elements | Value of $D$
----------------------|-----------------
$(BR)$ and $(RB)$     | $D = 0$
$(BB)$                | $D = 2$
$(RR)$                | $D = -2$

:::


:::{.example #TossCoinTillHead name="Tossing a coin till a head appears"}
Consider the random process 'tossing a coin until a Head is observed'.

The sample space is
\[
   \Omega = \{(H), (TH), (TTH), (TTTH), \dots \}.
\]
We could then define the random variable $N$ as 'the number of tosses until the first head is thrown'.
Then each element of the sample space can be assigned to a real number:
\begin{align*}
   (H)\quad&\text{is assigned to}\quad N = 1;\\
   (TH)\quad&\text{is assigned to}\quad N = 2\\
   (TTH)\quad&\text{is assigned to}\quad N = 3,
\end{align*}
and so on.
Writing $N = 2$ means 'the number of tosses to observe the first head is two'.
:::





## Discrete, continuous and mixed random variables {#DiscreteContMixed}

Random variables can be discrete, continuous, or a mixture of both.


### Discrete random variables

:::{.definition #DiscreteRV name="Discrete random variable"}
A **discrete random variable** contains a finite or countably infinite number of values.
:::


:::{.example}
In Example \@ref(exm:TwoDiceRV), exactly 11 values of the random variable $Y$ are possible: $2, 3, \dots 12$.

In Example \@ref(exm:DrawTwoCards), the random variable $D$ can take one of three possible values: $-2, 0\text{ or }2$.

In Example \@ref(exm:TossCoinTillHead), the random variable $N$ takes a *countably infinite* number of possible values: $1, 2, 3, \dots$
:::


Notice that this definition refers to the values of random variable, not to the [sample space](#def:SDiscreteSampleSpace) (i.e., the inputs to the function).



### Continuous random variables

For a [continuous sample space](#def:ContinuousSampleSpace), the random variable is usually the *identity function* $Y(s) = s$.

For example, in Example \@ref(exm:ContinuousSampleSpaceThrow) the sample space that describes how far a cricket ball can be thrown is already defined on the (positive) reals.
Hence, we can define the random variable as $T(s) = s$, where $s$ is the distance specified in the sample space.

**IS that correct? Do we need to work with an *interval* in there?**


:::{.definition #ContinuousRF name="Continuous random variable"}
A **continuous random variable** can take on any value within any given interval.
:::

A continuous random variable can never, in principle, be measured exactly... so in practice needs to be rounded.
If a random variable can assume any value, or a set of values, in an interval, then it is *continuous*. 


:::{.example #ContinuousRVHeight name="Heights"}
Height is often recorded to the nearest centimetre (e.g., 179cm), but that is for convenience and practicality. 
Better measuring instruments may be able to record height to one or more decimal places of a centimetre.
:::

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
Even though *your* height may not change, the notion of a *random variable* means that height varies from one realisation of the random process to another; that is, from one *person* to the next.
:::

Examples of continuous random variables include:

* The volume of waste water treated at a sewage plant per day.
* The amount of money made (or lost) by an investment over 12 months.
* The weight of hearts in normal rats.
* The lengths of the wings of butterflies.
* The lifetime of diseased mice after taking an experimental drug.
* The yield of barley from a large paddock.
* The amount of rainfall recorded each year.
* The time taken to perform a psychological test.



### Mixed random variables

Some sample spaces have subsets that are discrete, and some that are continuous.
These are called *mixed random variables*.

:::{.definition #MixedRF name="Mixed random variable"}
A **mixed random variable** has regions where the random variable is [discrete](#def:DiscreteRF) and regions where it is [continuous](#def:ContinuousRF).
:::


:::{.example #MixeVehicleWait name="Vehicle wait times"}
Consider the time spent by vehicles waiting at a set of traffic lights before proceeding through the intersection.

If the light is green on arrival, the wait time is exactly zero (i.e., discrete): the vehicle can drive straight through the intersection.

However, if the light is red on arrival, the vehicle needs to  wait a continuous amount of time before it turns green.

The time spent waiting is a *mixed* random variable.
:::




## Univariate probability functions {#UnivariateProbabilityFunctions}

The previous section introduced *random variables*: real values assigned to outcomes in the sample space.
Often, many elements of the sample space were assigned to the same value of the random variable.
Therefore, we can assign *probabilities* to various values of the random variable., and develop a *probability model* for the random variable.

A *model* describes theoretical long-term patterns.
On any single roll of a die, a **4** may or may not occur, but theoretically (and in the long term) we expect a **4** to appear about 1/6 of the time.
A *probability model* describes the probability that various values of the random variable will appear on any one realisation in theory.

This probability model is called the *probability function*.

::: {.example #TossingCoinOutcomes name="Tossing coin outcomes"}
**WE PROB AVE THIS ELSEWHERE, SO ONLY REFER TO IT**

Consider tossing a coin twice and observing the outcome of the two tosses. 

Since a random variable is a *real-valued function*, simply observing the outcome as $\{H, T\}$, for example, is not a random variable. 

We could define the random variable of interest, say $H$, as the *number* of heads on the two tosses of the coin.
The *sample space* for the experiment is 
\[
   S = \{ (TT), (TH), (HT), (HH)\}.
\]
The connection between the sample space and $H$ is shown in the table below.
In this case, the range of $H$ is $R_H = \{0, 1, 2\}$.


Element of $S$ | Function $H()$                          | Value of $H$  | $\Pr(H = s_i)$
---------------|-----------------------------------------|---------------------
$TT$           | $H(s_1)$: The number of heads in $s_1$  | 0             | $1/4$
$TH$           | $H(s_2)$: The number of heads in $s_2$  | 1             | $1/4$
$HT$           | $H(s_3)$: The number of heads in $s_3$  | 1             | $1/4$
$HH$           | $H(s_4)$: The number of heads in $s_4$  | 2             | $1/4$

The *probability function* $p_H(h)$ could be defined as
\[
   p_H(h) = 
   \begin{cases}
      1/4 & \text{for $h = 0$}\\
      1/2 & \text{for $h = 1$}\\
      1/4 & \text{for $h = 2$}\\
      0   & \text{for all other values of $h$}.
   \end{cases}
\]
:::


Distinguishing between discrete, continuous and mixed random variables is useful, as the probability functions depend on the distinction.


### Discrete random variables: Probability mass functions {#ProbabilityFunctionsDiscrete}

For a discrete random variable, the *probability function* indicates how probabilities are assigned to the values of the discrete random variable.
For a discrete random variable, the probability function often called the *probability mass function* (or pmf).

::: {.definition #ProbabilityFunction name="Probability function"}
Let the range space of the discrete random variable $X$ be $R_X$.
With each $x\in R_X$, associate a number 

\[
   p_X(x) = \Pr(X = x)
\]
The function $p_X$ is called the *probability function* of $X$.
:::



The following properties of the probability function are implied by the definition.

1. $p_X(t) \ge 0$ for all values of $t$; that is, probabilities are never negative.
2. $\displaystyle \sum_{t \in R_X}  p_X(t) = 1$ where $R_X$ is the range of $X$; that is, the probability function accounts for all possible sample points in the sample space.
3. $p_X(t) = 0$ if $t \notin R_X$.
4. For an event $A$ defined on a sample space $S$, the probability of event $A$ is computed using
   \[
      \Pr(A) = \sum_{t\in A} p_X(t).
   \]


::: {.definition #ProbabilityDistribution name="Probability distribution"}
If
\[
   R_X =\{ x_1, x_2, \dots \},
\]
the set
\[
   \{ (x_i, p_X(x_i); \quad i = 1, 2,\dots\}
\]
is called the *probability distribution* of the discrete random variable $X$.
:::

The probability distribution of a discrete random variable $X$ can be represented by listing each outcome woth its probability, a formula, a table or a graph which displays the probabilities $p(x)$ corresponding to each $x\in R_X$.

Sometimes the probability function is denoted $p(x)$ rather than $p_X(x)$.
Using the subscript is recommended to avoid confusion in situations where many random variables are considered at once.
The subscript is used throughout this book.

The probability distribution of a random variable is a description of the range space, or value set, of the variable and the associated assignment of probabilities.



::: {.example #Independence name="Independence"}
Five balls numbered 1, 2, 3, 4, 5 are in a box.
Two balls are selected at random.
Consider finding the probability distribution of the *larger* of the two numbers.
The sample space is:
\[ 
    S =\{ (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)\},
\]
where all 10 elements are equally likely.

Let $X$ be the random variable 'the *larger* of the two numbers chosen'.
Then $R_X = \{2, 3, 4, 5\}$ and
\begin{align*}
     \Pr(X = 2) &= \Pr((1,2)) = 1/10\\
     \Pr(X = 3) &= \Pr((1,3) \text{ or }  (2,3)) = 2/10\\
     \Pr(X = 4) &= \Pr((1,4) \text{ or } (2,4) \text{ or } (3,4)) = 3/10\\
     \Pr(X = 5) &= \Pr((1,5) \text{ or } (2,5) \text{ or } (3,5)\text{ or } (4,5)) = 4/10.
\end{align*}
This is the probability distribution of $X$, which could be given as a formula:
\[ 
   \Pr(X = x) = 
   \begin{cases}
      (x - 1)/10 & \text{for $x = 2, 3, 4, 5$}\\
      0 & \text{elsewhere}.
  \end{cases}
\]
The probability function could also be given in a table (Table \@ref(tab:LargestDie)) or as a graph (Fig. \@ref(fig:ProbDist1)).
:::

```{r LargestDie, echo=FALSE}
LargestDieTable <- array( dim = c(2, 4)) 

rownames(LargestDieTable) <- c("$x$",
                               "$\\Pr(X = x)$")

LargestDieTable[1, ] <- as.character(2:5)
LargestDieTable[2, ] <- ( (2:5) - 1 ) / 10

knitr::kable(LargestDieTable,
             caption = "A table showing the distribution of $X$, the largest number in two rolls of a die")
```



```{r ProbDist1, echo=FALSE, fig.align="center", fig.cap="The probability function for the larger of two numbers drawn"}
plot( x = 2:5,
      y = c(0.1, 0.2, 0.3, 0.4),
      xlim = c(1.75, 5.25),
      ylim = c(0, 0.4),
      type = "h",
      las = 1,
      lty = 3,
      lwd = 1,
      axes = FALSE,
      col = plotColour,
      main = expression( 
        paste( "The probability distribution of ", italic(X)) 
        ),
      xlab = expression( 
        paste("Values of the rv ", italic(X)) 
        ),
      ylab = expression( 
        paste( "The probability function ", italic(p)[italic(X)](italic(x)) )
      )
)
axis(side = 1,
     at = 2:5)
axis(side = 2,
     at = seq(0, 0.4, by = 0.1),
     las = 1)
box()

points( x = 2:5,
        y = c(0.1, 0.2, 0.3, 0.4),
        pch = 19,
        col = plotColour)

```
 
 
::: {.example #TossingHeads name="Tossing heads"}
Suppose a fair coin is tossed twice.
Then the *sample space* is 
\[
   S = \{HH, HT, TH, TT\}.
\]
Let $H$ be the *number* of heads observed.
$H$ is a (discrete) random variable, and the range of $H$ is $R_H = \{0, 1, 2\}$, representing the values that $H$ can take.

The probability function maps each of these values to the associated probability.
Using techniques from Chap. \@ref(Probability), the probabilities can be computed as:
\begin{align*}
   \Pr(H = 0) &= \Pr(\text{no heads}) = 0.25\\
   \Pr(H = 1) &= \Pr(\text{one head}) = 0.5\\
   \Pr(H = 2) &= \Pr(\text{two heads}) = 0.25.
\end{align*}
As a function, the probability function could be written
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
               0.25 & \text{if $h = 0$}\\
               0.5 & \text{if $h = 1$}\\
               0.25 & \text{if $h = 2$}\\
               0 & \text{otherwise}
              \end{cases}
\]
(Recall that the upper case $H$ refers to the *name* of the random variable.)
The more adventurous may write
\[
   p_H(h) = \Pr(H = h) 
          = \begin{cases}
                  (0.5)0.5^{|h - 1|} & \text{for $h = 0$, $1$ or $2$}\\
                  0 & \text{otherwise}
              \end{cases}
\]
This information can also be presented as a table (Table \@ref(tab:TwoDieRV)) or graph (Fig. \@ref(fig:ProbDistributionCoin)).

Note that $\sum_{t \in \{0, 1, 2\}} p_H(t) = 1$ and $p_H(h)\ge0$ for all $h$ as required of a pf.
:::


```{r TwoDieRV, echo=FALSE}
TwoDieTable <- array( dim = c(2, 3)) 

rownames(TwoDieTable) <- c("$h$",
                           "$\\Pr(H = h)$")

TwoDieTable[1, ] <- as.character(0:2)
TwoDieTable[2, ] <- c(0.25, 0.50, 0.25)

knitr::kable(TwoDieTable,
             caption = "A table showing the distribution of $H$, the number of heads in two rolls of a die")
```



```{r ProbDistributionCoin, echo=FALSE, fig.align="center", fig.cap="CAPTION"}
plot( x = 0:2,
      y = c(0.25, 0.50, 0.25),
      ylim = c(0, 0.55),
      type = "h",
      las = 1,
      lty = 3,
      col = plotColour,
      main = expression(
        paste("The probability distribution of ", italic(H))
        ),
      xlab = expression(
        paste("Values of the rv ", italic(H) )
        ),
      ylab = expression(
        paste("The probability function ", italic(p)[italic(H)](italic(h)))
      )
)

points( x = 0:2,
        y = c(0.25, 0.5, 0.25),
        pch = 19,
        col = plotColour)

```

### Continuous random variables: Probability density functions {#ProbabilityFunctionsContinuous}

Using probability functions to describe the distribution of a continuous random variable is tricky, because probability behaves like mass.
In the discrete case, we imagine mass can be distributed over a number (possibly countably infinite) of distinct points where each point has non-zero mass.
However, in the continuous case, mass cannot be thought of as an attribute of a *point* but rather of a *region* surrounding a point.

PT TO EARIER in Chap 1

The only way we can retain information about how 'massive' an object is at a point is to consider its mass per unit volume in the neighbourhood of that point and consider what happens as the volume of the neighbourhood shrinks to zero.
This measure does not go to zero.
And it is familiar to all of us as (mass) density.

Not only does density have meaning at a point, it allows us to determine the mass of an object by integration if we know the density at every point throughout the mass.

Similarly, to describe the probability distribution for a continuous random variable requires us to know the probability density at every point in the range space.
The function describing this density is naturally called the *probability density function* or pdf.
Once the pdf is known we can determine by integration the probability associated with any event defined on the range space.

Many texts either don't explicitly define the pdf or define it indirectly.
The definition given below relates directly to the idea of a density as described above, but doesn't tell us how to find the function.


::: {.definition #ProbabilityDensityFunction name="Probability density function"}
The *probability density function* (pdf) of the continuous random variable $X$ is a function $f_X(\cdot)$ such that
\[
   \Pr(a < X \le b) = \int_a^b f_X(x)\,dx
\]
for any interval $(a, b]$ (where $a < b$) on the real line.
:::


We are usually only concerned with $a, b\in R_X$, but it makes sense to think of the pdf as defined for all $x$, insisting that $f_X(x) = 0$ for $x\notin R_X$.
This definition states that *areas under the graph of the pdf represent probabilities* and leads to the following properties.

The following properties of the probability density function are implied by the definition.

1. $f_X(x) \ge 0$ for all $-\infty < x < \infty$.
2. $\displaystyle \int_{-\infty}^\infty f_X(x)\,dx = 1$.
3. For an event $E$ defined on a sample space $S$, the probability of event $E$ is computed using
   \[
      \Pr(E) = \int_{E} f_X(x)\, dx
   \]
4. Since exact values are not possible:
   \begin{align*}
      \Pr(a < X \le b) &= \Pr(a < X < b) = {}\\
      \Pr(a \le X < b) &= \Pr(a \le X \le b) = \int_a^b f_X(x)\,dx
    \end{align*}
5. From the *Mean Value Theorem* in calculus,
   \[ 
      \Pr(x < X < x + \Delta x) = \int ^{x + \Delta x}_x f(t)\, dt = \Delta xf(\xi ), \quad x < \xi < x + \Delta x.
   \]
6. For $\Delta x$ small,
   \begin{equation}
     \Pr(x < X < x +\Delta x)\simeq f(x)\Delta x.
   \end{equation}

Properties 1 and 2 are sufficient to prove that a function is a pdf; ie if we're asked to show that some function $g(x)$ is a pdf all we need do is show that $g(x) \ge 0$ for all $-\infty < x < \infty$ and that $\int_{-\infty}^\infty g(x)\,dx = 1$.

Property 4 results from noting that if $X$ is a continuous random variable, $\Pr(X = a ) = 0$ for any and every value $a$ for the same reason that a point has mass zero.

::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
The value of a pdf at some point $x$ does not represent a probability, but rather a *probability density*.
Hence, the pdf can have any non-negative value of arbitrary size at a specific value of $X$.
:::

Properties 5 and 6 directly relate the idea of a density to that of a probability.
These properties often find use in making approximations and in theoretical work.


::: {.example #ProbabilityDensityFunction name="Probability density function"}
Consider the continuous random variable $W$ with the pdf
\[
   f_W(w) = 
   \begin{cases}
      2w & \text{for $0 < w < 1$}\\
      0  & \text{elsewhere}
   \end{cases}.
\]
There are two ways to compute the probability $\Pr(0 < W < 0.5)$.
One is to use the pdf:
\[
   \Pr(0 < W < 0.5) = w^2\Big|_0^{0.5} = 0.25
\]
Alternately, the probability can be computed *geometrically* from the graph of the pdf Fig. \@ref(fig:ContinuousPDF).
The region corresponding to $\Pr(0 < W < 0.5)$ is triangular; integration simply finds the area of this triangle
The area can also be found using the area of a triangle directly: the length of the base of the triangle, times the height of the rectangle, divided by two:
\[
   0.5 \times 1 /2 = 0.25,
\]
and the answer is the same as before.
:::



```{r ContinuousPDF, echo=FALSE, fig.align="center", fig.cap="The probability function for $W$"}
plot( x = c(-1, 2),
      y = c(0, 2),
      type = "n",
      las = 1,
      main = expression(
        paste("The probability distribution of ", italic(W))
        ),
      xlab = expression(
        paste("Values of the rv ", italic(W))
        ),
      ylab = expression(
        paste("The probability function ", italic(p)[italic(W)](italic(w)))
      )
)

polygon( x = c(0, 0.5, 0.5, 0),
         y = c(0, 1, 0, 0),
         col = plotColour)
lines( x = c(-0.5, 0, 1),
       y = c(0, 0, 2),
       lwd = 2)
lines( x = c(-1, -0.5),
       y = c(0, 0),
       lwd = 2,
       lty = 2)
lines( x = c(1, 1.5),
       y = c(0, 0),
       lwd = 2)
lines( x = c(1, 2),
       y = c(0, 0),
       lwd = 2,
       lty = 2)
points(1, 2, 
       pch = 1)
points(1, 0, 
       pch = 19)
```





### Mixed random variables {#ProbabilityFunctionsMixed}


### Bivariate probability functions {#BivariateProbabilityFunctions}





## The distribution function {#DistributionFunction}

Another way of describing random variables is using a *distribution function* (df), also called a *cumulative distribution function* (cdf).
We will use the df description in this book.

The df gives the probability that a random variable $X$ is less than *or equal to* a given value $t$.

::: {.definition #DistributionFunction name="Distribution function"}
For any random variable $X$ the *distribution function*, $F_X(x)$, is given by
\[
     F_X(x) = \Pr(X \leq x) \quad \text{for $-\infty < x < \infty$}.
\]
:::
Note that the distribution function applies to discrete or continuous or mixed (see below) random variables.

Two important points to note:

1. The definition includes a less than *or equal to* sign.
2. The distribution function is defined on the entire real line.


If $X$ is a discrete random variable with range space $R_X$, the df,
\begin{align*}
     F_X(x)
     &= \Pr(X \leq x)\\
     &= \sum_{x_i \leq x} \Pr(X = x_i)\text{ for }x_i\in R_X,\text{ and }-\infty < x < \infty.
\end{align*}
If $X$ is a continuous random variable, the df,
\begin{align*}
     F_(x)
     &= \Pr(X \leq x)\\
     &= \int^x_{-\infty} f(t)\,dt \text{ for } -\infty < x < \infty.
\end{align*}


::: {.example #TossingHeads2 name="Tossing heads"}
Consider the simple example in Example \@ref(exm:TossingHeads).
The probability function for $H$ is given in that Example in numerous forms.
To determine the df, first note that when $t < 0$, the accumulated probability is zero; hence, $F_H(t) = 0$ when $t < 0$.
At $t = 0$, the probability of $0.25$ is accumulated, and no more probability is accumulated until $t = 1$.
Thus, $F_H(t) = 0.25$ for $0 \le t< 1$.
Continuing, the df is 
\[
   F_H(t) = \begin{cases}
               0 & \text{for $h < 0$}\\
               0.25 & \text{for $0\le h < 1$}\\
               0.75 & \text{for $1\le h < 2$}\\
               1 & \text{for $h\ge 2$}
            \end{cases}
\]
The df can be displayed graphically, being careful to clarify what happens at $H = 1$, $H = 2$ and $H = 3$ using open or filled circles (Fig. \@ref(fig:HeadsDF)).
:::



```{r HeadsDF, echo=FALSE, fig.cap="A graphical representation of the distribution function for Example \\ref(exm:TossingHeads2). The filled circles contain the given point, while the empty circles omit the given point."}
plot( x = c(-0.5, 4),
      y = c(0, 1.05),
      type = "n",
      las = 1,
      main = expression(
        paste("The probability function of ", italic(H))
        ),
      xlab = expression(italic(H)),
      ylab = expression(
        paste("The probability function ",italic(F)[italic(H)](italic(h)))
      )
)

abline(h = c(0, 1),
       col = "grey")


lines( x = c(-0.5, 0),
       y = c(0, 0),
       lty = 2,
       lwd = 2)
lines( x = c(0, 1),
       y = c(0.25, 0.25),
       lwd = 2)
lines( x = c(1, 2),
       y = c(0.75, 0.75),
       lwd = 2)
lines( x = c(2, 3),
       y = c(1, 1),
       lwd = 2)
lines( x = c(3, 4),
       y = c(1, 1),
       lwd = 2,
       lty = 2)


points(0, 0, 
       pch = 1)
points(0, 0.25, 
       pch = 19)

points(1, 0.25, 
       pch = 1)
points(1, 0.75, 
       pch = 19)

points(2, 0.75, 
       pch = 1)
points(2, 1, 
       pch = 19)

```




::: {.example #ProbabilityFunction name="Probability function"}
Consider a continuous random variable $V$ with pdf
\[
   f_V(v) = \begin{cases}
               v/2 & \text{for $0 < v < 2$}\\
               0 & \text{otherwise}
            \end{cases}
\]
The df is zero whenever $v\le 0$.
For $0 < v < 2$,
\[
   F_V(v) = \int_0^v t/2\,dt = v^2/4.
\]
Whenever $v\ge 2$, the df is one.
So the df is
\[
   F_V(v) = \begin{cases}
               0 & \text{if $v\le 0$}\\
               v^2/4 & \text{if $0< v< 2$}\\
               1 & \text{if $v\ge 2$}
             \end{cases}.
\]
A picture of the df is shown in Fig. \@ref(fig:DFCont).
:::

```{r DFCont, echo=FALSE, fig.align="center", fig.cap="The distribution function of $V$"}
vb <- seq(0, 2,
         length = 100)
vbDF <- ( vb ^ 2 ) / 4

plot( x = c(-2, 4),
      y = c(0, 1),
      type = "n",
      xlab = expression(italic(v)),
      ylab = "Distribution function",
      las = 1)
lines( x = c(-2, -1),
       y = c(0, 0),
       lwd = 3,
       lty = 2)
lines( x = c(-1, 0),
       y = c(0, 0),
       lwd = 3,
       lty = 1)
lines( vbDF ~ vb,
       lwd = 3)
lines( x = c(2, 3),
       y = c(1, 1),
       lwd = 3)
lines( x = c(3, 4),
       y = c(1, 1),
       lwd = 3,
       lty = 2)
```


::: {.importantBox .important data-latex="{iconmonstr-warning-8-240.png}"}
For the integral, *do not write*
\[
   \int_0^v v/2\,dv.
\]
It makes no sense to have the *variable* of integration as a limit on the integral and also in the function to be integrated.
Either write the integral as given in the example, or write $\int_0^t v/2\,dv = t^2/4$ and then change the variable from $t$ to $v$.
:::


Properties of the df are stated below.

1. $0\leq F_X(x)\leq 1$ because $F_X(x)$ is a probability.
2. $F_X(x)$ is a non-decreasing function of $x$.
   If $x_1 < x_2$ then $\{ x:x\leq x_1\} \subset \{ x:x\leq x_2\}$.
   So $F_X(x_1) = \Pr(X \leq x_1)\leq \Pr(X\leq x_2) = F_X(x_2)$.
3. Denoting $\displaystyle{\lim_{x\to \infty} F_X(x)}$ by $F_X(\infty )$ and $\displaystyle{\lim_{x\to -\infty} F_X(x)}$ by $F_X(-\infty )$ we have $F_X(\infty ) = 1$ and $F_X(-\infty) = 0$.
4. $\Pr(a < X \leq b) = F_X(b) - F_X(a)$.
5. If $X$ is discrete, then $F_X(x)$ is a step-function but if $X$ is continuous $F_X$ will be a continuous function for all $x$.

We can use (2.2) to find $F_X(x)$ given $\Pr(X = x)$ or (3.4) to find $F_X(x)$ given $f_X(x),$ but we need to be able to proceed in the other direction as well.
That is, given $F_X(x)$, how do we find $\Pr(X = x)$ for $X$ discrete or $f_X(x)$ for $X$ continuous?

* As seen from the graph of the df in Example \@ref(exm:TossingHeads2), the values of $x$ where a 'jump' in $F_X(x)$ occurs are the points in the range space, and the probability associated with a particular point in $R_X$ is the 'height' of the jump there.
That is,
\begin{equation}
      p_X(x_j) = \Pr(X = x_j) = F_X(x_j) - F_X(x_{j - 1})
\end{equation}

* For $X$ continuous, from the Fundamental Theorem of Calculus,
  \begin{equation}
     f_X(x) = \frac{dF_X(x)}{dx} \quad \text{where the derivative exists.}
\end{equation}


:::{.example}
???
:::


### Mixed random variables {#MixedRandomVariables}

Some random variables are neither continuous nor discrete, but have parts of both.
These random variables are called *mixed random variables*.

::: {.example #MixedRandomVariable name="Mixed random variable"}
In a factory producing diodes, a fraction of the diodes $p$ fail immediately.
The distribution of the lifetime (in hundred of days), say $Y$, if the diodes is given by a discrete part at $y = 0$ for which $\Pr(Y = 0) = p$ and a continuous part for $y > 0$ described say by the pdf
\[
   f_Y(y) = (1 - p) \exp(-y) \quad \text{if $y > 0$.}
\]
(Strictly speaking $f_Y(y)$ is not a proper pdf because it doesn't integrate to one but we can see that the total probability is
\[
   0.4 + \int_0^\infty 0.6\exp(-y) \, dy = 0.4 + 0.6 = 1
\]
as required.)

Consider a diode for which $p = 0.4$.
The probability distribution is displayed in Fig. \@ref(fig:Diode) (left panel) where a solid dot is included to show the discrete part.

```{r Diode, echo=FALSE, fig.align="center", fig.cap="The probability function and distribution function for the diodes example"}
par( mfrow = c(1, 2))

p <- 0.4
x <- seq(0, 4, 
         length = 100)
fy <- (1 - p) * exp( - x)
fy[1] <- 1 - p

Fy <- 0.4 + 0.6 * (1 - exp(-x ) )
F[1] <- p

plot(fy ~ x,
     lwd = 2,
     type = "l",
     xlab = expression(italic(Y)),
     ylab = expression(italic(f)[italic(y)](italic(y))),
     main = "Probability function",
     las = 1)
points( x = 0,
        y = 0.4,
        pch = 19)
points( x = 0,
        y = 0.6,
        pch = 1)


plot(Fy ~ x,
     ylim = c(0, 1),
     lwd = 2,
     type = "l",
     xlab = expression(italic(Y)),
     ylab = expression(italic(F)[italic(y)](italic(y))),
     main = "Distribution function",
     las = 1)
points( x = 0,
        y = Fy[1],
        pch = 19)
points( x = 0,
        y = 0.4,
        pch = 1)

```

We see there are difficulties representing the probability distribution in this mixed case because we need to combine a probability distribution and a pdf.
These difficulties are circumvented by using the distribution function.
The df of $Y$ is  (Fig. \@ref(fig:Diode), right panel):
\[
   F_Y(y) = \begin{cases}
               0 & \text{if $y < 0$}\\
               0.4 & \text{if $y = 0$}\\
               0.4 + 0.6(1 - \exp(-y)) & \text{if $y > 0$}.
            \end{cases}
\]
:::


