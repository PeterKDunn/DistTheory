
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Self-assessment exercises}

The following exercises are designed to provide practice at problem-solving
based on the material in this module. Solutions are provided at the end of the module.
Additional exercises are available in the next section and in the textbook.

\begin{exercises}


\item
The rv $Y$ is defined as
\[
   f_Y(y) = \begin{cases}
               2y + k & \text{for $0\le y \le 1$}\\
               0 & \text{elsewhere}
            \end{cases}
\]
\begin{enumerate}
   \item
   Find a value for $k$.
   \item
   Plot the pdf of $Y$.
   \item
   Compute $\text{E}(Y)$.
   \item
   Compute $\text{var}(Y)$.
   \item
   Compute $\Pr{X>0.15}$.
\end{enumerate}

\begin{answer}
(a) $k=0$ (c) $\text{E}(Y)=2/3$ (d) $\text{E}(Y^2)=1/2$ so $\text{var}(Y)=1/18$
(e) 0.85
\end{answer}

\item
The rv $N$ is defined as
\[
   p_N(n) =
   \begin{cases}
      1/3 & \text{for $n=1$}\\
      1/6 & \text{for $n=2$}\\
      \alpha & \text{for $n=3$}\\
      0 & \text{otherwise}
   \end{cases}
\]
\begin{enumerate}
   \item
   Find the value of $\alpha$.
   \item
   Compute the mean and variance of $M$.
   \item
   Find the mgf for $M$.
   \item
   Compute the mean and variance of $M$ from the mgf.
\end{enumerate}

\begin{answer}
(a) $\alpha=1/2$ (b) $\text{E}(N)=13/6$, $\text{var}(N) \approx 0.8056$ (c) $M_N(t) =
\exp(t)/3 + \exp(2t)/6 + \exp(3t)/2$
\end{answer}


\item
The mgf of the discrete rv $Z$ is
\[
   M_Z(t) = [0.3\exp(t) + 0.7]^2
\]
\begin{enumerate}
   \item
   Compute the mean and variance of $Z$.
   \item
   Find the pf of $Z$.
\end{enumerate}

\begin{answer}
$M_Z'(t) = 0.6\exp(t)[0.3\exp(t) + 0.7]$ so $\text{E}(Z)=0.6$; $M''_Z(t)
= 0.18\exp(2t) + 0.6\exp(t)[0.3\exp(t)+0.7]$ so $\text{E}(Z^2)=0.78$,
hence so $\text{var}(Z)=0.42$ (be careful with the derivatives here!);
expand the quadratic and find $\Pr{Z=0}=0.49$, $\Pr{Z=1}=0.42$,
$\Pr{Z=2}=0.09$.
\end{answer}

\item
The mgf of $G$ is $M_G(t) = (1-\beta t)^{-\alpha}$. Find the mean
and variance of $G$.

\begin{answer}
$M'_G(t) = \alpha\beta(1-\beta t)^{-\alpha-1}$ so $\text{E}(G) =
\alpha\beta$; $M''_G(t) = \alpha\beta^2(\alpha+1)(1-\beta
t)^{-\alpha-2}$ so $\text{E}(G^2)=\alpha\beta^2(\alpha+1)$ and
$\text{var}(G)=\alpha\beta^2$.
\end{answer}



\item Suppose that the pdf of $X$ is
\[
   f_X(x) = \begin{cases}
               2(1-x) & \text{for $0<x<1$}\\
               0 & \text{otherwise}
            \end{cases}
\]
\begin{enumerate}
   \item
   Find the $r$th raw moment of $X$.
   \item
   Find $\text{E}((X+3)^2)$ using the previous answer.
   \item
   Find the variance of $X$.
\end{enumerate}

\begin{answer}
\begin{enumerate}
\item
   $\mu'_r = \text{E}(X^r) = \int_{x=0}^1 x^r 2(1-x)\, dx=
   2\left[ \left(\frac{x^{r+1}}{r+1} - \frac{x^{r+2}}{r+2}\right)\Big|_{0}^{1}\right]
   = 2\left[ \frac{1}{r+1} - \frac{1}{r+2}\right]$.
\item
   Expanding,
   $\text{E}((X+3)^2) = \text{E}(X^2) + 6\text{E}(X) + 9$.
   Now,
   $\text{E}(X) = \mu'_1 = 1/3$ from above,
   and
   $\text{E}(X^2) = \mu'_2 = 1/6$ from above.
   Hence $\text{E}((X+3)^2) = 67/6$.
\item
   $\text{var}(X) = \text{E}(X^2) - \text{E}(X)^2 = 1/18$.

\end{enumerate}
\end{answer}

\item
(Computer exercise) Generate a random sample of size 120 from the
distribution in Example~\ref{EG:3:die}. Find the mean and standard deviation
of the sample. Compare the results with those found in Example~\ref{EG:3:die}.
Draw a histogram for the sample. Are they as you would expect?

\begin{answer}
\begin{verbatim}
face<-sample(1:6,size=120,replace=T)
hist(face)
\end{verbatim}

\end{answer}

\end{exercises}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Exercises}


\begin{exercises}

\item
For a discrete random variable $X$ with probability function
\[ \Pr{X=x}=\frac{1}{5}, \quad x=-1,0,1,2,3,\]
find (a) $\text{E}(X)$, (b) $\text{E}(X^2)$, (c) $\text{var}(X)$, (d) $\text{E}(|X|)$ and
(e) the median of $X$.

\begin{answer}
(a) $\text{E}(X)=1$\ (b) $\text{E}(X^2)=3$\ (c) $\text{var}(X)=2$\ (d) $\text{E}(|X|)=7/5$\ (e) median = 1
\end{answer}



\item A rv $X$ is defined as
\[
   f_X(x) = \begin{cases}
      k/x & \text{for $1<x<2$}\\
      0 & \text{otherwise}
      \end{cases}
\]
\begin{enumerate}
   \item
   Determine a value for $k$.
   \item
   Compute the mean and variance of $X$.
   \item
   Determine the distribution function for $X$.
\end{enumerate}



\item The rv $X$ has the mgf
\[
   M_X(t) = \exp\left( \mu t + \frac{t^2 \sigma^2}{2}\right)
\]
\begin{enumerate}
   \item
   Find the mean and variance of $X$.
   \item
   Find the mgf of $X + Y$ if $Y$ has the same mgf as $X$.
\end{enumerate}

\item
Consider a random variable $W$ for which $\Pr{W=c}=k$,\break
$\Pr{W=-c}=2k$ and $\Pr{W=0}=3k$, and is zero elsewhere. Find the
mean and variance of $W$.


\item
Consider the random variable $X$ which has the density function
\[
   f_X(x) = \frac{k}{x^2}
\]
for $3<x<\infty$.
\begin{enumerate}
   \item
   Find the value of $k$.
   \item
   Sketch the density function over the range $0\le x \le 6$.
   \item
   Using the integral definition of the mean,
   show that the mean cannot be computed.
   \item
   Determine $\Pr{X>3 \mid  X<4}$.
   \item
   Find the (cumulative) distribution function for $X$.
   \item
   Using the distribution function,
   determine the median of $X$.
\end{enumerate}



\item
The random variable $W$ has the probability function
\[
   p_W(w) = \frac{5w}{6(1+w^2)}\quad\text{for $w=1,2,3$},
\]
and is zero for other values of $W$.

\begin{enumerate}
\item
   Find the moment generating function for $W$.
\item
   Using the moment generating function,
   calculate $\text{E}(W)$ and $\text{var}(W)$.
\item
   Determine and sketch the \emph{distribution function} of $W$.
\end{enumerate}


\item
The distribution
\[
   f_W(w) = \frac{1}{105}w^2(6-w)
\]
is defined for $w=1, 2, 3, 4, 5$, and is zero for other values of
$W$.

\begin{enumerate}
\item
   Find the moment generating function for $W$.
\item
   Using the moment generating function,
   calculate $\text{E}(W)$ and $\text{var}(W)$.
\item
   Determine and sketch the distribution function of $W$.
\end{enumerate}



\item
Consider a discrete random variable $X$ defined on $x=0, 1, 2,\dots$
\begin{enumerate}
\item
   Show that $\Pr{X=x} = \Pr{X\ge x} - \Pr{X\ge x+1}$.
   (\Hint: Write out the right-hand side for the first few values
   of $x$.)
\item
   Hence show that
   $\displaystyle \text{E}(X) = \sum_{x=0}^\infty
                      x[ \Pr{X\ge x} - \Pr{X\ge x+1} ]$.
\item
   Use the previous result to show that
   $\displaystyle \text{E}(X) = \sum_{x=0}^\infty \Pr{X>x}$.
   (\Hint: Write out the summation from~(b) for the first few values
   of $x$.)
\end{enumerate}

\item
The probability density function of a random variable $X$ is given by\\
\[ f(x)=\begin{cases}
0&x \le 1\\
\frac{1}{4}&1 < x \le 2\\
0&2 < x \le 3\\
\frac{1}{2}&3 < x \le 4\\
0&4 <x \le 5\\
\frac{1}{4}&5 < x \le 6\\
0&x > 6
\end{cases}\]
Find  (a) $\text{E}(X)$ (b) $\text{E}(X^2)$ (c) $\text{var}(X)$ (d) the median of $X$.

\begin{answer}
(a) $\text{E}(X)=3.5$ (b) $\text{E}(X^2)=43/4$ (c) $\text{var}(X)=2.08333$ (d)  median=3.5
\end{answer}


\item\label{QN:5:q7}
\begin{enumerate}
\item Find the mgf of the distribution with pdf
\[ f(x) = \begin{cases}
\frac{1}{2}e^{x}&-\infty<x<0 \\
\frac{1}{2}e^{-x}&0 < x < \infty
\end{cases}\]
What restrictions must be placed on the value of $t$?
\item Hence find $\text{E}(X^r)$, $r=1,2,3,\cdots$.
%\item What are the cumulants of this distribution?
\item Find the coefficients of skewness and kurtosis.
\end{enumerate}

\begin{answer}
(a) $M_X(t) = \ds{\frac{1}{1-t^2}}$, $|t|<1$ (b) $\text{E}(X^r) = r!$ for $r$ even, 0 otherwise.
%(c) See Section~\ref{SC:cgf}.
(d) $\gamma_1=0$, $\gamma_2=3$
\end{answer}


\item
\begin{enumerate}
\item For the distribution in Question~\ref{QN:5:q7} find $\Pr{|X| \ge 3}$.
\item Use Tchebychev's inequality to get an upper bound for this probability.
Comment on the bound.
\end{enumerate}

\begin{answer}
(a) 0.04979 (b) $\sigma^2=2$, thus $k=3/\sqrt{2}$ and upper bound = 2/9.
\end{answer}


\item
Prove that for a continuous random variable $X$ which has a distribution
that is symmetric about 0 then $ M_X(t) = M_{-X}(t)$.
Hence prove that for such a rv all odd moments about the origin
are zero.

\begin{answer}
Begin with Definition~\ref{DF:mgf} for $M_X(t)$ and use fact that if
a distribution is symmetric about 0 then $f_X(x)=f_X(-x)$ using
symmetry. Transform the resulting integral.
\end{answer}


\item
If $X$ has mgf given by
$\ds M_X(t)=\frac{1}{1-t},$
\begin{enumerate}
%\item find the $r$th cumulant.
\item Find the moment generating function of $Y=4X-3$.
\item Using the moment generating functions find $\text{E}(X)$, $\text{E}(Y)$, $\text{var}(X)$
and $\text{var}(Y)$.
\item Show the relationship between the means and variances in (d) is as
you would expect by finding $\text{E}(Y)$ and $\text{var}(Y)$ directly from the definition of $Y$.
\item Hence find the coefficients of skewness and kurtosis for this distribution.
\end{enumerate}

\begin{answer}
%(a) $k_r = (r-1)!$ (b) $\gamma_1=2$, $\gamma_2=6$.\\[3mm]
(a) Using Theorem~\ref{TM:3:mgf1}, $M_Y(t) = \ds{\frac{e^{3t}}{1-4t}}$\\
(b) Expand $M_X(t)$ and $M_Y(t)$ in powers of $t$ and find the coefficients
of $t/1!$ and $t^2/2!$. (Only coefficients of $t$ and $t^2$ are needed.)\\
$\text{E}(X)=1$, $\text{var}(X)=1$, $\text{E}(Y)=1$, $\text{var}(Y)=16$
(d) $\gamma_1=2$, $\gamma_2=6$.
\end{answer}







\item
Consider the distribution
\[
  f_Y(y) = \frac{2}{y^2}\qquad y\ge 2.
\]
\begin{enumerate}
\item Show that the mean of the distribution does not exist.
\item Show that the variance does not exist.
\item Plot the probability
density function over a suitable range.
\item Plot the
distribution function over a suitable range.
\item Determine the
median of the distribution.
\item Determine the interquartile
range of the distribution.  (The interquartile range is a measure
of spread, and is calculated as the difference between the third
quartile and the first quartile. The first quartile is the value
below which 25\% of the data lie; the third quartile is the value
below which 75\% of the data lie.)
\item Find $\Pr{Y>4\mid Y>3}$.
\end{enumerate}


\item
Consider the discrete distribution
\[
   p_X(x) = k\frac{x}{x+1},\qquad\hbox{for $x=1, 2, 3, 5$.}
\]
\begin{enumerate}
\item Find $k$.
\item Find the moment generating function of $X$.
\item Use the mgf to determine the mean and variance of $X$.
\item Plot the distribution function of $X$.
\end{enumerate}


\item
Consider the random variable $X$ which has a probability
function
\[
   p_X(x) = \kappa \frac{x}{x^2+1}\quad\text{for $x=1, 2, 3$}
\]
where $\kappa$ is a positive constant.
\begin{enumerate}
   \item
   Determine the value of the constant $\kappa$.

   \item
   Calculate the moment generating function for $X$.

   \item
   Find the mean of $X$.

   \item
   Find $F_X(x)$, the distribution function of $X$.
\end{enumerate}


\item
Let $Z$ be a random variable such that
\[
   \Pr{Z=c} = \Pr{Z= -c} = \frac{1}{2}
\]
for some constant $c>0$.
\begin{enumerate}
   \item
   Determine the expected value and the variance of $Z$.
   \item
   Determine the probability that $Z$ is within two
   standard deviations of the mean.
\end{enumerate}


\item
A random variable $Y$ has the pdf
\[
   f_Y(y) = \begin{cases}
               y^2 & \text{for $0<y<1$}\\
               1-ky & \text{for $1<y<2$}
            \end{cases}
\]
\begin{enumerate}
   \item
   Find a value for $k$.
   \item
   Plot the probability density function for $Y$.
   \item
   Find $\E[Y]$.
   \item
   Find the (cumulative) distribution function for $Y$.
\end{enumerate}


\item
The discrete rv $W$ has the pf
\[
   p_W(w) = \begin{cases}
               k \log\left( \frac{w+1}{w}\right) & \text{for $w=2, 3, 4, 5$}\\
               0 & \text{otherwise}
            \end{cases}
\]
\begin{enumerate}
   \item
   Show  $k=1/\log(3)$.
\item
   Deduce the mgf of $W$.
\item
   Calculate $\text{E}(W)$ and $\text{var}(W)$ using the mgf.
\item
   Determine and sketch the \emph{distribution function} of $W$.
\end{enumerate}



\item
In a particular application, the distribution
\[
   f_Z(z) = \kappa \exp\{ 1-\cos(z) \}\quad 0\le z\le 2\pi
\]
is needed, where $\kappa$ is a constant.
\begin{enumerate}
   \item
   Use a numerical integration technique to determine the value
   of $\kappa$ accurate to at least one decimal place.
   %% KAPPA = 1/21.623732
   \item
   Plot the density function of $Z$, and deduce (but do not
   calculate) its mean.
   \item
   Determine $\Pr{0<Z<1}$ accurate to at least two decimal places.
\end{enumerate}


\item
Find the mgf for the random variable with probability function
\[ \Pr{X=1}=\Pr{X=-1}=\frac{1}{2}. \]
\begin{enumerate}
\item Hence show that
\[ \text{E}(X^r) = \begin{cases}
1&\text{if $r$ even}\\
0&\text{if $r$ odd}
\end{cases}\]
\item  Find the mean and variance of $X$.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\item
If $(X,Y)$ has pdf given by $f_{X,Y}(x,y)=4xy$, $0 \le x \le 1$, $0 \le y \le 1$,\\
 find $\text{E}(X\mid Y=1/4)$.

\begin{answer}
Use Definition~\ref{DF:condexp}. Ans = 2/3
\end{answer}


\item
The Cauchy distribution has the pdf
\[
   f_X(x) = \frac{1}{\pi(1+x^2)}\quad\text{for $-\infty<x<\infty$}
\]

\begin{enumerate}

   \item
   By integrating $x f_X(x)$, show that the mean does not exist
      for the Cauchy distribution.

   \item
   Hence show that the variance does not exist for the Cauchy distribution.

\end{enumerate}

\begin{answer}
For the mean, $\text{E}(X) = (1/\pi) \int_{-\infty}^\infty x/(1+x^2)\,
dx = (2/\pi)\log( 1+x^2)\Big|_{-\infty}^{\infty}$. Now,
$\log(\infty)$ is not defined, so the mean is not defined.
\end{answer}

\item(Computer exercise)
\begin{enumerate}
\item A rv $X$ is uniformly distributed on the interval $[0,1]$ with
density function, $f_X(x) = 1$ for $x\in[0,1]$. If
\[ g(x) = e^{x} \]
find $\E[g(X)]$.
\item Generate a random sample of size 1000 from a uniform distribution on $[0,1]$
({\sf runif(n=1000,min=0,max=1)}
and estimate $\ds \int_0^1 e^{x} dx$. Hence obtain an estimate of $e$.
\item Let $h(x)=1/(1+x^2)$. Find $\E[h(X)]$.
\item Estimate $\int_0^1 (1+x^2)^{-1} dx$ by Monte-Carlo integration and hence obtain
an estimate for $\pi$.
\end{enumerate}

\begin{answer}
(a) $\text{E}(X) = e-1$ \ (b) See \R\ Exercise~\ref{QN:5:MonteCarlo}. (c) $\int (1+x^2)^{-1}\,dx = \tan^{-1}(x)$,
$\E[h(X)]= \pi/4$ (Don't expect accuracy to more than 1 dec pl with $N=1000$.)
\end{answer}


\end{exercises}



\makeanswers

\endinput


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%unused qns


\item
In this course, we only deal with simple distributions. In
practice, some distributions cannot be written in closed form, but
are only known by their moment generating functions. To evaluate
the density then requires an infinite summation or an infinite
integral. Given a moment generating function $M(t)$, the
probability density function can be reconstructed numerically from
the integral using the \emph{inversion formula}
\begin{equation}
   f_Y(y) = \frac{1}{2\pi}\int_{-\infty}^{\infty} M(it) \exp(-ity)\,dt,
   \label{EQN:mgf}
\end{equation}
where $i=\sqrt{-1}$. (See, for example, J\o
rgensen~\cite[p~41]{BIB:jorgensen}.) The evaluation of the
integral generally requires advanced numerical techniques. In this
question, we just consider the exponential distribution as a
simple example to demonstrate the use of the inversion formula.
\begin{enumerate}
\item Write down the expression in~(\ref{EQN:mgf}) in the case of
the exponential distribution. \item We only need the real parts of
the integral.  Extract the real parts of this expression, and
simplify the integrand. (The integrand is the expression to be
integrated.) \item Write the expression from the last part as an
integral from $0$ to $\infty$. \item Plot the integrand from the
last part from $t=0$ to $t=20$ in the case $\beta=2$ and $y=1$.
\end{enumerate}


\item
Consider a continuous random variable $Y$ with pdf $f_Y(y)$, and
non-zero constants $a$ and $b$.

\begin{enumerate}
   \item
   Prove,
   using the integral definition of the mean,
   that $\E[aY+b] = a \E[Y]+b$.

   \item
   Prove,
   using the integral definition,
   that $\E\left[(aY+b)^2\right] = a^2\E[Y^2] + 2ab\E[Y] + b^2$.

   \item
   Use the above results to prove
   that $\text{var}[aY+b] = a^2\text{var}[Y]$.

\end{enumerate}



\item
   Let the continuous random variable $Y$ have the moment generating function
   $M_Y(t)$.  Show that the moment generating function of
   $Z=aY+b$ is $e^{bt} M_Y(at)$ for constants $a$ and $b$.

\item Consider constants $a$ and $b$, and a rv $X$ with mgf
$M_X(t)$. Prove:
\begin{enumerate}
   \item
   the mgf of $Y=X+a$ is $M_Y(t)=\text{E}( \exp\{t(X+a)\}) = \exp(at) M_X(t)$

   \item
   the mgf of $Z=(U+a)/b$ is $M_Z(t) = \text{E}( \exp\{ t (X+a)/b\} ) = \exp(at/b)M_X(t)$

   \item
   the mfg of $U=bX$ is $M_U(t) = \text{E}(\exp(bXt)) = M_X(bt)$.
\end{enumerate}

\item Consider constants $a$ and $b$. Also, $X_1$, $X_2$, $\dots$,
$X_n$ are $n$ independent random variables with mgf $M_{X_i}(t)$.
Prove that the mgf of $Y=X_1 + X_2 + \cdots X_n$ is
\[
   M_Y(t) = \prod_{i=1}^n M_{X_i}(t).
\]



\item
The exponential distribution has the probability density function
(for $\lambda>0$)
\[
   f_Y(y) = \frac{1}{\lambda}\exp( -y/\lambda)
\]
for $y>0$ and is zero elsewhere.

\begin{enumerate}

   \item
   Determine the moment generating function of $Y$.

   \item
   Use the moment generating function to compute the
   mean and variance of the exponential distribution.

\end{enumerate}