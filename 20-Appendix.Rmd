\part{Appendices}

# (APPENDIX) Appendices {-}



# Some useful series {#UsefulSeries}

For convenience and reference we state some results here involving series that occur quite frequently in probability and statistical theory.


## Finite series

* Sum of natural numbers:
\begin{equation}
   1 + 2 + 3 + \ldots + n 
   = \frac{n(n + 1)}{2}.
   (\#eq:SumNaturalNumbers)
\end{equation}

* Sum of squares of natural numbers:
\begin{equation}
   1^2 + 2^2 + 3^2 + \ldots + n^2
   = \frac{n}{6}(n + 1)(2n + 1)
   (\#eq:SumSquaredNaturalNumbers)
 \end{equation}
 
* Geometric series
\begin{align}
   a + ar + ar^2 + \ldots + ar^{n - 1}
   &= \frac{a(1 - r^n)}{1 - r}
   (\#eq:SumGeometricFinite)\\
   &\rightarrow \frac{a}{1 - r} \text{ as $n  \rightarrow  \infty$}
  (\#eq:SumGeometricInfinite)
\end{align}
where the infinite series only converges if $|r| < 1$.

* Binomial expansion:
\begin{equation}
   (a + b)^n = b^n + \binom{n}{1}ab^{n - 1} + \ldots + \binom{n}{r}a^r b^{n - r} + \ldots a^n.
   (\#eq:BinomialSeries)
\end{equation}



## Power series

A power series is a series of the form $\sum_{n = 0}^{\infty}a_n z^n$.

* Exponential function:
\begin{align}
   e^z
   &= 1 + z + \frac{z^2}{2!} + \frac{z^3}{3!} + \ldots
   (\#eq:Exponential)\\
   e^{-z}
   &= 1 - z + \frac{z^2}{2!} - \frac{z^3}{3!} + \ldots
   (\#eq:ExponentialNegative)
\end{align}

* Logarithmic series:
\begin{align}
   \log(1 + z)
   &= z - \frac{z^2}{2} + \frac{z^3}{3} - \ldots
   (\#eq:Logarithmic)\\
   \log(1 - z)
   &= -z - \frac{z^2}{2} - \frac{z^3}{3} - \ldots
   (\#eq:LogarithmicNegative)
\end{align}

* Others:
\begin{align}
   (1 - z)^{-1}
   &= 1 + z + z^2 + z^3 + \ldots
   (\#eq:Other1)\\
   (1 - z)^{-r}
   &= 1 + rz + \frac{r(r + 1)z^2}{2!} + \frac{r(r + 1)(r + 2)z^3}{3!} + \ldots
   (\#eq:Other2)
\end{align}

Note that the expressions on the RHS above do not converge to the LHS for all values of $z$.



# Using R with univariate distributions {#UseRDistributions}

In **R**, standard distributions have four associated function:

* Computing the [probability function](#ProbabilityFunction): All begin with `p` (such as `pnorm()` for the normal distribution).
* Computing the [distribution function](DistributionFunction): All begin with `d`(such as `dnorm()`).
* Computing the quantile function (XREF): All begin with `q` (such as `qnorm()`).
* Generating random numbers (XREF): All begin with `r` (such as `rnorm()`).

ADD PARAMETERS TOO... if enough room.

In **R**, four function are available for most distributions

* Computing the [probability function](#ProbabilityFunction): Functions start with `d`
* Computing the [distribution function](#DistributionFunction): Functions start with `p`
* Computing the quantiles: Functions start with `q`
* Generatimg random numbers: Functions start with `r`.

For example, the fours function above are called, for the normal distribution (denoted `norm` in **R**):

* `dnorm()`
* `pnorm()`
* `qnorm()`
* `rnorm()`

ADD a chapter on how to generate random numbers and quantiles and so on.



## Discrete distributions

Common parameters:

* `x`: Values where to evaluate the probability function  
* `q`: Quantiles
* `p`: Probabilities
* `n`: The number of random observations to generate



Distribution       | **R** function          | Common parameters
-------------------|-------------------------|-----------------------
Discrete uniform   | `sample()`              | ~                     
Binomial           | `dbinom(x, size, prob)` | `size`: The number of trials
.                  | `pbinom(q, size, prob)` | `prob`: The probability of 'success' in each trial
.                  | `qbinom(p, size, prob)` | 
.                  | `rbinom(n, size, prob)` | 
.                  |                         | 
.                  |                         | 
Poisson            | `dpois(x, lambda)`      | `lambda`: The Poisson mean  
.                  | `ppois(q, lambda)`      | 
.                  | `qpois(p, lambda)`      | 
.                  | `rpois(n, lambda)`      | 
.                  |  .                      | 
Geometric          | `dgeom(x, prob)`        | `prob`: The probability of 'success' in each trial  
.                  | `pgeom(q, prob)`        | 
.                  | `qgeom(p. prob)`        |    
.                  | `rgeom(n, prob)`        | 
.                  |                         | 
Negative binomial  | `dnbinom(x, size, prob, mu)` | `size`: The number of trials          
.                  | `pnbinom(q, size, prob, mu)` | `prob`: The probability of 'success' in each trial
.                  | `qnbinom(p, size, prob, mu)` | `mu`: Useful for alternative parameterisation   
.                  | `rnbinom(p, size, prob, mu)` | 
.                  |                              | 


## Continuous distributions


Distribution       | Probability function | Distribution function | Quantile function     | Random numbers
-------------------|----------------------|-----------------------|-----------------------|-----------------
Discrete uniform   | `sample()`           | ~                     |   ~                   | ~
Binomial           | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Poisson            | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Geometric          | `dgeom()`            | `pgeom()`             | `qunif()`             | `runif()`
Negative binomial  | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Continuous uniform | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Normal|            | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Gamma|             | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$t$                | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$\chi$-squared     | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$F$                | `dunif()`            | `punif()`             | `qunif()`             | `runif()`



## Multivariate distributions 

ADD??




Distribution       | Probability function | Distribution function | Quantile function     | Random numbers
-------------------|----------------------|-----------------------|-----------------------|-----------------
Discrete uniform   | `sample()`           | ~                     |   ~                   | ~
Binomial           | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Poisson            | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Geometric          | `dgeom()`            | `pgeom()`             | `qunif()`             | `runif()`
Negative binomial  | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Continuous uniform | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Normal|            | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
Gamma|             | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$t$                | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$\chi$-squared     | `dunif()`            | `punif()`             | `qunif()`             | `runif()`
$F$                | `dunif()`            | `punif()`             | `qunif()`             | `runif()`



Distribution       | **R**  functions (with common parameters)
-------------------|-----------------------------------------------------------------------------
Discrete uniform   | Random sample: `sample()`  
Binomial           | `dbinom(x, size, prob)`   
.                   | `pbinom(q, size, prob)`  
.                   | `qbinom(p, size, prob)`  
.                   | `rbinom(n, size, prob)`
Poisson            | `dpois(x, lambda)`   
.                   | `ppois(q, lambda)`   
.                   | `qpois(p, lambda)`   
.                   | `rpois(n, lambda)`
Geometric          | `dgeom(x, prob)`   
.                   | `pgeom(q, prob)`   
.                   | `qgeom(p, prob)`   
.                   | `rgeom(n, prob)`
Negative binomial  | `dnbinom(x, size, prob, mu)` 
.                   | `pnbinom(q, size, prob, mu)` 
.                   | `qdbinom(p, size, prob, mu)` 
.                   | `rnbinom(n, size, prob, mu)`
                   

## Standard univariate continuous distributions
                 
                   
Distribution       | **R**  functions (with common parameter)
-------------------|-----------------------------------------------------------------------------
Continuous uniform | `dunif(x, min = 0, max = 1)`   
.                   | `punif(q, min = 0, max = 1)`   
.                   | `qunif(p, min = 0, max = 1)`   
.                   | `runif(r, min = 0, max = 1)`
Normal             | `dnorm(x, mean = 0, sd = 1)`   
.                   | `pnorm(q, mean = 0, sd = 1)`   
.                   | `qnorm(p, mean = 0, sd = 1)`   
.                   | `rnorm(n, mean = 0, sd = 1)`
Gamma              | `dgamma(x, shape, rate = 1, scale = 1 / rate)`  
.                   | `pgamma(q, shape, rate = 1, scale = 1 / rate)`  
.                   | `qgamma(p, shape, rate = 1, scale = 1 / rate)`  
.                   | `rgamma(n, shape, rate = 1, scale = 1 / rate)`
$t$                | `dt(x, df)`      
.                   | `pt(q, df)`      
.                   | `qt(p, df)`      
.                   | `rt(n, df)`
$\chi$-squared     | `dchisq(x, df)`  
.                   | `pchisq(q, df)`  
.                   | `qchisq(p, df)`  
.                   | `rchisq(n, df)`
$F$                | `df(x, df1, df2)`      
.                   | `pf(q, df1, df2)`      
.                   | `qf(p, df1, df2)`      
.                   | `rf(n, df1, df2)`



## Standard bivariate distributions

Add `mvtnorm::dmvnor()`???

`rmultinom(n, size, prob)`

`dmultinom(x, size = NULL, prob, log = FALSE)`


# Solutions

## Answers for Chap. 1

:::{.answer}
**Answer to Exercise \@ref(exr:BasicProbs).**

1. Probably the Venn diagram.
1. $0.74$.
2. $0.11$.
3. $0.40$
4. $0.13/0.24 = 0.5416...$
5. $\Pr(A) \times \Pr(B) = 0.44\times 0.35 = 0.1272 \ne \Pr(A\cap B) = 0.13$; not independent... but close!
:::





:::{.answer}
**Answer to Exercise \@ref(exr:DrawNumbers).**

1. $(50/100)\times (49/99)\times (48/98)\times (47/97) \approx 0.0578$.
1. $^{50}C_2\times ^{50}C_2 / ^{100}C_4 / = 1225/3201 \approx 0.3826$.
1. $\Pr(\text{at least 2 odd before 1st even}) = \Pr(\text{odd, odd, even, either}) + \Pr(\text{odd, odd, odd, even)} = (50/100)\times(49/99)\times(50/98) + (50/100)\times (49/99)\times(48/98)\times(50/97) \approx 0.1887$.
1. $\Pr(\text{sum odd}) = \Pr(\text{exactly 1 odd number drawn, OR exactly 3 odd numbers drawn}) = \displaystyle{\frac{1600}{3201}}$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:Quadratic).**

1. $S = \{ (a,b,c) \mid a\in(-\infty, 0)\cap (0, \infty), -\infty < b < \infty, -\infty < c < \infty\}$.
1. The solutions to a quadratic equation are given by
\[
   x = \frac{-b \pm \sqrt{b^2 - 4ac} }{2a}.
\]
For two equal roots, $b^2 - 4ac = 0$, so event $R$ is defined as $R = \{ (a,b,c) \mid b^2 - 4ac = 0\}$.
1. For no real roots, $b^2 - 4ac < 0$, so event $Z$ is defined as $Z = \{ (a,b,c) \mid b^2 - 4ac < 0\}$.
:::



:::{.answer}
**Answer to Exercise \@ref(exr:GreenLights).**

1. The length of time (in seconds) between green lights at the intersection, say $G$.
2. $S = \{G \mid 15 \le G \le 150\}$.
3. No---no equally likely events are defined
4. The probability can be *approximated*---observe the lights many times, and count how often there is less than 90 seconds between green
lights.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:Cricket).**

1. $C^7_5 \times C^5_4 \times C^2_1 \times C^1_1 = 210$.
2. $11^2 + (2\times 22) = 165$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:WalkScore).**
???
:::




:::{.answer}
**Answer to Exercise \@ref(exr:HatData).**

Tree diagram: Fig, \@ref(fig:HatTree); table: Table \@ref(tab:HatTable); Venn diagram: Fig. \@ref(fig:HatVenn).
:::


```{r HatTree, echo=FALSE, fig.align="center", fig.cap="Tree diagram for the hat-wearing example", fig.width=4, fig.height=4, out.width='70%'}

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      main = "Tree diagram for the hat data",
      xlab = "",
      ylab = "",
      axes = FALSE)
#STEP 1
lines( x = c(0.2, 0.40),
       y = c(0.5, 0.75),
       lwd = 2)
lines( x = c(0.2, 0.40),
       y = c(0.5, 0.25),
       lwd = 2)
# STEP 2
lines( x = c(0.60, 0.80),
       y = c(0.75, 0.90),
       lwd = 2)
lines( x = c(0.60, 0.80),
       y = c(0.75, 0.60),
       lwd = 2)

lines( x = c(0.60, 0.80),
       y = c(0.25, 0.40),
       lwd = 2)
lines( x = c(0.60, 0.80),
       y = c(0.25, 0.10),
       lwd = 2)

# TEXT
text(x = 0.50,
     y = 0.75,
     labels = "Males")
text(x = 0.50,
     y = 0.25,
     labels = "Females")

text(x = 0.90,
     y = 0.90,
     labels = "Hat")
text(x = 0.90,
     y = 0.60,
     labels = "No hat")

text(x = 0.90,
     y = 0.40,
     labels = "Hat")
text(x = 0.90,
     y = 0.10,
     labels = "No hat")

# ADD PROBS
text(x = 0.38,
     y = 0.63,
     cex = 0.9,
     labels = "0.513")
text(x = 0.38,
     y = 0.37,
     cex = 0.9,
     labels = "0.487")

text(x = 0.65,
     y = 0.84,
     cex = 0.9,
     labels = "0.205")
text(x = 0.65,
     y = 0.66,
     cex = 0.9,
     labels = "0.795")

text(x = 0.65,
     y = 0.34,
     cex = 0.9,
     labels = "0.060")
text(x = 0.65,
     y = 0.16,
     cex = 0.9,
     labels = "0.940")

## STEPS
text(x = 0.50,
     y = 0.01,
     label = expression(bold("Step 1"))
     )
text(x = 0.90,
     y = 0.01,
     label = expression(bold("Step 2"))
     )
```


```{r HatTable, echo=FALSE}
BRIS <- read.csv("Data/sunglasses.csv")
BRIS$Gender <- factor(BRIS$Gender,
                      levels = c(1, 2),
                      labels = c("Males", 
                                 "Females"))
BRIS$Hat <- factor(BRIS$Hat,
                   levels = c(0, 1),
                   labels = c("Not Hat",
                              "Hat"))

HatTable <- xtabs( Count ~ Gender + Hat,
                   data = BRIS)
HatTable <- cbind( HatTable,
                   "Total" = rowSums(HatTable) )
knitr::kable(HatTable,
             caption = "The numbers of males and females wearing a hat in the middle of the day in Brisbane")
```



```{r HatVenn, echo=FALSE, fig.width=7, fig.height=7, out.width='70%', fig.align="center", fig.cap="The hat-wearing data as a Venn diagram"}
par( mfrow = c(2, 2))
colourMale <- rgb(0, 0, 255, 
                  max = 255, 
                  alpha = 125)
colourHat  <- rgb(0, 255, 0, 
                  max = 255, 
                  alpha = 125)

plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(M), " and ", bar(italic(M)))),
      axes = FALSE)

polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourMale)
text(x = 0.4,
     y = 0.5,
     labels = expression(paste(italic(M), ": 307")))
text(x = 0.8,
     y = 0.5,
     labels = expression(paste(bar(italic(M)), ": 366")))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


###############


plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(H), " and ", bar(italic(H)))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))

plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourHat)

text(x = 0.6,
     y = 0.5,
     labels = expression(paste(italic(H), ": 101")))
text(x = 0.2,
     y = 0.5,
     labels = expression(paste( bar(italic(H)), ": 651")))

mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


####################


plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = expression(paste("Events ", italic(M), " and ", italic(H))) ,
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourMale)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourHat)
text(x = 0.3,
     y = 0.5,
     labels = expression(italic(M)))
text(x = 0.7,
     y = 0.5,
     labels = expression(italic(H)))
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)


#################



plot( x = c(0, 1),
      y = c(0, 1),
      type = "n",
      ylab = "",
      xlab = "",
      main = "The numbers in each section",
      axes = FALSE)


polygon( x = c(0, 0, 1, 1),
         y = c(0, 1, 1, 0))
plotrix::draw.circle(x = 0.4, 
                     y = 0.5,
                     radius = 0.2,
                     col = colourMale)
plotrix::draw.circle(x = 0.6,
                     y = 0.5,
                     radius = 0.2,
                     col = colourHat)
text(x = 0.3,
     y = 0.5,
     labels = "307")
text(x = 0.7,
     y = 0.5,
     labels = "22")
text(x = 0.7,
     y = 0.85,
     labels = expression(bar(italic(M)) ~ intersect() ~ bar(italic(H)) ~ ": 344") )
mtext(text = expression(italic(S)),
      side = 1,
      adj = 0.25)

# Intersection
text(x = 0.5, 
     y = 0.5, 
     label = "79")

```



:::{.answer}
**Answer to Exercise \@ref(exr:CarPassengers).**
A family with six non-driving children, and two driving parents has an eight-seater vehicle.

1. In how many ways can the family be seated in the car (and legally go driving)?
1. Suppose one of the children obtains their driving licence.
   In how many ways can the family be seated in the car (and legally go driving) now?
1. Two of the children needs car seats, and there are two car seats fixed in the vehicle (i.e., they cannot be moved to different seats).
   If the two parents are the only drivers, in how many ways can the family be seated in the car (and legally go driving) now)?

Here, the location of where people sit (i.e., the 'order') is relevant, so use permutations.

1. $^2C_1 \times ???$.

:::



:::{.answer}
**Answer to Exercise \@ref(exr:MatchingBrackets).**

Many document processors help users match brackets.
Bracket matching is an interesting mathematical problem!
For instance, the string `(())` is syntactically valid, whereas `())(` is not, even though both contain two opening and two closing brackets.


1. `()()` and `(())`. 
   There are two ways.
1. `()()()` and `(())()` and `()(())` and `((()))` and `(()())`. 
   There are five ways.
1. $\displaystyle \frac{1}{n + 1} \binom{2n}{n} = \frac{1}{n + 1}\frac{(2n)!}{n!n!}  = \frac{1}{(n + 1)!} \frac{(2n)!}{n!}$ as to be shown.
1. ANSWER: Show that another expression for $C_n$ is $\displaystyle \binom{2n}{n} - \binom{2n}{n + 1}$ for $n\geq 0$.
1. The first nine Catalan numbers, for $n = 0, \dots 8$, are $1, 1, 2, 5, 14, 42, 132, 429, 1430$
:::



:::{.answer}
**Answer to Exercise \@ref(exr:CompareMeansStress).**

????
:::






:::{.answer}
**Answer to Exercise \@ref(exr:Stirling).**

```{r fig.cap="Relative error of Stirling's approximation"}
# Define a function to compute Stirling numbers:
stirling <- function(n){ 
  sqrt(2 * pi *( n)) * (n/exp(1))^n
}

n <- 1:10
Actual <- factorial(n) 
Approx <- stirling(n)
RelError <- (Actual - Approx)/Actual * 100

cbind(Actual, Approx, RelError)

plot(RelError ~ n,
     ylim = c(0, 8),
     las = 1, 
     type = "b",
     pch = 19,
     lwd = 2,
     xlab = expression(italic(n)),
     ylab = "Relative error (%)",
     main = "Relative error of\nStirling's approximation")
```
:::




:::{.answer}
**Answer to Exercise \@ref(exr:DiceGame).**

1. $\Pr(\text{Player throwing first wins}) = \Pr(\text{First six on throw 1 or 3 or 5 or \dots}) = \Pr(\text{First six on throw 1}) + \Pr(\text{First six on throw 3}) + \cdots$.
   This produces a geometric progression that can be summed obtained (see App \@ref(UsefulSeries)).
2. Use Theorem \@ref(thm:TotalProb).
   Define the events $A = \text{Player 1 wins}$, $B_1 = \text{Player 1 throws first}$, and $B_2 = \text{Player 1 throws second}$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:RandomisedResponse).**

1. Use Theorem \@ref(thm:TotalProb) to find $\Pr(Y)$.
2. $Y$ = \{Yes\}, $D$ = \{Student has used illegal drugs in last 12 months\}, $\overline{D}$ = \{student hasn't used illegal drugs in last 12 months\}.
3. $\displaystyle \Pr(D)= \frac{N\Pr(Y) - [N - m]}{2m - N}$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:MCExam).**

Use Theorem \@ref(thm:TotalProb) to find $\Pr(C)$ where $C = \text{select correct answer}$, $K = \text{student knows answer}$. 
Then, $\Pr(C)  =\displaystyle {\frac{mp + q}{m}}$
:::





## Answers for Chap. 2

:::{.answer}
**Answer to Exercise \@ref(exr:SSpaceRV).**

1. $R_X = \{ 0, 1, 2\}$; discrete.
2. $R_X = \{1, 2, 3\dots \}$; discrete.
3. $R_X = (0, \infty)$; continuous.
4. $R_X = (0, \infty)$; continuous.
5. $R_X = \{0, 1, 2, \dots\}$; discrete.
6. $R_X = \{0, 1, 2, \dots\}$; discrete.
7. $R_X = (0, \infty)$; continuous.
:::



:::{.answer}
**Answer to Exercise \@ref(exr:DFcontinuous).**

1. $\displaystyle F_X(x) = 
   \begin{cases}
      0   & \text{for $x < 10$}\\
      0.3 & \text{for $10 \le x < 15$}\\
      0.5 & \text{for $15 \le x < 20$}\\
      1   & \text{for $x \ge 20$}.
    \end{cases}$
1. $\Pr(X > 13) = 1 - F_X(13) = 0.7$.
1. $\Pr(X \le 10 \mid X\le 15) = \Pr(X \le 10) / \Pr(X \le 15) = F_X(10)/F_X(15) = 0.3/0.5 = 0.6$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:DFcontinuous).**

1. $\displaystyle F_Z(z) = 
    \begin{cases}
        0                     &  \text{for $z \le -1$};\\
        6z/15 - z^2/15 + 7/15 & \text{for $-1 < z < 2$};\\
        1                     & \text{for $z \ge 2$}.
    \end{cases}.$
1. $\Pr(Z < 0) = F_Z(0) = 7/15$.
:::



:::{.answer}
**Answer to Exercise \@ref(exr:DFdiscreteBackwards).**

1. $\displaystyle
   p_W(w) = \begin{cases}
               0.3 & \text{for $w = 10$};\\
               0.4 & \text{for $w = 20$};\\
               0.2 & \text{for $w = 30$};\\
               0.1 & \text{for $w = 40$};\\
               0   & \text{elsewhere}.
            \end{cases}$
1. $\Pr(W < 25) = 0.7$.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:DFcontinuousBackwards).**

1. $\displaystyle
   f_Y(y) = \begin{cases}
               (4/3) - y^2 & \text{for $0 < y < 1$};\\
               0 & \text{elsewhere}.
            \end{cases}$
1. $\Pr(Y < 0.5) = 0.625$.
:::







## Answers for Chap. 3


:::{.answer}
**Answer for Exercise \@ref(exr:C3ContA).**

1. $k = -3/2$.
2. See Fig. \@ref(fig:PDFY).
3. $\text{E}(Y) = ???$.
4. ???.
5. $\Pr(X > 1.5) = \int_{1.5}^2 f_Y(y)\, dy = ???$.

```{r, PDFY, echo=FALSE, fig.align="center", fig.cap="The pdf for Y"}
xx <- seq(0, 3, 
          length = 500)
fy <- function(x){
  y <- 2*x - 3/2
  y <- ifelse(x < 1, 0, y)
  y <- ifelse( x > 2, 0, y)
  y
}

plot(x = xx,
     y = fy(xx),
     lwd = 2,
     type = "l",
     main = "Pdf for D",
     xlab = "D",
     ylab = "Prob. fn")
```

:::


:::{.answer}
Answer to Exercise \@ref(exr:C3DiscreteA).

1. $k = 1/4$.
1. $\text{E}(D) = 1.75$, $\text{var}(D) 0.6875$.
1. $M_D(t) = \exp(t)/2 + \exp(2t)/4 + \exp(3t)/4$.
:::


:::{.answer}
Answer to Exercise \@ref(exr:C3DiscreteB).

1. $M_Z'(t) = 0.6\exp(t)[0.3\exp(t) + 0.7]$ so $\text{E}(Z) = 0.6$.
   Also, $M''_Z(t) = 0.18\exp(2t) + 0.6\exp(t)[0.3\exp(t) + 0.7]$ so $\text{E}(Z^2) = 0.78$, hence so $\text{var}(Z) = 0.42$ (be careful with the derivatives here!); expand the quadratic and find $\Pr(Z = 0) = 0.49$, $\Pr(Z = 1) = 0.42$,
$\Pr(Z = 2) = 0.09$.
:::


:::{.answer}
Answer to Exercise \@ref(exr:C3MGFA).

1. $M'_G(t) = \alpha\beta(1 - \beta t)^{-\alpha - 1}$ so $\text{E}(G) = \alpha\beta$.
   $M''_G(t) = \alpha\beta^2(\alpha + 1)(1 - \beta t)^{-\alpha - 2}$ so $\text{E}(G^2) = \alpha\beta^2(\alpha + 1)$ and $\text{var}(G) = \alpha\beta^2$.
:::


:::{.answer}
Answer to Exercise \@ref(exr:C3Moments).

1. $\mu'_r = \text{E}(X^r) = \int_{x = 0}^1 x^r 2(1 - x)\, dx = 2\left[ \left(\frac{x^{r + 1}}{r + 1} - \frac{x^{r + 2}}{r + 2}\right)\Big|_{0}^{1}\right] = 2\left[ \frac{1}{r + 1} - \frac{1}{r + 2}\right]$.
1. Expanding, $\text{E}((X + 3)^2) = \text{E}(X^2) + 6\text{E}(X) + 9$.
   Now, $\text{E}(X) = \mu'_1 = 1/3$ from above, and $\text{E}(X^2) = \mu'_2 = 1/6$ from above.
   Hence $\text{E}((X + 3)^2) = 67/6$.
1. $\text{var}(X) = \text{E}(X^2) - \text{E}(X)^2 = 1/18$.
:::






:::{.answer}
Answer to Exercise \@ref(exr:C3Cauchy).

1. See Fig. \@ref(fig:Cauchy) (left panel).
1. Evaluate $F_X(t) = \displaystyle \int_{-\infty}^t \frac{1}{\pi(1 + x^2)}\,dx = \frac{1}{\pi}\arctan(x) + \frac{1}{2}$.
   See Fig. \@ref(fig:Cauchy) (right panel).
1. $\displaystyle \text{E}(X) =  \int_{-\infty}^t \frac{x}{\pi(1 + x^2)}\,dx = ...$, which is not defined.
:::

```{r Cauchy, fig.align="center", fig.cap="The Cauchy distribution", fig.height=4, fig.width=7,out.width='70%'}
par( mfrow = c(1, 2))
x <- seq(-5, 5,
         length = 100)
y <- 1 / (pi * (1 + x^2))
plot(y ~ x,
     lwd = 2,
     las = 1,
     type = "l",
     main = "Density function for\nthe Cauchy distribution",
     xlab = "X",
     ylab = "Density function")

Y <- atan(x)/pi + 0.5
plot(Y ~ x,
     lwd = 2,
     las = 1,
     ylim = c(0, 1),
     type = "l",
     main = "Distribution function for\nthe Cauchy distribution",
     xlab = "X",
     ylab = "Distribution function")
```



:::{.answer}
Answer to Exercise \@ref(exr:C3MGFSymmetric).

Begin with Definition \@ref(def:MGF) for $M_X(t)$ and use fact that if a distribution is symmetric about 0 then $f_X(x) = f_X(-x)$ using symmetry. 
Transform the resulting integral.
:::






## Answers for Chap. 4



## Answers for Chap. 5



## Answers for Chap. 6

:::{.answer #DiscreteXY}
1. This corresponds to the cell $X = 1, Y = 2$:  the answer is $1/20$. 
1. $\Pr(X + Y \le 1) = \Pr(X = 0, Y = 0) + \Pr(X = 0, Y = 1) + \Pr(X = 1, Y=0) = 1/2$.
1. $\Pr(X > Y) = \Pr(X = 1, Y = 0) + \Pr(X = 2, Y = 0) + \Pr(X = 2, Y = 1) = 7/30$.
1. Write:
\[
   p_X(x) = \begin{cases}
            7/15 & \text{if $x = 0$};\\
            7/15 & \text{if $x = 1$};\\
            1/15 & \text{if $x = 2$};\\
            0 & \text{otherwise}.
            \end{cases}
\]
1. Only consider the column corresponding to $X = 1$:
\[
   p_{Y\mid X = 1}(y\mid x = 1) = 
   \begin{cases}
            (1/6)/(7/15) = 15/42 & \text{if $y = 0$};\\
            (1/4)/(7/15) = 15/28 & \text{if $y = 1$};\\
            (1/20)/(7/15) = 3/28 & \text{if $y = 2$};\\
            0 & \text{otherwise}.
   \end{cases}
\]
:::

:::{.answer}
**Answer to Exercise \@ref(exr:AandBsimple).*

1. $7$ ; 2. $5$; 3. $-6$; $35$.
:::






## Answers for Chap. 7

:::{.answer}
**Answer to Exercise \@ref(exr:Ycubed).**

For $0 < x < 2$, the transformation is one-to-one.
The inverse transform is $X = Y^{1/3}$, and so $0 < y < 8$.

1. $F_Y(y) = \Pr{Y\le y}
   = \Pr{X^3 \le y} = \Pr{X\le y^{1/3}}= F_X( y^{1/3})
   = \int_{u = 0}^{y^{1/3}} u/2\,du = u^2/4\Big|_{u = 0}^{u = y^{1/3}} = y^{2/3}/4.$
Differentiate to find the pdf: 
$\frac{d}{dy} y^{2/3}/4 = y^{-1/3}/6$. 
The pdf of $Y$ is
\[
   f_Y(y) = \begin{cases}
               y^{-1/3}/6 & \text{for $0 < y < 8$};\\
               0 & \text{otherwise}.
            \end{cases}
\]

2. Since $w(y) = y^{1/3}$, then $w'(y) = y^{-2/3}$.
Then:
\begin{align*}
   f_Y(y)
   &= f_X(y) |J|\\
   &= y^{1/3}/2 \times \overbrace{y^{-2/3}/3}^{|J|} \\
   &= y^{-1/3}/6.
\end{align*}
So the pdf of $Y$ is as above.
:::


:::{.answer}
**Answer to Exercise \@ref(exrJointDiscrete).**

Note $Y_1$ takes the values $1$ and $2$ for $Y_2 = 0$;
$Y_1$ takes the values $2$ and $3$ for $Y_2 = 1$.

The joint pf is shown in Table \@ref(tab:JDTable).
Hence,
\[
   f_{Y_1} = 
   \begin{cases} 
      2/14 & \text{if $y_1 = 1$};\\
      7/14 & \text{if $y_1 = 2$};\\
      5/14 & \text{if $y_1 = 3$};\\
      0    & \text{otherwise}.
    \end{cases}
\]

```{r JDTable, echo=FALSE}
JDTable <- array( dim = c(2, 4))

colnames(JDTable) <- c("",
                       "$Y_1 = 1$",
                       "$Y_1 = 2$",
                       "$Y_1 = 3$")
JDTable[1, ] <- c("",
                  "2/14",
                  "4/14",
                  "0")
JDTable[2, ] <- c("",
                  "0",
                  "3/14",
                  "5/14")
kable(JDTable)
```
:::

:::{.answer}
**Answer to Exercise \@ref{exr:GammaSum}.**

$Y \sim\text{Gam}(\sum\alpha, \beta)$.
:::
  
  
:::{.answer}
**Answer to Exercise \@ref{exr:CauchySquared}.**
  
Transformation is not 1-1. 
$f_Y(y)=\displaystyle {\frac{1}{\pi \sqrt{y}(1 + y)}}$ for $0 < y < \infty$.
:::

:::{.answer}
**Answer to Exercise \@ref(exr:ContTransform).**

1. $f_x(x) = x$ for $-0.5 < x < 0.5$.  
1. $F_Y(y) =\Pr(Y \le y) = 1 - 2\sqrt{4 - y}$ for $3.75 < y < 4$.
1. $f_Y(y) = (4 - y)^{-1/2}$.
:::

## Answers for Chap. 8

  
:::{.answer}
**Answer to Exercise \@ref(exr:CLTProb).**

$\text{E}(Y) = \int_0^1 y(3y^2)\, dy = 3/4$.
$\text{E}(Y^2) = 3/5$, so $\text{Var}(Y) = 3/80$. 
By the CLT, $\overline{Y}\sim N(3/4, 3/(80n) )$. 
Therefore
\[
   \Pr( 3/4 - \sqrt{3/80} < \overline{Y} < 3/4 + \sqrt{3/80} )
   = \Pr(0.56 < \overline{Y} < 0.94)
\]
is needed. For a sample of size $n$,
\[
   \Pr( \frac{0.56 - 0.75}{0.19/\sqrt{n}} < Z < \frac{0.56 - 0.75}{0.19/\sqrt{n}} )
   = \Pr(-\sqrt{n} < Z < \sqrt{n} )
\]
which approaches one as $n\to\infty$.
For example, if $n = 10$, $\Pr(-\sqrt{10} < Z < \sqrt{10} ) = 0.9984$.
:::
  
:::{.answer}
**Answer to Exercise \@ref(exr:EggsVariance).**

Let the weight be $E$, so $E\sim N(59, 0.7)$. 
By the CLT, the sample mean $\overline{E} \sim N(59, 0.7/12)$. 
So
\[
   \Pr(\overline{E} > 59.5)
   = \Pr(Z > \frac{59.5 - 59}{\sqrt{0.7/12}})
   = \Pr(z > 2.07)
   \approx 0.019.
\]
1. We seek $\Pr(s^2 > 1}$. 
Since 
\[
   \frac{(n - 1)s^2}{\sigma^2}\sim \chi^2_{n - 1}
\]
where $n = 12$ and $\sigma^2 = 0.7$. So
\begin{align*}
   \Pr(s^2 > 1)
   &= \Pr( \frac{11 s^2}{0.7} > \frac{11\times 1}{0.7} )\\
   &=\Pr( \chi^2_{11} > 15.714)\\
   &\approx 0.152.
\end{align*}
:::
  
:::{.answer}
**Answer to Exercise \@ref(exr:EggsBroken).**

Let the number broken be $B$, so $B \sim \text{Pois}(0.2)$. 
The sample mean number broken has the distribution $\overline{B}\sim N(0.2, 0.2/\sqrt{12})$ approx. 
So
\[
   \Pr(B\ge 1) 
   = \Pr(Z > \frac{1 - 0.2}{\sqrt{0.2\sqrt{12}}})
   = \Pr(Z > 6.196) = 0.
\]
In contrast, in any one carton, the probability of more than one
broken egg is
\[
   \Pr(B > 1) = 1 - \Pr(B = 0) = 1 - 0.8187 = 0.181
\]
using the Poisson distribution.
:::

:::{.answer}
**Answer to Exercise \@ref(exr:ContRVM).**
  
1. $\text{E}(M) = 3/4$.
1. $\text{var}(M) = 3/80$.
1. $\overline{M}\sim N(3/4, 1/240)$.
1. $0.8788$.
:::
  
  

  
  
  