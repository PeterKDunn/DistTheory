## Answers for Chap. 4


:::{.answer}
**Answer to Exercise \@ref(exr:BinChange).**
From what is given: $p_X(x; n, 1 - p) = \binom{n}{x} (1 - p)^x p^{n - x}$.
Then, define $Y = n - X$ and hence 
$f_Y(y) = \binom{n}{y} p^y (1 - p)^{n - y}$, which is $f_Y(y) = \binom{n}{n - x} p^{n - x} (1 - p)^{n}$.
It is easy to show that $\binom{n}{x} = \binom{n}{n - x}$ and hence $f_X(x)$ and $f_Y(y)$ are equivalent.
:::


:::{.answer}
**Answer to Exercise \@ref(exr:SaltIntake).**

Care: The geometric is parameterised so that $x$ is the number of *failures* before a success (not the number of *trails*).
Similarly for the negative biniomial.


```{r echo=TRUE}
sum( dbinom(10:25, # Part 1
            size = 25,
            prob = 0.30) )
sum( dbinom(0:9,  # Part 2
            size = 25,
            prob = 0.30) )
sum( dbinom(5:10,  # Part 3
            size = 25,
            prob = 0.30) )
dgeom(x  = 5,  # Part 4: 5 fails before 1st success
      prob = 0.30)

sum( dgeom(x  = 7:50,  # Part 5: Num. fails! 
           prob = 0.30) )

# Part 6; This means 5 fails, before 3rd success
dnbinom(x = 5,
        prob = 0.30,
        size = 3)
```

Assumes independence of people, and a *constant* probability.
:::


<!-- :::{.answer} -->
<!-- **Answer to Exercise \@ref(exr:Placebos).** -->

<!-- Care: The geometric is parameterised so that $x$ is the number of *failures* before a success (not the number of *trails*). -->
<!-- Similarly for the negative binomial. -->

<!-- ```{r echo=TRUE} -->
<!-- sum( dbinom( 16:81,  # Part 1 -->
<!--              size = 81, -->
<!--              prob = 0.20) ) # 0.5663638-->
<!-- sum( dbinom( 12:81,  # Part 2 -->
<!--              size = 81, -->
<!--              prob = 0.20) ) # 0.9082294-->
<!--   # Part 3 -->
<!-- dgeom(x = 2, #i.e., two failures before first success -->
<!--       prob = 0.20) # 0.128-->

<!--   # Part 4 -->
<!-- dnbinom(x = 5, # is 5 fails before 5th success -->
<!--         prob = 0.20, -->
<!--         size = 10) -->
<!-- sum( dbinom(50:81, -->
<!--             size = 81, -->
<!--             prob = 0.2) ) -->
<!-- ``` -->
<!-- ::: -->


:::{.answer}
**Answer to Exercise \@ref(exr:NoisyMiners).**

```{r echo=TRUE}
dpois( 0,  # Part 1
       lambda = 3)
sum( dpois( 6:50,  # Part 2
            lambda = 3) )
dpois( 2,   # Part 3
       lambda = 6)
```
:::



:::{.answer}
**Answer to Exercise \@ref(exr:DisaggregationPoisson).**

See Fig. \@ref(fig:RainEventsPlotA).

```{r RainEventsPlot, fig.show="hide"}
x <- 0:10
pSummer <- dpois(x,
                 lambda = 2.5)
pWinter <- dpois(x,
                 lambda = 1.9)

plot( pWinter ~ x,
      las = 1,
      pch = 19,
      ylab = "Probability",
      xlab = "Number of rainfall events")
points( pSummer ~ x,
        pch = 0)
lines( ifelse(pWinter > pSummer, pWinter, pSummer) ~ x,
       type = "h", # Add vertical lines
       lty = 2,
       col = "grey")
 
legend("topright",
       pch = c(19, 0),
       legend = c("Winter", "Summer"))

sum( dpois(4:20,  # Part 2
     lambda = 1.9) )
sum( dpois(4:20,  # Part 3
     lambda = 2.5) )

# Part 4
sum( dpois(4:20, lambda = 2.5) ) /
   sum( dpois(2:20, lambda = 2.5) )

# Part 5
sum( dpois(3:10, lambda = 1.9) ) /
   sum( dpois(2:10, lambda = 1.9) )
```
:::

```{r, RainEventsPlotA, fig.width=5, echo=FALSE, results='hide', fig.cap="The number of rainfall events in summer and winter", fig.align="center"}
<<RainEventsPlot>>
```



<!-- :::{.answer} -->
<!-- **Answer to Exercise \@ref(exr:UnknownSize).** -->

<!-- 1. Yep. -->
<!-- 1. $\log n_x = \log N + \log p + x\log (1 - p)$, which is a linear regression model of $\log n_x$ regressed on $x$, with intercept $\beta_0 = \log N + \log p$ and slope $\beta_1 = \log (1 - p)$. -->
<!-- 1. So from the fitted slope, we can estimate $p$; then, using the estimated intercept, we can estimate $N$. -->
<!-- More specifically, the estimate of $p$ is $1 - \exp( \hat{\beta}_1)$, and the estimate of $N$ is then $\exp(\beta_0 - \log p)$. -->
<!-- The population size is estimate as about 894: -->
<!-- ::: -->

<!-- ```{r echo=TRUE} -->
<!-- x <- 1:6 -->
<!-- nx <- c(247, 63, 20, 4, 2, 1) -->

<!-- m1 <- lm( log(nx) ~ x); coef(m1) -->
<!-- beta0 <- coef(m1)[1] -->
<!-- beta1 <- coef(m1)[2] -->

<!-- p <- 1 - exp(beta1); p -->
<!-- N <- exp(beta0 - log(p) ); N -->
<!-- ``` -->
<!-- p = 0.6765636 -->
<!-- N = 894.2445 -->


:::{.answer}
**Answer to Exercise \@ref(exr:NigerianWater)**
Defining $X$ as the 'number of failures until 4kWh/m^2^ was observed', since the parameterisation used in the textbook is for *the number of failures until the first success*.

Then, $X\sim \text{Geom}(p)$.


1. $\text{E}(X) = (1 - p)/p = 1$ failures till first success, followed by the day of success: So 2.
1. $\text{E}(X) = (1 - p)/p = 3$ failures, so $3 + 1 = 4$.
1. $\text{var}(X) = (1 - p)/p^2 = 12$.

```{r}
# Part 4
sum( dgeom(0:2,  # 0 to 2 failures before the success
           prob = 0.25))

```
:::


<!-- :::{.answer} -->
<!-- **Answer to Exercise \@ref(exr:LayDate).** -->

<!-- 1. See Fig. \@ref(fig:LayData). -->
<!--    They are not hugely different. -->
<!-- 1. Similar probabilities: 0.85 (in 1999) and 0.91 (in 2000). -->
<!-- 1. Similar: 16 days (in 1999) and 12 (in 2000). -->
<!-- 1. Writing $X$ for the clutch size (where $n = 237$): -->

<!--    * $\text{E}(X) = (1\times \frac{9}{237}) + (2\times \frac{29}{237}) + (3\times \frac{199}{237}) =   2.801688$, or about 2.8. -->
<!--    * $\text{E}(X^2) = (1^2\times \frac{9}{237}) + (2^2\times \frac{29}{237}) + (3^2\times \frac{199}{237}) = 8.084388$. -->
<!--    * So, $\text{var}(X) = 8.084388 - (2.801688)^2 = 0.2349324$, so the standard deviation is 0.4846982, or about 0.485. -->
<!-- ::: -->

<!-- ```{r} -->
<!--   ## Part 2 -->
<!-- pnbinom(30, mu = 23.0, size = 20.6) # 0.8583004-->
<!-- pnbinom(30, mu = 19.5, size = 8.9) # 0.9082475-->
<!--   ## Part 3 -->
<!-- qnbinom(0.15, mu = 23.0, size = 20.6) # 16 -->
<!-- qnbinom(0.15, mu = 19.5, size = 8.9)  # 12-->

<!-- ``` -->

<!-- ```{r LayData, out.width='80%', fig.width=8, fig.height = 3.5, fig.cap="The lay date model for glaucous-winged gulls, in 1999 and 2000", fig.align="center"} -->
<!-- x <- 0:50  -->
<!-- y1999 <- dnbinom(x, mu = 23.0, size = 20.6) -->
<!-- y2000 <- dnbinom(x, mu = 19.5, size = 8.9) -->

<!-- plot( y1999 ~ x, -->
<!--       pch = 19, -->
<!--       las = 1, -->
<!--       main = "Lay date for glaucous-winged gulls", -->
<!--       xlab = "Lay date", -->
<!--       ylab = "Prob. function") -->
<!-- points( y2000 ~ x, -->
<!--         pch = 1) -->
<!-- legend("topleft", -->
<!--        pch = c(19, 1), -->
<!--        legend = c("1999", -->
<!--                   "2000")) -->

<!-- ``` -->





:::{.answer}
**Answer to Exercise \@ref(exr:NegativeBinomialALT).**

In Eq. \@ref(eq:NegativeBinomialPMF), the rv $X$ refers to the number of *failures* before the $r$th success is observed, so that $X = 0, 1, 2, \dots$.
So define $Y$ as the number of trials till the $r$th success, and hence $Y = X + r$.

1. The range space is $Y\in\{r, r + 1, r + 2, \dots\}$
1. \begin{equation}
   p_Y(y; p, r) = \binom{y - 1}{r - 1}(1 - p)^{y - r} p^{r - 1}
   \quad\text{for $y = r, r + 1, r + 2, \dots$}
\end{equation}
1. $\text{E}(Y) = \text{E}(X + r) = \text{E}(X) + r = r/p$.  
   $\text{var}(Y) = \text{var}(X + r) = \text{var}(X) = r(1 - p)/p^2$.  

:::



<!-- :::{.answer} -->
<!-- **Answer to Exercise \@ref(exr:PoissonTypos).** -->

<!-- Let $X$ be the number of typos per minute; then $X\sim\text{Pois}(\lambda = 2.5\times 5 = 12.5)$ for a five-minute test. -->

<!-- ```{r} -->
<!-- dpois(10, lambda = 12.5) # 0.09564364-->
<!-- dpois(6, lambda = 2.5 * 3) * dpois(4, lambda = 2.5 * 2) #  0.02398959-->
<!-- ``` -->

<!-- For part 3: The number of errors occurring in the 'overlap minute' could be 0, 1, 2, \dots 6. -->
<!-- So proceed: -->

<!-- * 6 errors in overlap minute:   -->
<!--  $\Pr(\text{0 errors first 2 mins})\times{}$  -->
<!--  $\Pr(\text{6 errors overlap min})\times{}$ -->
<!--  $\Pr(\text{0 errors final 2 mins})$  -->
<!-- * 5 errors in overlap minute:   -->
<!--  $\Pr(\text{1 error first 2 mins})\times{}$  -->
<!--  $\Pr(\text{5 errors overlap min})\times{}$ -->
<!--  $\Pr(\text{1 error final 2 mins})$  -->

<!-- <!-- And so on. --> -->

<!-- ```{r} -->
<!-- prob <- function(ErrorsInOverlap){ -->
<!--   dpois( (6 - ErrorsInOverlap), lambda = 2 * 2.5) * -->
<!--   dpois(ErrorsInOverlap, lambda = 1 * 2.5) * -->
<!--   dpois((6 - ErrorsInOverlap), lambda = 2 * 2.5) -->
<!-- } -->
<!-- sum( prob( 0:6 ) ) # 0.02120811 -->
<!-- ``` -->
<!-- ::: -->



:::{.answer}
**Answer to Exercise \@ref(exr:RiverDepth).**

1. $0.25$.
2. `dbinom(x = 2, size = 4, prob = 0.25)` ${}=  0.2109375$.
:::




<!-- :::{.answer} -->
<!-- **Answer to Exercise \@ref(exr:QueuingPois).** -->

<!-- The code below is for one simulation for each part only. -->

<!-- ```{r, fig.align="center", fig.cap="A simulation"} -->
<!-- ### Part 1 -->
<!-- set.seed(2268) # For reproducibility -->

<!-- queueLength <- array(dim = 60) -->

<!-- queueLength[1] <- rpois(1, lambda = 0.5) -->

<!-- for (i in 2:60){ -->
<!--    queueLength[i] <- queueLength[i - 1] + rpois(1, lambda = 0.5) -->
<!--    # Print every 10 minutes -->
<!--    if ( floor(i/10) == i/10 ) { -->
<!--      cat("After ", i, " minutes past 8AM, queue length: ", queueLength[i], "\n") -->
<!--    } -->
<!-- } -->
<!-- plot( queueLength, type = "l", las = 1) -->



<!-- ### Part 2 -->
<!-- queuelength <- array(dim = 60) -->

<!-- queueLength[1] <- rpois(1, lambda = 0.5) -->

<!-- for (i in 2:60){ -->
<!--    NumberIn <- rpois(1, lambda = 0.5) -->

<!--    # Number being served -->
<!--    if ( i < 30 ) { -->
<!--      NumberServed <- 0 -->
<!--    } else { -->
<!--      if (i >= 30) { -->
<!--         lambda <- 0.75 -->
<!--      } -->
<!--      NumberServed <- rpois(1, lambda = lambda) -->
<!--      queueLength[i] <- queueLength[i - 1] + NumberIn - NumberServed -->
<!--    } -->

<!--    if ( queueLength[i] < 0 ) queueLength[i] <- 0 -->
<!-- } -->

<!-- plot( queueLength, type = "l", las = 1) -->
<!-- abline(v = 30, -->
<!--        lwd = 2, -->
<!--        col = "grey") -->
<!-- text(30, 5,  -->
<!--      pos = 3, # To the right, -->
<!--      labels = "Server starts") -->




<!-- ### Part 3. -->
<!-- queuelength <- array(dim = 60) -->

<!-- queueLength[1] <- rpois(1, lambda = 0.5) -->

<!-- for (i in 2:60){ -->
<!--    NumberIn <- rpois(1, lambda = 0.5) -->

<!--    # Number being served -->
<!--    if ( i < 30 ) { -->
<!--      NumberServed <- 0 -->
<!--    } else { -->
<!--      if ( (i > 30) & (i < 45) ) { -->
<!--         lambda <- 0.7 -->
<!--      } -->
<!--      if ( i > 45 ) { -->
<!--         lambda <- 1.3 -->
<!--      } -->
<!--      NumberServed <- rpois(1, lambda = lambda) -->
<!--    } -->

<!--    queueLength[i] <- queueLength[i - 1] + NumberIn - NumberServed -->

<!--    if ( queueLength[i] < 0 ) queueLength[i] <- 0 -->
<!-- } -->

<!-- plot( queueLength, type = "l", las = 1) -->
<!-- abline(v = 30, -->
<!--        lwd = 2, -->
<!--        col = "grey") -->
<!-- text(30, 5,  -->
<!--      pos = 3, # To the right, -->
<!--      labels = "Server 1 starts") -->
<!-- abline(v = 45, -->
<!--        lwd = 2, -->
<!--        col = "grey") -->
<!-- text(45, 5,  -->
<!--      pos = 3, # To the right, -->
<!--      labels = "Server 2 starts") -->
<!-- ``` -->

<!-- ::: -->


:::{.answer}
**Answer to Exercise \@ref(exr:PoissonEqualValues).**
Suppose $X\sim\text{Pois}(\lambda)$; then $\Pr(X) = \Pr(X + 1)$ implies

\begin{align*}
   \frac{\exp(-\lambda)\lambda^x}{x!} 
   &= \frac{\exp(-\lambda)\lambda^{x + 1}}{(x + 1)!} \\
   \frac{\lambda^x}{x!} 
   &= \frac{\lambda^{x} \lambda}{(x + 1) \times x!}
\end{align*}
so that $\lambda = x + 1$ (i.e., $\lambda$ must be a while number).
For example, if $x = 4$ we would have $\lambda = 5$.
And we can check:

```{r}
dpois(x = 4,     lambda = 5)
dpois(x = 4 + 1, lambda = 5)
```
:::



:::{.answer}
**Answer to Exercise \@ref(exr:HypergeometricFPC).**

1. $\text{E}(X) = kp$ which is the same as the binomial (here, $k$ is the sample size).
1. $\text{var}(X) = k p (1 - p) \times \left(\frac{N - k}{N - 1}\right)$; the first bit is the variance for the binomial distribution (recall $k$ is the sample size).
   The other term is $(N - k)/(N - 1)$, which is the FPC factor as defined.
:::




:::{.answer}
**Answer to Exercise \@ref(exr:DiscreteUniformVar).**

Since $\text{var}(Y) = \text{E}(Y^2) - \text{E}(Y)^2$, find $\text{E}(Y^2)$ using \@ref(eq:SumSquaredNaturalNumbers):

\begin{align*}
  \text{E}(Y^2)
  &= \sum_{i = 0}^{b - a} i^2\frac{1}{b - a + 1}\\
  &= \frac{1}{b - a + 1}(0^2 + 1^2 + 2^2 + \dots  +(b - a)^2)\\
  &= \frac{1}{b - a + 1}\frac{(b - a)(b - a + 1)(2(b - a) + 1)}{6}\\
  &= \frac{(b - a)(2(b - a) + 1)}{6}.
\end{align*}
Therefore
\begin{align*}
   \text{var}(X)
    = \text{var}(Y)
   &= \frac{(b - a)(2(b - a) + 1)}{6} - \left(\frac{b - a}2\right)^2\\
   &= \frac{(b - a)(b - a + 2)}{12}.
\end{align*}
:::
 