# Mixed distributions {#MixedDistributions}

::: {.objectivesBox .objectives data-latex="{iconmonstr-target-4-240.png}"}
On completion of this module, you should be able to:

* recognise the probability functions and underlying parameters of mixed variables.
* know the basic properties of the above mixed distributions.
* apply these distributions as appropriate to problem solving.
:::



## Hurdle models	

A point mass at\ $0$, plus a truncated distribution (e.g., truncated gamma) for positive values.

* Not censoring
Concept: Two-stage model:

First, a Bernoulli model decides whether the value is zero or positive.

Then, a truncated distribution (e.g., Poisson or Gamma) is fitted to the positive values only.

* Two-part model: Bernoulli + truncated distn (e.g., gamma).
* Healthcare costs; heavy zero mass
* Helpful with structural zeroes
* Model:
$$
   \Pr(Y = 0) = (1 - \pi); \Pr(Y = y>0) = \pi f_Y(y)
$$
where $f_Y(y)$ is a zero-truncated density or PMF.


## Tobit model	

A censored normal: positive mass at a threshold (e.g.,\ $0$), plus continuous above it.

Concept: A censored regression model, used when there's an underlying latent continuous variable that’s only partially observed.


* Joint model
* Censored economic data; wages; Time use (Jude Brown)
* Model:
$$
  Y^* \sim N(X\beta, \sigma^2)
$$
but $Y = \max(0, Y^*)$ only is observed (i.e., censoring).
Or:
$$
  Y = 
  \begin{cases}
    0   & \text{if $Y^* \le 0$};\\
    Y^* & \text{if $Y*^ > 0$} 
  \end{cases}
$$


## Bernoulli–normal mixture	

With prob $p$, get $0$ (discrete), else sample from a normal (continuous).

* Two-part
* Spike, signal modelling
* Not censored (like Tobit); zeros are structural (not a result of censoring)

Concept: A two-part model, often written as:
$$
  Y = 
  \begin{cases}
    0                       & \text{with probability $\pi$};\\
    Z\sim N(\mu, \sigma^2)  & \text{with probability $(1 - \pi)$}.
  \end{cases}
$$


## Spiked distributions	

Like a delta function (point mass) combined with a density (e.g., 
p \delta_0 + (1-p)N(0,1)).

* Generic mixture
* Bayesian priors; sparse signals

Concept: Similar to Bernoulli-normal mixture, but more general:
$$
  f(x) = \pi\delta_0(x) + (1 - \pi) f_c(x)
$$
where $\delta_0(x)$ is a Dirac delta at 0, and $f_c(x)$ is a continuous density.


## Poisson sums of gamma distributions: Poisson-gamma distributions

* One part model
* Rainfall, insurance claims
* Single modelConstruction:

Let
$$
  N \sim \text{Poisson}(\lambda)
  \quad\text{and}\quad
  Y_i \sim \text{Gamma}(\alpha, \beta).
$$
Then, 
$$
  Y = \sum_{i = 1}^N Y_i,
$$
and so $\Pr(Y = 0) = \Pr(N = 0)$.


## Exercises
