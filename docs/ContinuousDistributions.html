<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>8 Standard continuous distributions | The Theory of Statistical Distributions</title>
<meta name="author" content="Peter K. Dunn">
<meta name="description" content="On completion of this chapter, you should be able to: recognise the probability functions and underlying parameters of uniform, exponential, gamma, beta, and normal random variables. know the...">
<meta name="generator" content="bookdown 0.45 with bs4_book()">
<meta property="og:title" content="8 Standard continuous distributions | The Theory of Statistical Distributions">
<meta property="og:type" content="book">
<meta property="og:description" content="On completion of this chapter, you should be able to: recognise the probability functions and underlying parameters of uniform, exponential, gamma, beta, and normal random variables. know the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="8 Standard continuous distributions | The Theory of Statistical Distributions">
<meta name="twitter:description" content="On completion of this chapter, you should be able to: recognise the probability functions and underlying parameters of uniform, exponential, gamma, beta, and normal random variables. know the...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><script src="libs/rglWebGL-binding-1.3.31/rglWebGL.js"></script><link href="libs/rglwidgetClass-1.3.31/rgl.css" rel="stylesheet">
<script src="libs/rglwidgetClass-1.3.31/rglClass.min.js"></script><script src="libs/CanvasMatrix4-1.3.31/CanvasMatrix.min.js"></script><link rel="shortcut icon" href="icons/iconmonstr-chart-1-240.png">
<script>
    document.addEventListener('DOMContentLoaded', function() {
      // Find all R code blocks that should be toggleable.
      // Our Lua filter adds the 'r-code-box' class to the code block.
      var codeBlocks = document.querySelectorAll('.r-code-box');

      codeBlocks.forEach(function(codeBlock) {
        // Create the button element
        var button = document.createElement('button');
        button.textContent = 'Show R Code'; // Initial text for the button
        button.className = 'code-toggle-button'; // Assign CSS class

        // Insert the button directly before the code block.
        // The codeBlock's parentNode is the div.figure-with-code container.
        // We insert the button as a sibling of the codeBlock within that container.
        codeBlock.parentNode.insertBefore(button, codeBlock);

        // Hide the code block initially by default.
        codeBlock.style.display = 'none';

        // Add a click event listener to the button
        button.addEventListener('click', function() {
          if (codeBlock.style.display === 'none') {
            codeBlock.style.display = 'block'; // Show the code block
            button.textContent = 'Hide R Code'; // Change button text
          } else {
            codeBlock.style.display = 'none'; // Hide the code block
            button.textContent = 'Show R Code'; // Change button text back
          }
        });
      });
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/columns.css">
<link rel="stylesheet" href="html/largerDie.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">The Theory of Statistical Distributions</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li class="book-part">Theoretical foundations</li>
<li><a class="" href="ChapterSetTheory.html"><span class="header-section-number">1</span> Essentials of set theory</a></li>
<li><a class="" href="ChapterProbability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="" href="DistributionRandomVariables.html"><span class="header-section-number">3</span> Random variables and their distributions</a></li>
<li><a class="" href="ChapBivariate.html"><span class="header-section-number">4</span> Bivariate distributions</a></li>
<li><a class="" href="ChapExpectation.html"><span class="header-section-number">5</span> Mathematical expectation</a></li>
<li><a class="" href="ChapterTransformations.html"><span class="header-section-number">6</span> Transformations of random variables</a></li>
<li class="book-part">Standard univariate probability distributions</li>
<li><a class="" href="DiscreteDistributions.html"><span class="header-section-number">7</span> Standard discrete distributions</a></li>
<li><a class="active" href="ContinuousDistributions.html"><span class="header-section-number">8</span> Standard continuous distributions</a></li>
<li><a class="" href="ChapterMixedDistributions.html"><span class="header-section-number">9</span> Mixed distributions</a></li>
<li class="book-part">Multivariate random variables and distributions*</li>
<li><a class="" href="ChapMultivariate.html"><span class="header-section-number">10</span> Multivariate distributions*</a></li>
<li><a class="" href="MultivariateExtensions.html"><span class="header-section-number">11</span> Expectations for multivariate distributions*</a></li>
<li class="book-part">Sampling distributions</li>
<li><a class="" href="SamplingDistributions.html"><span class="header-section-number">12</span> Describing samples</a></li>
<li><a class="" href="OrderStatisticsChapter.html"><span class="header-section-number">13</span> Order statistcs</a></li>
<li><a class="" href="BayesianIntro.html"><span class="header-section-number">14</span> Introduction to Bayesian statistics</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="SymbolsUsed.html"><span class="header-section-number">A</span> Symbols used</a></li>
<li><a class="" href="UsefulSeries.html"><span class="header-section-number">B</span> Some useful series</a></li>
<li><a class="" href="ShortRIntro.html"><span class="header-section-number">C</span> Short R introduction</a></li>
<li><a class="" href="UseRDistributions.html"><span class="header-section-number">D</span> Using R with distributions</a></li>
<li><a class="" href="selected-solutions.html"><span class="header-section-number">E</span> Selected solutions</a></li>
<li><a class="" href="references.html"><span class="header-section-number">F</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PeterKDunn/DistTheory">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ContinuousDistributions" class="section level1" number="8">
<h1>
<span class="header-section-number">8</span> Standard continuous distributions<a class="anchor" aria-label="anchor" href="#ContinuousDistributions"><i class="fas fa-link"></i></a>
</h1>
<div class="objectivesBox objectives">
<p>On completion of this chapter, you should be able to:</p>
<ul>
<li>recognise the probability functions and underlying parameters of uniform, exponential, gamma, beta, and normal random variables.</li>
<li>know the basic properties of the above continuous distributions.</li>
<li>apply these distributions as appropriate to problem solving.</li>
<li>approximate the binomial distribution by a normal distribution.</li>
</ul>
</div>
<div id="introduction-2" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-2"><i class="fas fa-link"></i></a>
</h2>
<p>In this chapter, some popular continuous distributions are discussed.
Properties such as definitions and applications are considered.</p>
</div>
<div id="ContinuousUniform" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Continuous uniform distribution<a class="anchor" aria-label="anchor" href="#ContinuousUniform"><i class="fas fa-link"></i></a>
</h2>
<p>
The continuous uniform distribution has a constant PDF over a given range.</p>
<div class="definition">
<p><span id="def:ContinuousUniformDistribution" class="definition"><strong>Definition 8.1  (Continuous uniform distribution) </strong></span>If a random variable <span class="math inline">\(X\)</span> with range space <span class="math inline">\([a, b]\)</span> has the PDF
<span class="math display" id="eq:ContinuousUniformPMF">\[\begin{equation}
   f_X(x; a, b) = \displaystyle\frac{1}{b - a}\quad\text{for $a\le x\le b$},
   \tag{8.1}
\end{equation}\]</span>
then <span class="math inline">\(X\)</span> has a <em>continuous uniform distribution</em>.
We write <span class="math inline">\(X\sim U(a, b)\)</span> or <span class="math inline">\(X\sim\text{Unif}(a, b)\)</span>.</p>
</div>
<p>This distribution is also called the <em>rectangular distribution</em>.
The same notation is used to denote the discrete and continuous uniform distribution; the context should make it clear which is meant.
A plot of the PDF for a continuous uniform distribution is shown in Fig. <a href="ContinuousDistributions.html#fig:ContinuousUniform">8.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ContinuousUniform"></span>
<img src="08-SpecificContinuous_files/figure-html/ContinuousUniform-1.png" alt="The PDF for a continuous uniform distribution $U(a,b)$." width="384"><p class="caption">
FIGURE 8.1: The PDF for a continuous uniform distribution <span class="math inline">\(U(a,b)\)</span>.
</p>
</div>
<div class="definition">
<p><span id="def:ContinuousuniformDF" class="definition"><strong>Definition 8.2  (Continuous uniform distribution: distribution function) </strong></span>For a random variable <span class="math inline">\(X\)</span> with the continuous uniform distribution given in Eq. <a href="ContinuousDistributions.html#eq:ContinuousUniformPMF">(8.1)</a>, the distribution function is
<span class="math display">\[
  F_X(x; a, b) =
  \begin{cases}
    0                                  &amp; \text{for $x &lt; a$};\\
    \displaystyle \frac{x - a}{b - a}  &amp; \text{for $a \le x \le b$};\\
    1                                  &amp; \text{for $x &gt; b$}.
  \end{cases}
\]</span></p>
</div>
<p>The following are the basic properties of the continuous uniform distribution.</p>
<div class="theorem">
<p><span id="thm:ContUniformProperties" class="theorem"><strong>Theorem 8.1  (Continuous uniform distribution properties) </strong></span>If <span class="math inline">\(X\sim\text{Unif}(a,b)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[X]  = (a + b)/2\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[X] = (b - a)^2/12\)</span>.</li>
<li>
<span class="math inline">\(M_X(t) = \{ \exp(bt) - \exp(at) \} / \{t(b - a)\}\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-41" class="proof"><em>Proof</em>. </span>These proofs are left as exercises.</p>
</div>
<div class="softwareBox software">
<p>The four <strong>R</strong> functions for working with the continuous uniform distribution have the form <code>[dpqr]unif(min, max)</code> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).</p>
</div>
<div class="example">
<p><span id="exm:ContinuousUniform" class="example"><strong>Example 8.1  (Continuous uniform) </strong></span>If <span class="math inline">\(X\)</span> is uniformly distributed on <span class="math inline">\([-2, 2]\)</span>, then <span class="math inline">\(\Pr(|X| &gt; \frac{1}{2})\)</span> can be found.
Note that
<span class="math display">\[
  f_X(x; a = -2, b = 2) = \frac{1}{4} \quad\text{for $-2 &lt; x &lt; 2$.}
\]</span>
Then:
<span class="math display">\[\begin{align*}
     \Pr\left(|X| &gt; \frac{1}{2}\right)
     &amp;= \Pr\left(X &gt; (1/2)\right) + \Pr\left(X &lt; -(1/2)\right)\\
     &amp;= \int^2_{1/2} f(x)\,dx  +  \int^{-1/2}_{-2} f(x)\,dx\\
     &amp;= 3/4.
\end{align*}\]</span>
The probability could also be computed by finding the area of the appropriate rectangle.
Alternatively, in <strong>R</strong>:</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">punif</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">punif</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="op">-</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.75</span></span></code></pre></div>
</div>
<p></p>
</div>
<div id="Normal" class="section level2" number="8.3">
<h2>
<span class="header-section-number">8.3</span> Normal distribution<a class="anchor" aria-label="anchor" href="#Normal"><i class="fas fa-link"></i></a>
</h2>
<div id="NormalUsual" class="section level3" number="8.3.1">
<h3>
<span class="header-section-number">8.3.1</span> Definition and properties<a class="anchor" aria-label="anchor" href="#NormalUsual"><i class="fas fa-link"></i></a>
</h3>
<p>
The most well-known continuous distribution is probably the <em>normal distribution</em> (or <em>Gaussian distribution</em>), sometimes called the <em>bell-shaped</em> distribution.
The normal distribution has many applications (especially in sampling; see Sect. <a href="SamplingDistributions.html#SamplingDistributions">12</a>), and many natural quantities (such as heights and weights of humans) follow normal distributions.</p>
<div class="definition">
<p><span id="def:NormalDistribution" class="definition"><strong>Definition 8.3  (Normal distribution) </strong></span>If a random variable <span class="math inline">\(X\)</span> has the PDF
<span class="math display" id="eq:NormalPMF">\[\begin{equation}
   f_X(x; \mu, \sigma^2) =
   \displaystyle \frac{1}{\sigma \sqrt{2\pi}}
                 \exp\left\{ -\frac{1}{2}\left( \frac{x-\mu}{\sigma}\right)^2 \right\}
   \tag{8.2}
\end{equation}\]</span>
for <span class="math inline">\(-\infty&lt;x&lt;\infty\)</span>, then <span class="math inline">\(X\)</span> has a <em>normal distribution</em>.
The two parameters are the mean <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(-\infty &lt; \mu &lt; \infty\)</span>; and the variance <span class="math inline">\(\sigma^2\)</span> such that <span class="math inline">\(\sigma^2 &gt; 0\)</span>.
We write <span class="math inline">\(X\sim N(\mu, \sigma^2)\)</span>.</p>
</div>
<p>Some authors—especially in non-theoretical work—use the notation <span class="math inline">\(X\sim N(\mu,\sigma)\)</span> so it is wise to check each article or book for the notation used.
Some examples of normal distribution PDFs are shown in Fig. <a href="ContinuousDistributions.html#fig:Normal">8.2</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Normal"></span>
<img src="08-SpecificContinuous_files/figure-html/Normal-1.png" alt="Some examples of normal distributions. The solid lines correspond to $\sigma = 0.5$ and the dashed lines to $\sigma = 1$. For the left panel, $\mu = -3$; for the right panel, $\mu = 2$." width="80%"><p class="caption">
FIGURE 8.2: Some examples of normal distributions. The solid lines correspond to <span class="math inline">\(\sigma = 0.5\)</span> and the dashed lines to <span class="math inline">\(\sigma = 1\)</span>. For the left panel, <span class="math inline">\(\mu = -3\)</span>; for the right panel, <span class="math inline">\(\mu = 2\)</span>.
</p>
</div>
<p>In drawing the graph of the normal PDF, note that</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(f_X(x)\)</span> is symmetrical about <span class="math inline">\(\mu\)</span>: <span class="math inline">\(f_X(\mu - x) = f_X(\mu + x)\)</span>.</li>
<li>
<span class="math inline">\(f_X(x) \to 0\)</span> asymptotically as <span class="math inline">\(x\to \pm \infty\)</span>.</li>
<li>
<span class="math inline">\(f_X'(x) = 0\)</span> when <span class="math inline">\(x = \mu\)</span>, and a maximum occurs there.</li>
<li>
<span class="math inline">\(f_X''(x) = 0\)</span> when <span class="math inline">\(x = \mu \pm \sigma\)</span> (points of inflection).</li>
</ol>
<p>The proof that <span class="math inline">\(\displaystyle \int^\infty_{-\infty} f_X(x)\,dx = 1\)</span> is not obvious so will not be given.
The proof relies on first squaring the integral and then changing to polar coordinates.</p>
<div class="definition">
<p><span id="def:NormalDF" class="definition"><strong>Definition 8.4  (Normal distribution: distribution function) </strong></span>For a random variable <span class="math inline">\(X\)</span> with the normal distribution given in Eq. <a href="ContinuousDistributions.html#eq:NormalPMF">(8.2)</a>, the distribution function is
<span class="math display">\[\begin{align}
  F_X(x; \mu, \sigma^2)
  &amp;= \frac{1}{\sigma \sqrt{2\pi}}
    \int_{-\infty}^x
    \exp\left\{\frac{(t - \mu)^2}{2\sigma^2}\right\}\, dt\\
  &amp;= \frac{1}{2}
    \left\{1 + \operatorname{erf} \left( \frac{x - \mu}{\sigma {\sqrt{2}} }\right)\right\}
\end{align}\]</span>
where <span class="math inline">\(\operatorname{erf}(\cdot)\)</span> is the <em>error function</em>
<span class="math display" id="eq:ErrorFunction">\[\begin{equation}
  \operatorname{erf}(x) =
  \frac{2}{\sqrt{\pi}} \int _{0}^{x} \exp\left( -t^{2}\right)\,dt,
  \tag{8.3}
\end{equation}\]</span>
for <span class="math inline">\(x \in\mathbb{R}\)</span>.
The function <span class="math inline">\(\operatorname{erf}(\cdot)\)</span> appears in numerous places, is commonly tabulated, and available in many computer packages.</p>
</div>
<p>The following are the basic properties of the normal distribution.</p>
<div class="theorem">
<p><span id="thm:NormalProperties" class="theorem"><strong>Theorem 8.2  (Normal distribution properties) </strong></span>If <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[X] = \mu\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[X] = \sigma^2\)</span>.</li>
<li>
<span class="math inline">\(M_X(t) = \displaystyle \exp\left(\mu t + \frac{t^2\sigma^2}{2}\right)\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-42" class="proof"><em>Proof</em>. </span>The proof is delayed until after Theorem <a href="ContinuousDistributions.html#thm:StandardNormalProperties">8.3</a>.</p>
</div>
<div class="softwareBox software">
<p>The four <strong>R</strong> functions for working with the normal distribution have the form <code>[dpqr]norm(mean, sd)</code> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).
Note that the normal distribution in <strong>R</strong> is specified by giving the <em>standard deviation</em> and <strong>not</strong> the <em>variance</em>.</p>
<p>The error function <span class="math inline">\(\operatorname{erf}(\cdot)\)</span> is not available directly in <strong>R</strong>, but can be evaluated using
<span class="math display">\[
  \operatorname{erf}(x) = 2\times \texttt{pnorm}(x\sqrt{2}) - 1.
\]</span></p>
</div>
</div>
<div id="StandardNormal" class="section level3" number="8.3.2">
<h3>
<span class="header-section-number">8.3.2</span> The standard normal distribution<a class="anchor" aria-label="anchor" href="#StandardNormal"><i class="fas fa-link"></i></a>
</h3>
<p>
A special case of the normal distribution is the <em>standard normal</em> distribution, when the normal distribution has mean zero and variance one.</p>
<div class="definition">
<p><span id="def:StandardNormal" class="definition"><strong>Definition 8.5  (Standardard normal distribution) </strong></span>The PDF for a random variable <span class="math inline">\(Z\)</span> with a <em>standard normal distribution</em>, sometimes denoted <span class="math inline">\(\phi(x)\)</span>, is
<span class="math display" id="eq:StandardNormalPMF">\[\begin{equation}
   f_Z(z) = \displaystyle \frac{1}{\sqrt{2\pi}}
                                \exp\left\{ -\frac{z^2}{2}\right\}
   \tag{8.4}
\end{equation}\]</span>
where <span class="math inline">\(-\infty &lt; z &lt; \infty\)</span>.
We write <span class="math inline">\(Z\sim N(0, 1)\)</span>.</p>
</div>
<p>Since <span class="math inline">\(f_Z(z)\)</span> is a PDF, then
<span class="math display" id="eq:ZDistribution">\[\begin{equation}
   \frac 1{\sqrt{2\pi}}\int^\infty_{-\infty} \exp\left\{-\frac{1}{2} z^2\right\}\,dz = 1,
   \tag{8.5}
\end{equation}\]</span>
a result which proves useful in many contexts (as in the proof of the second statement in Theorem <a href="DiscreteDistributions.html#thm:GammaFunctionProperties">7.7</a>, and in the proof below).</p>
<div class="definition">
<p><span id="def:StandardNormalDF" class="definition"><strong>Definition 8.6  (Standard normal distribution: distribution function) </strong></span>For a random variable <span class="math inline">\(X\)</span> with the standard normal distribution given in Eq. <a href="ContinuousDistributions.html#eq:StandardNormalPMF">(8.4)</a>, the distribution function is
<span class="math display" id="eq:PhiFunction">\[\begin{align}
  F_X(x)
  &amp;= \frac{1}{2}
     \left\{1 + \operatorname{erf} \left( \frac {x}{\sqrt{2}} \right)\right\}\nonumber\\
  &amp;= \int_{-\infty}^z \frac{1}{\sqrt{2\pi}} \exp\left\{ -\frac{t^2}{2}\right\}\, dt \\
  &amp;=  \Phi(z)
  \tag{8.6}
\end{align}\]</span>
where <span class="math inline">\(\operatorname{erf}(\cdot)\)</span> is the <em>error function</em> <a href="ContinuousDistributions.html#eq:ErrorFunction">(8.3)</a>.</p>
</div>
<div class="definition">
<p><span id="def:StdNormalPhiNotation" class="definition"><strong>Definition 8.7  (Notation) </strong></span>The density and distribution functions for the standard normal distribution are used so often that they have their own notation.
The density function is denoted <span class="math inline">\(\phi(\cdot)\)</span>, and the distribution function is denoted <span class="math inline">\(\Phi(\cdot)\)</span>.
Then, the density function a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> is <span class="math inline">\(\phi\big( (x - \mu)/\sigma\big)\)</span>, and the corresponding distribution function is <span class="math inline">\(\Phi\big( (x - \mu)/\sigma\big)\)</span>.</p>
<p><strong>Note:</strong> <span class="math inline">\(\displaystyle\frac{d}{dx} \Phi(x) = \phi(x)\)</span>.</p>
</div>
<p>The following are the basic properties of the standard normal distribution.</p>
<div class="theorem">
<p><span id="thm:StandardNormalProperties" class="theorem"><strong>Theorem 8.3  (Standard normal distribution properties) </strong></span>If <span class="math inline">\(Z\sim N(0, 1)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[Z] = 0\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[Z] = 1\)</span>.</li>
<li>
<span class="math inline">\(M_Z(t) = \displaystyle \exp\left(\frac{t^2}{2}\right)\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-43" class="proof"><em>Proof</em>. </span>Part 3 could be proven first, and used to prove Parts 1 and 2.
However, proving Parts 1 and 2 directly is constructive.
For the expected value:
<span class="math display">\[\begin{align*}
    \operatorname{E}[Z]
    &amp;= \frac {1}{\sqrt{2\pi}}
       \int^\infty_{-\infty} z \exp\left\{-\frac{1}{2}z^2 \right\}\,dz\\
    &amp;= \int^\infty_{-\infty} -\frac{d}{dz} \left(\exp\left\{-\frac{1}{2}z^2\right\} \right)\, dz\\
    &amp;= \left[ -\exp\left\{-\frac{1}{2}z^2\right\}\right]^\infty_{-\infty} = 0,
\end{align*}\]</span>
since the integrand is symmetric about <span class="math inline">\(0\)</span>.</p>
<p>For the variance, first see that <span class="math inline">\(\operatorname{var}[Z] = \operatorname{E}[Z^2] - \operatorname{E}[Z]^2 = \operatorname{E}[Z^2]\)</span> since <span class="math inline">\(\operatorname{E}[Z] = 0\)</span>.
So:
<span class="math display">\[
   \operatorname{var}[X] = \operatorname{E}[Z^2]
   = \frac {1}{\sqrt{2\pi}}\int^\infty_{-\infty}z^2e^{-\frac{1}{2}z^2}\,dz.
\]</span>
To integrate by parts (i.e., <span class="math inline">\(\int u\,dv = uv - \int v\, du\)</span>), set <span class="math inline">\(u = z\)</span> (so that <span class="math inline">\(du = 1\)</span>) and set
<span class="math display">\[
   dv = ze^{-\frac{1}{2}z^2}
   \quad\text{so that}\quad
   v = -e^{-\frac{1}{2}z^2}.
\]</span>
Hence,
<span class="math display">\[\begin{align*}
   \operatorname{var}[X]
   &amp;= \frac {1}{\sqrt{2\pi}} \left\{ -z \exp\left\{-\frac{1}{2}z^2\right\} - \int^\infty_{-\infty}-\exp\left\{-\frac{1}{2}z^2\right\}\, dz \right\}\\
   &amp;= \frac {1}{\sqrt{2\pi}}\left(\left. -z\,\exp\left\{-\frac{1}{2} z^2\right\}\right|^\infty_{-\infty}\right) + \frac{1}{\sqrt{2\pi}}\int^\infty_{-\infty} \exp\left\{-\frac{1}{2}z^2\right\}\,dz = 1
\end{align*}\]</span>
since the first term is zero, and the second term uses Eq. <a href="ContinuousDistributions.html#eq:ZDistribution">(8.5)</a>.</p>
<p>For the MGF:
<span class="math display">\[
   M_Z(t) = \operatorname{E}[\exp\left\{tZ\right\}]
   = \int^\infty_{-\infty} \exp\left\{tz\right\}
     \frac{1}{\sqrt{2\pi}} \exp\left\{-\frac{1}{2}z^2\right\}\,dz.
\]</span>
Collecting together the terms in the exponent and completing the square,
<span class="math display">\[\begin{equation*}
     -\frac{1}{2}[z^2 -2tz] = -\frac{1}{2}(z - t)^2+\frac{1}{2} t^2.
\end{equation*}\]</span>
Taking the constants outside the integral:
<span class="math display">\[
   M_Z(t)
   = \exp\left\{\frac{1}{2}t^2\right\}\int^\infty_{-\infty}
     \frac{1}{\sqrt{2\pi}} \exp\left\{-\frac{1}{2}[z - t]^2\right\}\,dz.
\]</span>
The integral here is <span class="math inline">\(1\)</span>, since it is the area under an <span class="math inline">\(N(t, 1)\)</span> PDF.
Hence
<span class="math display">\[
   M_Z(t) = \exp\left\{\frac{1}{2} t^2\right\}.
\]</span></p>
</div>
<p>This distribution is important in practice since <em>any</em> normal distribution can be rescaled into a standard normal distribution using
<span class="math display" id="eq:ConvertToZ">\[\begin{equation}
   Z = \frac{X - \mu}{\sigma}.
   \tag{8.7}
\end{equation}\]</span>
Since <span class="math inline">\(Z = (X - \mu)/\sigma\)</span>, then <span class="math inline">\(X = \mu + \sigma Z\)</span>, and so
<span class="math display">\[
   \operatorname{E}[X] = \operatorname{E}[\mu + \sigma Z] = \mu + \sigma \operatorname{E}[Z] = \mu
\]</span>
because <span class="math inline">\(\operatorname{E}[Z] = 0\)</span>.
Also
<span class="math display">\[
   \operatorname{var}[X] = \operatorname{var}[\mu  +\sigma Z] = \sigma^2\operatorname{var}[Z] = \sigma^2
\]</span>
because <span class="math inline">\(\operatorname{var}[Z] = 1\)</span>.
Finally
<span class="math display">\[
   M_X(t) = \operatorname{E}[e^{tX}] = \operatorname{E}\big[\exp\{t(\mu + \sigma Z)\}\big] = \exp(\mu t)\operatorname{E}\big[\exp(t\sigma Z)\big].
\]</span>
However, <span class="math inline">\(\operatorname{E}\big[\exp(t\sigma Z)\big] = M_Z(t\sigma) = \exp\left\{\frac{1}{2}(\sigma t)^2\right\}\)</span> so
<span class="math display">\[
   M_Z(t) = \displaystyle \exp\left(\frac{t^2}{2}\right).
\]</span></p>
<div class="softwareBox software">
<p>The four <strong>R</strong> functions for working with the normal distribution have the form <code>[dpqr]norm(mean, sd)</code> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).
By default, <code>mean = 0</code> and <code>sd = 1</code>, corresponding to the standard normal distribution.
Note that the normal distribution is specified by giving the <em>standard deviation</em> and <strong>not</strong> the <em>variance</em>.</p>
</div>
<p></p>
</div>
<div id="FindNormalProbs" class="section level3" number="8.3.3">
<h3>
<span class="header-section-number">8.3.3</span> Determining normal probabilities<a class="anchor" aria-label="anchor" href="#FindNormalProbs"><i class="fas fa-link"></i></a>
</h3>
<p>
The probability <span class="math inline">\(\Pr(a &lt; X \le b)\)</span> where <span class="math inline">\(X\sim N(\mu, \sigma^2)\)</span> can be written
<span class="math display">\[
   \Pr(a &lt; X \le b) = F_X(b) - F_X(a).
\]</span>
where <span class="math inline">\(F_X(x)\)</span> is the distribution function in Def. <a href="ContinuousDistributions.html#def:StandardNormalDF">8.6</a>.
The integral in the distribution function cannot be written in terms of standard functions and in general must be evaluated for a particular <span class="math inline">\(x\)</span> numerically (e.g., using Simpson’s rule or similar).
However, all statistical packages have built-in procedures to evaluate <span class="math inline">\(F_X(x)\)</span> for any <span class="math inline">\(z\)</span> (such as <code><a href="https://rdrr.io/r/stats/Normal.html">pnorm()</a></code> in <strong>R</strong>).</p>
<p>Also, since any normal distribution can be transformed into a standard normal distribution, we can write
<span class="math display">\[
   z_1 = (a - \mu)/\sigma
   \quad\text{and}\quad
   z_2 = (b - \mu)/\sigma
\]</span>
and hence the probability is
<span class="math display">\[
   \Pr( z_1 &lt; Z \le z_2) = \Phi(z_2) - \Phi(z_1),
\]</span>
where <span class="math inline">\(\Phi(z)\)</span> is the distribution function for the standard normal distribution, as in Eq. <a href="ContinuousDistributions.html#eq:ErrorFunction">(8.3)</a>.</p>
<p>The process of converting a value <span class="math inline">\(x\)</span> into <span class="math inline">\(z\)</span> using <span class="math inline">\(z = (x - \mu)/\sigma\)</span> is called <em>standardising</em>.
Tables of <span class="math inline">\(\Phi(z)\)</span> (or sometimes <span class="math inline">\(1 - \Phi(z)\)</span>) are commonly available.
These tables can be used to compute any probabilities associated with the normal distributions (see the examples below).
Of course, <strong>R</strong> can be used too.</p>
<p>In addition, the tables are often used in the reverse sense, where the probability of an event is given and the value of the random variable is sought.
In these case, the tables are used ‘backwards’; the appropriate area is found in the body of the table and the corresponding <span class="math inline">\(z\)</span>-value found in the table margins.
In <strong>R</strong>, the function <code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code> is used.
This <span class="math inline">\(z\)</span>-value is then converted to a value of the original random variable using
<span class="math display" id="eq:Unstandardising">\[\begin{equation}
   x = \mu + z\sigma.
   \tag{8.8}
\end{equation}\]</span>
This process is sometimes referred to as <em>unstandardising</em>.</p>
<p>The following examples illustrate the use of <strong>R</strong>.
Drawing rough graphs showing the relevant areas is encouraged.</p>
<div class="example">
<p><span id="exm:NormalWalkingSpeeds" class="example"><strong>Example 8.2  (Walking speeds) </strong></span>A study of stadium evacuations used a simulation to compare scenarios <span class="citation">(<a href="references.html#ref-xie2017improved">H. Xie, Weerasekara, and Issa 2017</a>)</span>.
The walking speed of people was modelled using a <span class="math inline">\(N(1.15, 0.2^2)\)</span> distribution; that is, <span class="math inline">\(\mu = 1.15\)</span> m/s with a standard deviation of <span class="math inline">\(0.2\)</span> m/s.
The situation can be shown in Fig. <a href="ContinuousDistributions.html#fig:NormalWalkingSpeed">8.3</a>, top left panel.</p>
<p>Many questions can be asked about the walking speeds, and <strong>R</strong> used to compute answers.
Using this model:</p>
<ol style="list-style-type: decimal">
<li>What is the probability that a person walks faster than <span class="math inline">\(1.5\)</span> m/s?</li>
<li>What is the probability that a person walks slower than <span class="math inline">\(1.0\)</span> m/s?</li>
<li>What is the probability that a person walks between <span class="math inline">\(1.0\)</span> m/s and <span class="math inline">\(1.5\)</span> m/s?</li>
<li>At what speed do the slowest <span class="math inline">\(15\)</span>% of people walk?</li>
<li>At what speed do the quickest <span class="math inline">\(5\)</span>% of people walk?</li>
</ol>
<p>Sketches of each of these situations are shown in Fig. <a href="ContinuousDistributions.html#fig:NormalWalkingSpeed">8.3</a>.
Using <strong>R</strong>:</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Part 1</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1.5</span>, mean <span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.04005916</span></span>
<span></span>
<span><span class="co"># Part 2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1</span>, mean <span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.2266274</span></span>
<span></span>
<span><span class="co"># Part 3</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1.5</span>, mean <span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">-</span> </span>
<span>   <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">1</span>, mean <span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.7333135</span></span>
<span></span>
<span><span class="co"># Part 4</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.15</span>, mean<span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.9427133</span></span>
<span></span>
<span><span class="co"># Part 5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.95</span>, mean <span class="op">=</span> <span class="fl">1.15</span>, sd <span class="op">=</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 1.478971</span></span></code></pre></div>
<p>So the answers are, respectively:</p>
<ol style="list-style-type: decimal">
<li>4%;</li>
<li>22.7%;</li>
<li>73.3%;</li>
<li>0.894 m/s;</li>
<li>1.479m/s.</li>
</ol>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:NormalWalkingSpeed"></span>
<img src="08-SpecificContinuous_files/figure-html/NormalWalkingSpeed-1.png" alt="The normal distribution used for modelling walking speeds. The vertical dotted lines are at the mean and $\pm1$, $\pm2$, $\pm3$ and $\pm4$ standard deviations from the mean." width="100%"><p class="caption">
FIGURE 8.3: The normal distribution used for modelling walking speeds. The vertical dotted lines are at the mean and <span class="math inline">\(\pm1\)</span>, <span class="math inline">\(\pm2\)</span>, <span class="math inline">\(\pm3\)</span> and <span class="math inline">\(\pm4\)</span> standard deviations from the mean.
</p>
</div>
<div class="example">
<p><span id="exm:Exam" class="example"><strong>Example 8.3  (Using normal distributions) </strong></span>Scores on an examination have a normal distribution, with a mean score of <span class="math inline">\(50\)</span> and standard deviation of <span class="math inline">\(10\)</span>.
Suppose the top <span class="math inline">\(75\)</span>% of candidates taking this examination are to be passed; call the minimum passing score <span class="math inline">\(x^*\)</span>.</p>
<p>Since <span class="math inline">\(X\sim N(50, 10^2)\)</span>:
<span class="math display">\[\begin{align*}
   \Pr(X &gt; x^*)
   &amp;= 0.75\\
   \Pr\left(Z &gt; \frac{x^* - 50}{10}\right)
   &amp;= 0.75\\
   \Pr\left(Z &lt; \frac{50 - x^*}{10}\right)
   &amp; = 0.75.
\end{align*}\]</span>
From tables, <span class="math inline">\(0.75 = \Phi(0.675)\)</span> so <span class="math inline">\((50 - x^*)/10 = 0.675\)</span> and <span class="math inline">\(x^* = 43.25\)</span>.
Using <strong>R</strong>:</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="co"># 'Top 75%' is the same as the 'bottom 25%' </span></span>
<span>      mean <span class="op">=</span> <span class="fl">50</span>,</span>
<span>      sd <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 43.2551</span></span></code></pre></div>
</div>
</div>
<div id="NormalApproxBinomial" class="section level3" number="8.3.4">
<h3>
<span class="header-section-number">8.3.4</span> Normal approximation to the binomial<a class="anchor" aria-label="anchor" href="#NormalApproxBinomial"><i class="fas fa-link"></i></a>
</h3>
<p>In Sect. <a href="DiscreteDistributions.html#BinomialDistribution">7.4</a>, the binomial distribution was considered.
Sometimes using the binomial distribution is tedious; consider a binomial random variable <span class="math inline">\(X\)</span> where <span class="math inline">\(n = 1000\)</span>, <span class="math inline">\(p = 0.45\)</span> and <span class="math inline">\(\Pr(X &gt; 650)\)</span> is sought: we would calculate <span class="math inline">\(\Pr(X = 651) + \Pr(X = 652) + \cdots + \Pr(X = 1000)\)</span>.</p>
<p>However, sometimes the normal distribution can be used to <em>approximate</em> binomial probabilities.
For certain parameter values, the binomial pf starts to take on a normal distribution shape (Fig. <a href="ContinuousDistributions.html#fig:NormalApprox">8.4</a>).</p>
<p>When is the binomial probability function close enough to use the normal approximation?
There is no definitive answer; a common guideline suggests that if <em>both</em> <span class="math inline">\(np \ge 5\)</span> <em>and</em> <span class="math inline">\(n(1 - p) \ge 5\)</span> the approximation is satisfactory.
(These are only guidelines, and other texts may suggest different guidelines.)</p>
<p>Figure <a href="ContinuousDistributions.html#fig:NormalApprox">8.4</a> shows some picture of various binomial probability functions overlaid with the corresponding normal distribution; the approximation is visibly better as the guidelines given above are satisfied.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:NormalApprox"></span>
<img src="08-SpecificContinuous_files/figure-html/NormalApprox-1.png" alt="The normal distribution approximating a binomial distribution. The guidelines suggest the approximation should be good when $np \ge 5$ and $n (1 - p) \ge 5$; this is evident from the pictures. In the top row, a significant amount of the approximating normal distribution even appears when $Y &lt; 0$." width="85%"><p class="caption">
FIGURE 8.4: The normal distribution approximating a binomial distribution. The guidelines suggest the approximation should be good when <span class="math inline">\(np \ge 5\)</span> and <span class="math inline">\(n (1 - p) \ge 5\)</span>; this is evident from the pictures. In the top row, a significant amount of the approximating normal distribution even appears when <span class="math inline">\(Y &lt; 0\)</span>.
</p>
</div>
<p>The normal distribution can be used to <em>approximate</em> probabilities in situations that are actually binomial.
A fundamental difficulty with this approach is that a <em>discrete</em> distribution is being modelled with a <em>continuous</em> distribution.
This is best explained through an example.
The example explains the <em>principle</em>; the idea extends to all situations where the normal distribution is used to approximate a binomial distribution.</p>
<div class="linkBox link">
<p>If the random variable <span class="math inline">\(X\)</span> has the binomial distribution <span class="math inline">\(X \sim \text{Bin}(n, p)\)</span>, the probability function can be approximated by the normal distribution <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>, where <span class="math inline">\(\mu = np\)</span> and <span class="math inline">\(\sigma^2 = np(1 - p)\)</span>.</p>
<p>The approximation is good if <em>both</em> <span class="math inline">\(np \ge 5\)</span> <em>and</em> <span class="math inline">\(n(1 - p) \ge 5\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:NormalApproxMice" class="example"><strong>Example 8.4  (Normal approximation to binomial) </strong></span>Consider <em>mdx</em> mice (which have a strain of muscular dystrophy) from a particular source for which <span class="math inline">\(30\)</span>% of the mice survive for at least <span class="math inline">\(40\)</span> weeks.
One particular experiment requires at least <span class="math inline">\(35\)</span> of the <span class="math inline">\(100\)</span> mice to live beyond <span class="math inline">\(40\)</span> weeks.
What is the probability that <strong><span class="math inline">\(35\)</span> or more</strong> of the group will survive beyond <span class="math inline">\(40\)</span> weeks?</p>
<p>First see that the situation is binomial; if <span class="math inline">\(X\)</span> is the number of mice from the group of <span class="math inline">\(100\)</span> that survive, then <span class="math inline">\(X \sim \text{Bin}(100, 0.3)\)</span>.
This could be <em>approximated</em> by the normal distribution <span class="math inline">\(Y\sim N(30, 21)\)</span>, where the variance is <span class="math inline">\(np(1 - p) = 100\times 0.3\times 0.7 = 21\)</span>.
Both <span class="math inline">\(np = 30\)</span> and <span class="math inline">\(n(1 - p) = 70\)</span> are much larger than <span class="math inline">\(5\)</span>, so this approximation is expected to adequate.</p>
<p>Figure <a href="ContinuousDistributions.html#fig:ContCorrBoxes">8.5</a> shows the upper tail of the distribution near <span class="math inline">\(X = 35\)</span>:
using the normal approximation from <span class="math inline">\(Y = 35\)</span>, only <em>half</em> of the original bar in the binomial pf is included.
However, since the number of mice is discrete, we want the <em>entire</em> bar corresponding to <span class="math inline">\(X = 35\)</span>.
So to compute the correct answer, the normal distribution must be evaluated for <span class="math inline">\(\Pr(Y &gt; 34.5)\)</span>.
This change from <span class="math inline">\(Y \ge 34.5\)</span> to <span class="math inline">\(Y &gt; 34.5\)</span> is called using the <em>continuity correction</em>.</p>
<p>The exact answer (using the binomial distribution) is <span class="math inline">\(0.1629\)</span> (rounded to four decimal places).
Using the normal distribution <em>with</em> the continuity correction gives the answer as <span class="math inline">\(0.1631\)</span>; using the normal distribution <em>without</em> the continuity correction, the answer is <span class="math inline">\(0.1376\)</span>.
The solution is more accurate, as expected, using the continuity correction.</p>
</div>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Exact</span></span>
<span><span class="va">ExactP</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">35</span><span class="op">:</span><span class="fl">100</span>,</span>
<span>                      size <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      prob <span class="op">=</span> <span class="fl">0.30</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ExactP2</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="fl">34</span>, </span>
<span>                      size <span class="op">=</span> <span class="fl">100</span>,</span>
<span>                      prob <span class="op">=</span> <span class="fl">0.30</span><span class="op">)</span></span>
<span><span class="co"># Normal approx</span></span>
<span><span class="va">NormalP</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">35</span>, </span>
<span>                     mean <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                     sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">21</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Normal approx with continuity correction</span></span>
<span><span class="va">ContCorrP</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">34.5</span>, </span>
<span>                       mean <span class="op">=</span> <span class="fl">30</span>,</span>
<span>                       sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">21</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Exact:"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">ExactP</span>, <span class="fl">6</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span> <span class="co"># \n means "new line" </span></span>
<span><span class="co">#&gt; 0.162858</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Exact (alt):"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">ExactP2</span>, <span class="fl">6</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.162858</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Normal approx:"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">NormalP</span>, <span class="fl">6</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.137617</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"With correction:"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">ContCorrP</span>, <span class="fl">6</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.163055</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ContCorrBoxes"></span>
<img src="08-SpecificContinuous_files/figure-html/ContCorrBoxes-1.png" alt="The normal distribution approximating the binomial distribution when $n = 100$, $p = 0.3$ and finding the probability that $X &gt; 35$." width="70%"><p class="caption">
FIGURE 8.5: The normal distribution approximating the binomial distribution when <span class="math inline">\(n = 100\)</span>, <span class="math inline">\(p = 0.3\)</span> and finding the probability that <span class="math inline">\(X &gt; 35\)</span>.
</p>
</div>
<div class="example">
<p><span id="exm:ContCorrectionDice" class="example"><strong>Example 8.5  (Continuity correction) </strong></span>Consider rolling a standard die <span class="math inline">\(100\)</span> times, and counting the number of times a <img src="Dice/die1.png" width="10"> appear uppermost.
The random variable <span class="math inline">\(X\)</span> is the number of times a <img src="Dice/die1.png" width="10"> appears; then, <span class="math inline">\(X\sim \text{Bin}(n = 100, p = 1/6)\)</span>.</p>
<p>Since <span class="math inline">\(np = 16.667\)</span> and <span class="math inline">\(n(1 - p) = 83.333\)</span> are both greater than <span class="math inline">\(5\)</span>, a normal approximation should be accurate, so define <span class="math inline">\(Y\sim N(16.6667, 13.889)\)</span> (where the variance is <span class="math inline">\(np(1 - p) = 13.889\)</span>).
Various probabilities (Table <a href="ContinuousDistributions.html#tab:ContCorrectionTable">8.1</a>) show the accuracy of the approximation, and the way in which the continuity correction has been used.</p>
<p>You should understand how the concept of the continuity correction has been applied in each situation, and be able to compute the probabilities for the normal approximation.</p>
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:ContCorrectionTable">TABLE 8.1: </span>Some events and their probabilities for the die-rolling example, computed using the binomial distribution (exact) and the normal approximation using the continuity correction. The accuracy of the approximation is generally very good.
</caption>
<thead><tr>
<th style="text-align:right;font-weight: bold;">
Event (binomial)
</th>
<th style="text-align:right;font-weight: bold;">
Prob (binomial)
</th>
<th style="text-align:right;font-weight: bold;">
</th>
<th style="text-align:right;font-weight: bold;">
Event (normal)
</th>
<th style="text-align:right;font-weight: bold;">
Prob (normal)
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
<span class="math inline">\(\Pr(X \lt 10)\)</span>
</td>
<td style="text-align:right;">
0.0213
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
<span class="math inline">\(\Pr(Y \lt 9.5)\)</span>
</td>
<td style="text-align:right;">
0.0368
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(\Pr(X \le 15)\)</span>
</td>
<td style="text-align:right;">
0.3877
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
<span class="math inline">\(\Pr(Y \lt 15.5)\)</span>
</td>
<td style="text-align:right;">
0.3771
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(\Pr(X \gt 17)\)</span>
</td>
<td style="text-align:right;">
0.4006
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
<span class="math inline">\(\Pr(Y \gt 17.5)\)</span>
</td>
<td style="text-align:right;">
0.4115
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(\Pr(X \ge 21)\)</span>
</td>
<td style="text-align:right;">
0.1519
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
<span class="math inline">\(\Pr(Y \gt 20.5)\)</span>
</td>
<td style="text-align:right;">
0.1518
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(\Pr(15 \lt X \le 17)\)</span>
</td>
<td style="text-align:right;">
0.2117
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
<span class="math inline">\(\Pr(15.5 \lt Y \lt 17.5)\)</span>
</td>
<td style="text-align:right;">
0.2113
</td>
</tr>
</tbody>
</table></div>
<p></p>
</div>
</div>
<div id="ExponentialDistribution" class="section level2" number="8.4">
<h2>
<span class="header-section-number">8.4</span> Exponential distribution<a class="anchor" aria-label="anchor" href="#ExponentialDistribution"><i class="fas fa-link"></i></a>
</h2>
<p>
The normal distribution is defined for all real values, but many quantities are defined on the positive real numbers only.
This is not always a problem, especially when the observations are far from zero, such as heights of adult humans.
However, many random variables have observations close to zero, and the data are often skewed to the right (positively skewed).</p>
<p>Many distributions can be used for modelling right-skewed data defined on the positive real numbers; the simplest is the exponential distribution.</p>
<div id="ExponentialDerivation" class="section level3" number="8.4.1">
<h3>
<span class="header-section-number">8.4.1</span> Derivation<a class="anchor" aria-label="anchor" href="#ExponentialDerivation"><i class="fas fa-link"></i></a>
</h3>
<p>The exponential distribution is closely related to the Poisson distribution.
To show this, consider a <a href="DiscreteDistributions.html#PoissonDerivation">Poisson process</a>, where events occur at an average rate of <span class="math inline">\(\lambda\)</span> events per unit time (e.g., <span class="math inline">\(\lambda = 0.5\)</span> per minute).</p>
<p>Then consider a fixed length of time <span class="math inline">\(t &gt; 0\)</span>; then, the number of occurrences <span class="math inline">\(Y\)</span> would have an average rate of <span class="math inline">\(\lambda t\)</span> (e.g., in 12 minutes, we’d expect an average rate of <span class="math inline">\(0.5\times 12 = 6\)</span> occurrences).
That is, the number of events occurring in the interval <span class="math inline">\((0, t)\)</span> has Poisson distribution with mean <span class="math inline">\(\lambda t\)</span>, with probability function
<span class="math display" id="eq:PoissonPMF2">\[\begin{equation}
  p_Y(y) = \frac{\exp(-\lambda t) (\lambda t)^y}{y!}
  \quad
  \text{for $y = 0, 1, 2, \dots$}.
   \tag{8.9}
\end{equation}\]</span>
Hence, the probability that zero events occur in the interval <span class="math inline">\((0, t)\)</span> is
<span class="math display">\[
  \Pr(Y = 0)
  = \frac{\exp(-\lambda t) (\lambda t)^0}{0!}
  = \exp(-\lambda t)
\]</span>
using <span class="math inline">\(Y = 0\)</span> in <a href="ContinuousDistributions.html#eq:PoissonPMF2">(8.9)</a>.</p>
<p>Now, introduce a new random variable <span class="math inline">\(T\)</span> that represent the <em>time until the first event occurs</em>.
Then, <span class="math inline">\(Y = 0\)</span> (i.e., no events occur in the interval <span class="math inline">\((0, t)\)</span>) corresponds to <span class="math inline">\(T &gt; t\)</span> (i.e., the time till the first event occurs must be great than the time interval <span class="math inline">\(t\)</span>).
That is,
<span class="math display">\[
  \Pr(Y = 0) = \exp(-\lambda t) = \Pr(T  &gt; t).
\]</span>
Rewriting in terms of a distribution function for <span class="math inline">\(T\)</span>,
<span class="math display">\[
  F_T(t) = 1 - \Pr(T &gt; t) = 1 - \exp(-\lambda t)
\]</span>
for <span class="math inline">\(t &gt; 0\)</span>.
Hence, the probability density function is
<span class="math display">\[
  f_T(t) = \lambda \exp(-\lambda t)
\]</span>
for <span class="math inline">\(t &gt; 0\)</span>.
This is the probability density function for the exponential distribution.</p>
<p>This shows that if events occur at random according to a Poisson distribution, then the time (or the space) <em>between</em> those events follows an exponential distribution (Theorem <a href="ContinuousDistributions.html#thm:PoissonProcess">8.4</a>).
Hence the exponential distribution is used to describe the interval between consecutive randomly occurring events that follow a Poisson distribution.</p>
<div class="theorem">
<p><span id="thm:PoissonProcess" class="theorem"><strong>Theorem 8.4  (Poisson process and exponential distributions) </strong></span>Consider a Poisson process at rate <span class="math inline">\(\lambda\)</span> and suppose observation starts at an arbitrary time point.
Then the time <span class="math inline">\(T\)</span> to the first event has an exponential distribution with mean <span class="math inline">\(\operatorname{E}[T] = 1/\lambda\)</span>; i.e.,
<span class="math display">\[
   f_T(t) = \lambda e^{-\lambda t},\quad t &gt; 0.
\]</span></p>
</div>
<p>Although the theorem refers to ‘time’, the variable of interest may be distance or any other continuous variable measuring the interval between events.</p>
<div class="linkBox link">
<p>If events occur according to a Poisson distribution, then the “time” <em>between</em> the Poisson events can be modelled using an exponential distribution.</p>
</div>
</div>
<div id="ExponentialDefinition" class="section level3" number="8.4.2">
<h3>
<span class="header-section-number">8.4.2</span> Definition and properties<a class="anchor" aria-label="anchor" href="#ExponentialDefinition"><i class="fas fa-link"></i></a>
</h3>
<p>The exponential distribution is usually written as follows.</p>
<div class="definition">
<p><span id="def:ExponentialDistribution" class="definition"><strong>Definition 8.8  (Exponential distribution) </strong></span>If a random variable <span class="math inline">\(X\)</span> has the PDF
<span class="math display" id="eq:ExponentialPMF">\[\begin{equation}
   f_X(x; \beta) = \displaystyle \frac{1}{\beta}  \exp(-x/\beta)
   \quad
   \text{for $x &gt; 0$}
   \tag{8.10}
\end{equation}\]</span>
then <span class="math inline">\(X\)</span> has an <em>exponential distribution</em> with parameter <span class="math inline">\(\beta &gt; 0\)</span>.
We write <span class="math inline">\(X\sim\text{Exp}(\beta)\)</span>.</p>
</div>
<p>The parameter <span class="math inline">\(\lambda = 1/\beta\)</span> is often used in place of <span class="math inline">\(\beta\)</span>, and is called the <em>rate</em> parameter.
Sometimes the notation <span class="math inline">\(X\sim\text{Exp}(\lambda)\)</span>, so checking which notation is being used in any context is wise.
Plots of the PDF for various exponential distributions are given in Fig. <a href="ContinuousDistributions.html#fig:ExponentialDistributions">8.6</a>}.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ExponentialDistributions"></span>
<img src="08-SpecificContinuous_files/figure-html/ExponentialDistributions-1.png" alt="Exponential distributions for various values of the rate parameter $\lambda = 1/\beta$." width="384"><p class="caption">
FIGURE 8.6: Exponential distributions for various values of the rate parameter <span class="math inline">\(\lambda = 1/\beta\)</span>.
</p>
</div>
<div class="definition">
<p><span id="def:ExponentialDF" class="definition"><strong>Definition 8.9  (Exponential distribution: distribution function) </strong></span>For a random variable <span class="math inline">\(X\)</span> with the exponential distribution given in Eq. <a href="ContinuousDistributions.html#eq:ExponentialPMF">(8.10)</a>, the distribution function is
<span class="math display">\[
  F_X(x; \lambda)
  = 1 - \exp\left\{-x/\beta\right\}
  = 1 - \exp\left\{-\lambda x\right\}
\]</span>
for <span class="math inline">\(x &gt; 0\)</span>.</p>
</div>
<p>The following are the basic properties of the exponential distribution.</p>
<div class="theorem">
<p><span id="thm:ExponentialProperties" class="theorem"><strong>Theorem 8.5  (Exponential distribution properties) </strong></span>If <span class="math inline">\(X\sim\text{Exp}(\beta)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[X] = \beta = 1/\lambda\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[X] = \beta^2 = 1/\lambda^2\)</span>.</li>
<li>
<span class="math inline">\(M_X(t) = (1 - \beta t)^{-1}\)</span> for <span class="math inline">\(t &lt; 1/\beta\)</span> (or, <span class="math inline">\(M_X(t) = \lambda/(\lambda - t)\)</span> for <span class="math inline">\(t &lt; \lambda\)</span>).</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-44" class="proof"><em>Proof</em>. </span>The proofs are left as an exercise.</p>
</div>
<p>The parameter <span class="math inline">\(\beta\)</span> represents the <em>mean</em> of the exponential distribution.
The alternative parameter <span class="math inline">\(\lambda = 1/\beta\)</span> represents the mean <em>rate</em> at which events occur.
Like the <a href="DiscreteDistributions.html#PoissonDistribution">Poisson distribution</a>, the variance is defined once the mean is defined .</p>
<div class="softwareBox software">
<p>The four <strong>R</strong> functions for working with the exponential distribution have the form <code>[dpqr]exp(rate)</code> where <code>rate</code><span class="math inline">\({}= \lambda = 1/\beta\)</span> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).</p>
</div>
<div class="example">
<p><span id="exm:ExpRainFall" class="example"><strong>Example 8.6  (Exponential distributions) </strong></span><span class="citation">Allen et al. (<a href="references.html#ref-allen1975stochastic">1975</a>)</span> use the exponential distribution to model daily rainfall in Kentucky.</p>
</div>
<div class="example">
<p><span id="exm:ExprainFall2" class="example"><strong>Example 8.7  (Exponential distributions) </strong></span><span class="citation">Cox and Lewis (<a href="references.html#ref-cox1966statistical">1966</a>)</span> give data collected by Fatt and Katz concerning the time intervals between successive nerve pulses along a nerve fibre.
There are <span class="math inline">\(799\)</span> observations which we do not give here.
The mean time between pulses is <span class="math inline">\(\beta = 0.2186\)</span> seconds.
An exponential distribution might be expected to model the data well.
This is indeed the case (Fig. <a href="ContinuousDistributions.html#fig:ExpNerves">8.7</a>).</p>
<p>Define <span class="math inline">\(X\)</span> as the time between successive nerve pulses (in seconds); then <span class="math inline">\(X\sim \text{Exp}(\beta = 0.2186)\)</span> (so the <em>rate parameter</em> is <span class="math inline">\(\lambda = 1/0.2186 = 4.575\)</span> per second).
To find the proportion of time intervals longer than <span class="math inline">\(1\)</span> second:
<span class="math display">\[\begin{align*}
   \Pr(X &gt; 1)
   &amp;=  \int_1^\infty \frac{1}{0.2186}\exp(-x/0.2186)\, dx \\
   &amp;= -\exp(-x/0.2186)\Big|_1^\infty \\
   &amp;= (-0) + (\exp\{-1/0.2186\})\\
   &amp;=  0.01031.
\end{align*}\]</span>
There is about a <span class="math inline">\(1\)</span>% chance of a nerve pulse exceeding one second.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ExpNerves"></span>
<img src="08-SpecificContinuous_files/figure-html/ExpNerves-1.png" alt="The time between successive nerve pulses. An exponential distribution fits well." width="384"><p class="caption">
FIGURE 8.7: The time between successive nerve pulses. An exponential distribution fits well.
</p>
</div>
<p>The relationship between the Poisson and exponential distribution was explored in Sect. <a href="ContinuousDistributions.html#ExponentialDerivation">8.4.1</a> (see, for example, Theorem <a href="ContinuousDistributions.html#thm:PoissonProcess">8.4</a>).
The next example explores this relationship</p>
<div class="example">
<p><span id="exm:ExpPoisson" class="example"><strong>Example 8.8  (Relationship between exponential and Poisson distributions) </strong></span>Suppose a Poisson process occurs at the mean <em>rate</em> of <span class="math inline">\(5\)</span> events per hour.
Let <span class="math inline">\(N\)</span> represent the number of events in one day and <span class="math inline">\(T\)</span> the time between consecutive events.
We can describe the distribution of the time between consecutive events and the distribution of the number of events in one day (<span class="math inline">\(24\,\text{h}\)</span>).</p>
<p>Since events occur at the mean rate of <span class="math inline">\(\lambda = 5\)</span> events per hour, the mean time between consecutive events is <span class="math inline">\(\beta = 1/\lambda = 0.2\,\text{h}\)</span>.
Hence, the mean number of events in one day is <span class="math inline">\(\mu = 24\times 5 = 120\)</span>.</p>
<p>Consequently, <span class="math inline">\(N\sim\text{Pois}(\mu = 120)\)</span> and <span class="math inline">\(X\sim\text{Exp}(\beta = 0.2)\)</span> (or, equivalently, <span class="math inline">\(X\sim\text{Exp}(\lambda = 5)\)</span>).</p>
</div>
<p>An important feature of a Poisson process, and hence of the exponential distribution, is the <em>memoryless</em> or <em>Markov property</em>: the future of the process at any time point does not depend on the history of the process.
This property is captured in the following theorem.</p>
<div class="theorem">
<p><span id="thm:MemorylessProperty" class="theorem"><strong>Theorem 8.6  (Memoryless property) </strong></span>If <span class="math inline">\(T \sim \text{Exp}(\lambda)\)</span> where <span class="math inline">\(\lambda\)</span> is the <em>rate</em> parameter, then for <span class="math inline">\(s &gt; 0\)</span> and <span class="math inline">\(t &gt; 0\)</span>,
<span class="math display">\[
    \Pr(T &gt; s + t \mid T &gt; s) = \Pr(T &gt; t)
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-45" class="proof"><em>Proof</em>. </span>Using Definition <a href="ChapterProbability.html#def:ConditionalProb">2.13</a>,
<span class="math display">\[
   \Pr(T &gt; s + t \mid T &gt; s)
   = \frac{ \Pr( \{T &gt; s + t\} \cap \{T &gt; s\})} {\Pr(T &gt; s)}
\]</span>
But if <span class="math inline">\(T &gt; s + t\)</span>, then <span class="math inline">\(T &gt; s\)</span>.
Consequently <span class="math inline">\(\Pr( \{T &gt; s + t \}\cap \{T &gt; s \} ) = \Pr(T &gt; s + t)\)</span> and so
<span class="math display">\[\begin{align*}
   \Pr(T &gt; s + t \mid T &gt; s )
   &amp;= \frac{\Pr(T &gt; s +t )}{\Pr(T &gt; s)}\\
   &amp;= \frac{\exp\left\{-\lambda(s + t)\right\}}{\exp\left\{-\lambda s\right\}}\\
   &amp;= \exp\left\{-\lambda t\right\}\\
   &amp;= \Pr(T &gt; t).
\end{align*}\]</span></p>
</div>
<p>This theorem states that the probability that the time to the next event is greater than <span class="math inline">\(t\)</span> does not depend on the time <span class="math inline">\(s\)</span> back to the previous event.
This is called the <em>memoryless property</em> of the exponential distribution.</p>
<div class="example">
<p><span id="exm:Memoryless" class="example"><strong>Example 8.9  (Memoryless property of exponential distribution) </strong></span>Suppose the lifespan of component <span class="math inline">\(A\)</span> is modelled by an exponential distribution with mean <span class="math inline">\(12\)</span> months.
Then, <span class="math inline">\(T \sim \text{Exp}(\beta = 6)\)</span>.</p>
<p>The probability that component <span class="math inline">\(A\)</span> fails in less than <span class="math inline">\(6\)</span> months is
<span class="math display">\[
   \Pr(T &lt; 6) = 1 - \exp(-6/12) = 0.3935.
\]</span></p>
<p>Now, suppose component <span class="math inline">\(A\)</span> has been in place for <span class="math inline">\(12\)</span> months.
The probability that it will fail in less than a further <span class="math inline">\(6\)</span> months is
<span class="math display">\[
   \Pr(T &lt; 18 \mid T &gt; 12) = \Pr(T &lt; 6) = 1 - \exp(-6/12) = 0.3935
\]</span>
by the memoryless property.</p>
</div>
<p>Example <a href="ContinuousDistributions.html#exm:Memoryless">8.9</a> shows that an exponential process is ‘ageless’: the risk of ‘mortality’ remains constant with age.
That is, the probability of such an event occurring in the next small interval, whether the failure of a component or the occurrence of an accident, remains constant regardless of the age of the component or the length of time since the last accident.
In this sense, an exponential lifetime is different from a human lifetime, or the lifetime of many man-made objects, where the risk of ‘death’ in the next small interval increases with age.
</p>
</div>
</div>
<div id="GammaDistribution" class="section level2" number="8.5">
<h2>
<span class="header-section-number">8.5</span> Gamma distribution<a class="anchor" aria-label="anchor" href="#GammaDistribution"><i class="fas fa-link"></i></a>
</h2>
<p>
Once the mean of an exponential distribution is defined, the variance is defined.
More flexibility is sometimes needed, which is provided by the gamma distribution.</p>
<div class="definition">
<p><span id="def:GammaDistribution" class="definition"><strong>Definition 8.10  (Gamma distribution) </strong></span>If a random variable <span class="math inline">\(X\)</span> has the PDF
<span class="math display">\[
   f_X(x; \alpha, \beta)
   = \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha - 1} \exp(-x/\beta)
\]</span>
then <span class="math inline">\(X\)</span> has a <em>gamma distribution</em>, where <span class="math inline">\(\Gamma(\cdot)\)</span> is the <em>gamma function</em> (see Sect. <a href="DiscreteDistributions.html#def:GammaFunction">7.11</a>) and <span class="math inline">\(\alpha, \beta &gt; 0\)</span>.
We write <span class="math inline">\(X \sim \text{Gam}(\alpha, \beta)\)</span>.</p>
</div>
<p>The parameter <span class="math inline">\(\alpha\)</span> is called the <em>shape parameter</em> and <span class="math inline">\(\beta\)</span> is called the <em>scale parameter</em>.
Some texts use different notation for the shape and scale parameters.
In broad terms, the <em>shape</em> parameter dictates the general shape of the distribution; the <em>scale</em> parameter dictates how ‘stretched out’ the distribution is.</p>
<div class="softwareBox software">
<p>In <strong>R</strong>, the gamma function <span class="math inline">\(\Gamma(x)\)</span> is evaluated using <code>gamma(x)</code>.</p>
<p>The four <strong>R</strong> functions for working with the gamma distribution have the form <code>[dpqr]gamma(shape, rate, scale = 1/rate)</code>, where <code>shape</code><span class="math inline">\({}= \alpha\)</span> and <code>scale</code><span class="math inline">\({}= \beta\)</span> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).</p>
</div>
<p>Plots of the gamma PDF for various values of the parameters are given in Fig. <a href="ContinuousDistributions.html#fig:GammaDistribution">8.8</a>.
In the bottom right panel, the gamma distributions are starting to look a bit like normal distributions.</p>
<div class="linkBox link">
<p>The exponential distribution is a special case of the gamma distribution with <span class="math inline">\(\alpha = 1\)</span>.
This means that properties of the exponential distribution can be obtained by substituting <span class="math inline">\(\alpha = 1\)</span> into the formulae for the gamma distribution.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:GammaDistribution"></span>
<img src="08-SpecificContinuous_files/figure-html/GammaDistribution-1.png" alt="The PDF of a gamma distribution for various values of $\alpha$ and $\beta$." width="80%"><p class="caption">
FIGURE 8.8: The PDF of a gamma distribution for various values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.
</p>
</div>
<p>Notice that
<span class="math display" id="eq:GammaStd">\[\begin{align}
   \int_0^\infty f_X(x)\,dx
   &amp;= \int_0^\infty\frac{e^{-x/\beta}x^{\alpha - 1}}{\beta^\alpha\Gamma(\alpha)}\,dx\nonumber\\
   &amp;= \frac{1}{\Gamma(\alpha)} \int_0^\infty e^{-y} y^{\alpha-1}\,dy  \quad \text{(on putting $y = x/\beta$)}\nonumber \\
   &amp;= 1,
   \tag{8.11}
\end{align}\]</span>
because <span class="math inline">\(\int_0^\infty \exp(-y) y^{\alpha-1}\,dy = \Gamma(\alpha)\)</span>.</p>
<p>The distribution function for the gamma distribution is complicated, involving incomplete gamma functions, and will not be given.
The following are the basic properties of the gamma distribution.</p>
<div class="theorem">
<p><span id="thm:GammaProperties" class="theorem"><strong>Theorem 8.7  (Gamma distribution properties) </strong></span>If <span class="math inline">\(X\sim\text{Gam}(\alpha,\beta)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[X] = \alpha\beta\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[X] = \alpha\beta^2\)</span>.</li>
<li>
<span class="math inline">\(M_X(t) = (1-\beta t)^{-\alpha}\)</span> for <span class="math inline">\(t &lt; 1/\beta\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-46" class="proof"><em>Proof</em>. </span>For the expected value:
<span class="math display">\[
   \operatorname{E}[X]
   = \int_0^{\infty}x\, f_X(x)\,dx
   = \beta \frac{\Gamma(\alpha + 1)}{\Gamma(\alpha)}
     \underbrace{\int_0^{\infty}\frac{\exp(-x/\beta) x^{(\alpha + 1) - 1}}{\beta^{\alpha + 1}\Gamma(\alpha + 1)} \, dx}_{= 1}
   = \alpha\beta.
\]</span>
This result follows from using Eq. <a href="ContinuousDistributions.html#eq:GammaStd">(8.11)</a> and Theorem <a href="ContinuousDistributions.html#thm:GammaProperties">8.7</a>
<span class="math display">\[
   \operatorname{E}[X^2]
   = \int_0^{\infty}x^2\,  f_X(x) \, dx
   = \beta^2\frac{\Gamma(\alpha + 2)}{\Gamma(\alpha)}
     \underbrace{\int_0^{\infty}\frac{\exp(-x/\beta) x^{(\alpha + 2) - 1}}{\beta^{\alpha + 2}\Gamma(\alpha + 2)}\,dx}_{= 1}
   = \alpha(\alpha + 1)\beta^2
\]</span>
where the result follows by writing <span class="math inline">\(\Gamma(\alpha + 2) = (\alpha + 1)\alpha\Gamma(\alpha)\)</span>.
Hence
<span class="math display">\[
   \operatorname{var}[X]
   = \operatorname{E}[X^2] - (\operatorname{E}[X])^2
   = \alpha(\alpha + 1)\beta^2 - (\alpha\beta)^2
   = \alpha\beta^2
\]</span>
Also:
<span class="math display">\[\begin{align*}
   M_X(t)
    = \operatorname{E}[e^{Xt}]
   &amp;= \int_0^{\infty}\exp(tx) \frac{\exp(-x/\beta) x^{\alpha - 1}}{\beta^{\alpha} \Gamma(\alpha)} \, dx\\
   &amp;= \int_0^{\infty} \frac{\exp\{-x(1 - \beta t)/\beta\}x^{\alpha - 1}}{\beta^{\alpha}\Gamma(\alpha)} \, dx\\
   &amp;= \int_0^{\infty} \frac{\exp(-z) z^{\alpha - 1}}{\Gamma(\alpha)(1 - \beta t)^{\alpha - 1}} \, \frac{dz} {1 - \beta t},
      \text{putting $z = x(1 - \beta t)/\beta$}\\
   &amp;= (1 - \beta t)^{-\alpha},
\end{align*}\]</span>
since the integral remaining is <span class="math inline">\(1\)</span>.</p>
</div>
<p>As usual the moments can be found by expanding <span class="math inline">\(M_X(t)\)</span> as a series.
That is,
<span class="math display">\[
   M_X(t) = 1 \ + \ \alpha\beta t \ + \ \frac{\alpha(\alpha+1)\beta^2}{2!}  t^2 \ + \ \cdots
\]</span>
from which
<span class="math display">\[\begin{align*}
   \operatorname{E}[X]   &amp;= \text{coefficient of }t =\alpha\beta,\\
   \operatorname{E}[X^2] &amp;= \text{coefficient of }t^2/2!=\alpha(\alpha+1)\beta^2,
\end{align*}\]</span>
as found earlier.</p>
<p>As for the normal distribution, the distribution function of the gamma cannot, in general, be computed without using numerical integration, tables (although see Example <a href="ContinuousDistributions.html#exm:ElectricalComponent">8.11</a>) or software.</p>
<div class="example">
<p><span id="exm:Rainfall" class="example"><strong>Example 8.10  (Rainfall) </strong></span><span class="citation">Das (<a href="references.html#ref-climate:das:1955">1955</a>)</span> used a (truncated) gamma distribution for modelling daily precipitation in Sydney.
A similar approach is adopted by <span class="citation">D. S. Wilks (<a href="references.html#ref-climate:wilks:1990">1990</a>)</span>.</p>
<p><span class="citation">Larsen and Marx (<a href="references.html#ref-larsen1986introduction">1986</a>)</span> (Case Study 4.6.1) use the gamma distribution to model daily rainfall in Sydney, Australia using the parameter estimates <span class="math inline">\(\alpha = 0.105\)</span> and <span class="math inline">\(\beta = 76.9\)</span> (based on <span class="citation">Das (<a href="references.html#ref-climate:das:1955">1955</a>)</span>).
The comparison between the data and the model (Table <a href="ContinuousDistributions.html#tab:GammaRain">8.2</a>) indicates a good agreement between the data and the theoretical distribution.</p>
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:GammaRain">TABLE 8.2: </span>The gamma distribution used to model Sydney daily rainfall.
</caption>
<thead><tr>
<th style="text-align:center;font-weight: bold;">
Rainfall (mm)
</th>
<th style="text-align:right;font-weight: bold;">
Observed
</th>
<th style="text-align:right;font-weight: bold;">
Modelled
</th>
<th style="text-align:center;font-weight: bold;">
</th>
<th style="text-align:center;font-weight: bold;">
Rainfall (mm)
</th>
<th style="text-align:right;font-weight: bold;">
Observed
</th>
<th style="text-align:right;font-weight: bold;">
Modelled
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:center;">
0–5
</td>
<td style="text-align:right;">
1631
</td>
<td style="text-align:right;">
1639
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
46–50
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:center;">
6–10
</td>
<td style="text-align:right;">
115
</td>
<td style="text-align:right;">
106
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
51–60
</td>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
20
</td>
</tr>
<tr>
<td style="text-align:center;">
11–15
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
62
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
61–70
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
15
</td>
</tr>
<tr>
<td style="text-align:center;">
16–20
</td>
<td style="text-align:right;">
42
</td>
<td style="text-align:right;">
44
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
71–80
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:center;">
21–25
</td>
<td style="text-align:right;">
27
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
81–90
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:center;">
26–30
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:right;">
26
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
91–100
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:center;">
31–35
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
21
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
101–125
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:center;">
36–40
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
126–150
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:center;">
41–45
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
151–425
</td>
<td style="text-align:right;">
14
</td>
<td style="text-align:right;">
13
</td>
</tr>
</tbody>
</table></div>
<div class="example">
<p><span id="exm:ElectricalComponent" class="example"><strong>Example 8.11  (Electrical components) </strong></span>The lifetime of an electrical component in hours, say <span class="math inline">\(T\)</span>, can be well modelled by the distribution <span class="math inline">\(\text{Gam}(2, 1)\)</span>.
What is the probability that a component will last for more than three hours?</p>
<p>From the information, <span class="math inline">\(T\sim \text{Gam}(\alpha = 2, \beta = 1)\)</span>.
The required probability is therefore
<span class="math display">\[\begin{align*}
   \Pr(T &gt; 3)
   &amp;= \int_3^\infty \frac{1}{1^2 \Gamma(2)}t^{2 - 1} \exp(-t/1)\,dt \\
   &amp;= \int_3^\infty t \exp(-t)\,dt \\
\end{align*}\]</span>
since <span class="math inline">\(\Gamma(2) = 1! = 1\)</span>.
This expression can be integrated using integration by parts:
<span class="math display">\[\begin{align*}
   \Pr(T &gt; 3)
   &amp;= \int_3^\infty t \exp(-t)\,dt \\
   &amp;= \left\{ -t \exp(-t)\right\}\Big|_3^\infty - \int_3^\infty -\exp(-t)\, dt \\
   &amp;= [ (0) - \{-3\exp(-3)\}] - \left\{ \exp(-t)\Big|_3^\infty\right\} \\
   &amp;= 3\exp(-3) + \exp(-3)\\
   &amp;= 0.1991
\end{align*}\]</span>
Integration by parts is only possible since <span class="math inline">\(\alpha\)</span> is an integer.
If <span class="math inline">\(\alpha = 2.5\)</span>, for example, integration by parts would not be possible.</p>
<p>A more general approach is to use tables of the incomplete gamma function to evaluate the integral, numerical integration, or software.
To use <strong>R</strong>:</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Integrate</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/integrate.html">integrate</a></span><span class="op">(</span><span class="va">dgamma</span>, <span class="co"># The gamma distribution prob. fn</span></span>
<span>          lower <span class="op">=</span> <span class="fl">3</span>,</span>
<span>          upper <span class="op">=</span> <span class="cn">Inf</span>,  <span class="co"># "Inf" means "infinity"</span></span>
<span>          shape <span class="op">=</span> <span class="fl">2</span>,</span>
<span>          scale <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; 0.1991483 with absolute error &lt; 9.3e-05</span></span>
<span></span>
<span><span class="co"># Directly</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="fl">3</span>,</span>
<span>           shape <span class="op">=</span> <span class="fl">2</span>,</span>
<span>           scale <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.1991483</span></span></code></pre></div>
<p>Using any method, the probability is about 20%.</p>
</div>
<div class="example">
<p><span id="exm:Gamma" class="example"><strong>Example 8.12  (Gamma) </strong></span>If <span class="math inline">\(X\sim \text{Gam}(\alpha, \beta)\)</span>, find the distribution of <span class="math inline">\(Y = kX\)</span> for some constant <span class="math inline">\(k\)</span>.</p>
<p>One way to approach this question is to use moment-generating functions.
Since <span class="math inline">\(X\)</span> has a gamma distribution, <span class="math inline">\(M_X(t) = (1-\beta t)^{-\alpha}\)</span>.
Now,
<span class="math display">\[\begin{align*}
   M_Y(t)
   &amp;= \operatorname{E}[\exp(tY)] \qquad\text{by definition of the MGF}\\
   &amp;= \operatorname{E}[\exp(t kX)] \qquad\text{since $X = kX$}\\
   &amp;= \operatorname{E}[\exp(s X)] \qquad\text{by letting $s = kt$}\\
   &amp;= M_X(s) \qquad\text{by definition of the MGF}\\
   &amp;= M_X(kt) \\
   &amp;= (1 - \beta kt)^{-\alpha}.
\end{align*}\]</span>
This is just the MGF for random variable <span class="math inline">\(X\)</span> with <span class="math inline">\(k\beta\)</span> in place of <span class="math inline">\(\beta\)</span>, so the distribution of <span class="math inline">\(Y\)</span> is <span class="math inline">\(\text{Gam}(\alpha, k\beta)\)</span>.</p>
</div>
<p></p>
</div>
<div id="BetaDistribution" class="section level2" number="8.6">
<h2>
<span class="header-section-number">8.6</span> Beta distribution<a class="anchor" aria-label="anchor" href="#BetaDistribution"><i class="fas fa-link"></i></a>
</h2>
<p>
Some continuous random variables are constrained to a finite interval.
The beta distribution is useful in these situations.</p>
<div class="definition">
<p><span id="def:BetaDistribution" class="definition"><strong>Definition 8.11  (Beta distribution) </strong></span>A random variable <span class="math inline">\(X\)</span> with probability density function
<span class="math display">\[\begin{equation*}
   f_X(x; m, n)
   = \frac{x ^ {m - 1}(1 - x)^{n - 1}}{B(m, n)} \quad \text{for $0\leq x \leq 1$ and $m &gt; 0$, $n &gt; 0$},
\end{equation*}\]</span>
and <span class="math inline">\(B(m, n)\)</span> is the <em>beta function</em>
<span class="math display" id="eq:BetaFunction">\[\begin{align}
   B(m, n)
   &amp;= \int_0^1  x^{m - 1}(1 - x)^{n - 1} \, dx, \quad \text{for $m &gt; 0$ and $n &gt; 0$}\notag\\
   &amp;= \frac{\Gamma(m)\, \Gamma(n)}{\Gamma(m + n)},
   \tag{8.12}
\end{align}\]</span>
is said to have a <em>beta distribution</em> with parameters <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>.
We write <span class="math inline">\(X \sim \text{Beta}(m, n)\)</span>.</p>
</div>
<p><span class="math inline">\(B(m, n)\)</span> defined by <a href="ContinuousDistributions.html#eq:BetaFunction">(8.12)</a> is known as the <em>beta function</em> with parameters <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>.
Since <span class="math inline">\(\int_0^1 f_X(x)\,dx = 1\)</span> then
<span class="math display">\[
   \int_0^1  \frac{x^{m - 1}(1 - x)^{n - 1}}{B(m, n)}\,dx = 1.
\]</span></p>
<div class="softwareBox software">
<p>In <strong>R</strong>, the beta function is evaluated using <code>beta(a, b)</code>, where <code>a</code><span class="math inline">\({} = m\)</span> and <code>b</code><span class="math inline">\({} = n\)</span>.</p>
<p>The four <strong>R</strong> functions for working with the beta distribution have the form <code>[dpqr]beta(shape1, shape2)</code>, where <code>shape1</code><span class="math inline">\({}= m\)</span> and <code>shape2</code><span class="math inline">\({}= n\)</span> (see App. <a href="UseRDistributions.html#UseRDistributions">D</a>).</p>
</div>
<p>The distribution function for the beta distribution is complicated, involving incomplete beta functions, and will not be given.
Some properties of the beta function follow.</p>
<div class="theorem">
<p><span id="thm:BetaFunctionProperties" class="theorem"><strong>Theorem 8.8  (Beta function properties) </strong></span>The beta function in Eq. <a href="ContinuousDistributions.html#eq:BetaFunction">(8.12)</a> satisfies the following:</p>
<ol style="list-style-type: decimal">
<li>The beta function is symmetric in <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>.
That is, if <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> are interchanged, the function remains unaltered; i.e., <span class="math inline">\(B(m, n) = B (n, m)\)</span>.</li>
<li>
<span class="math inline">\(B(1, 1) = 1\)</span>.</li>
<li>
<span class="math inline">\(B\left(\frac{1}{2}, \frac{1}{2}\right) = \pi\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-47" class="proof"><em>Proof</em>. </span>To prove the first, put <span class="math inline">\(z = 1 - x\)</span> and hence <span class="math inline">\(dz = -dx\)</span> in Eq. <a href="ContinuousDistributions.html#eq:BetaFunction">(8.12)</a>.
Then
<span class="math display">\[\begin{align*}
   B(m, n)
   &amp;= -\int_1^0(1 - z)^{m - 1}  z^{n - 1} \, dz\\
   &amp;= \int_0^1 z^{n - 1}(1 - z)^{m - 1} \, dz\\
   &amp;= B(n, m).
\end{align*}\]</span></p>
<p>For the second, put <span class="math inline">\(x = \sin^2\theta\)</span>, and so <span class="math inline">\(dx = 2\sin\theta\cos\theta\,d\theta\)</span>, in Eq. <a href="ContinuousDistributions.html#eq:BetaFunction">(8.12)</a>.
We have
<span class="math display">\[
   B(m, n) = 2 \int_0^{\pi/2} \sin^{2m - 1}\theta \cos ^{2n - 1}\theta\,d\theta.
\]</span>
So, for <span class="math inline">\(m = n = \frac{1}{2}\)</span>,
<span class="math display">\[
   B\left(\frac{1}{2}, \frac{1}{2}\right) = 2\int_0^{\pi/2} d\theta = \pi.
\]</span></p>
<p>For the third, note that <span class="math inline">\(\Gamma(1/2) = \sqrt{\pi}\)</span> from Theorem <a href="ContinuousDistributions.html#thm:GammaProperties">8.7</a>.
Further, since <span class="math inline">\(\Gamma(1) = 0! = 1\)</span>, the results follows.</p>
</div>
<p>Typical graphs for the beta PDF are given in Fig. <a href="ContinuousDistributions.html#fig:BetaDistributions">8.9</a>.
When <span class="math inline">\(m = n\)</span>, the distribution is symmetric about <span class="math inline">\(x = \frac{1}{2}\)</span>.</p>
<div class="linkBox link">
<p>When <span class="math inline">\(m = n = 1\)</span>, the beta distribution becomes the uniform distribution on <span class="math inline">\((0, 1)\)</span>.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:BetaDistributions"></span>
<img src="08-SpecificContinuous_files/figure-html/BetaDistributions-1.png" alt="Various beta-distribution PDFs." width="80%"><p class="caption">
FIGURE 8.9: Various beta-distribution PDFs.
</p>
</div>
<p>Some basic properties of the beta distribution follow.</p>
<div class="theorem">
<p><span id="thm:BetaDistributionProperties" class="theorem"><strong>Theorem 8.9  (Beta distribution properties) </strong></span>If <span class="math inline">\(X \sim \text{Beta}(m, n)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[X] = m/(m + n)\)</span>.</li>
<li>
<span class="math inline">\(\displaystyle\operatorname{var}[X] = \frac{mn}{(m + n)^2 (m + n + 1)}\)</span>.</li>
<li>A mode occurs at <span class="math inline">\(\displaystyle x = \frac{m - 1}{m + n - 2}\)</span> for <span class="math inline">\(m, n &gt; 1\)</span>.</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-48" class="proof"><em>Proof</em>. </span>Assume <span class="math inline">\(X \sim \text{Beta}(m, n)\)</span>, then
<span class="math display">\[\begin{align*}
   \mu_r'
   =\operatorname{E}[X^r]
   &amp;= \int_0^1  \frac{x^r  x^{m - 1}(1 - x)^{n - 1}} {B(m, n)}\,dx\\
   &amp;= \frac{B(m + r, n)}{B(m, n)}  \int_0^1 \frac{x^{m + r - 1}(1 - x)^{n - 1}}{B(m + r, n)}\,dx\\
   &amp;= \frac{\Gamma(m + r)\,\Gamma(n)}{\Gamma(m + r + n)} \frac{\Gamma(m + n)}{\Gamma(m)\,\Gamma(n)}\\
   &amp;= \frac{\Gamma(m + r)\,\Gamma(m + n)}{\Gamma(m + r + n)\,\Gamma(m)}
\end{align*}\]</span>
Putting <span class="math inline">\(r = 1\)</span> and <span class="math inline">\(r = 2\)</span> into the above expression, and using that <span class="math inline">\(\operatorname{var} = \operatorname{E}[X^2] - \operatorname{E}[X]^2\)</span>, the mean and variance are <span class="math inline">\(\operatorname{E}[X] = m/(m + n)\)</span> and <span class="math inline">\(\operatorname{var}[X] = \frac{mn}{(m + n)^2(m + n + 1)}\)</span>.</p>
<p>Any mode <span class="math inline">\(\theta\)</span> of the distribution for which <span class="math inline">\(0 &lt; \theta &lt; 1\)</span> will satisfy <span class="math inline">\(f'_X(\theta) = 0\)</span>.
From the definition we see that for <span class="math inline">\(m, n&gt;1\)</span> and <span class="math inline">\(0 &lt; x &lt; 1\)</span>,
<span class="math display">\[
   f'_X(x) = (m - 1)x^{m - 2} (1 - x)^{n - 1} - (n - 1)x^{m - 1}(1 - x)^{n - 1}/B(m, n) = 0
\]</span>
implying <span class="math inline">\((m - 1)(1 - x) = (n - 1)x\)</span> which is satisfied by <span class="math inline">\(x = (m - 1) / (m + n - 2)\)</span>.</p>
</div>
<p>The MGF of the beta distribution cannot be written in terms of standard functions.
The distribution function of the beta must be evaluated numerically in general, except when <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> are integers, as shown in the example below.</p>
<p>If <span class="math inline">\(X\sim \text{Beta}(m, n)\)</span>, then <span class="math inline">\(X\)</span> is defined on <span class="math inline">\([0, 1]\)</span>.
Sometimes then, the beta distribution is used to model proportions, though not proportions out of a total number (when the <a href="DiscreteDistributions.html#BinomialDistribution">binomial distribution</a> is used).
Instead, the beta distribution is used, for example, to model percentage cloud cover (for instance, <span class="citation">Falls (<a href="references.html#ref-falls1974beta">1974</a>)</span>).</p>
<p>For a random variable <span class="math inline">\(Y\)</span> defined on a different closed interval <span class="math inline">\([a, b]\)</span>, define <span class="math inline">\(Y = X(b - a) + a\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-49" class="example"><strong>Example 8.13  </strong></span><span class="citation">Damgaard and Irvine (<a href="references.html#ref-damgaard2019using">2019</a>)</span> use the beta-distribution to model the relative areas covered by plants of different species.
The beta distribution is a suitable model, since these relative areas are proportions.
In addition, the authors state (p. 2747) that</p>
<blockquote>
<p>…plant cover data tend to be left-skewed (J-shaped), right skewed (L-shaped) or U-shaped</p>
</blockquote>
<p>which align with some of the plots in Fig. <a href="ContinuousDistributions.html#fig:BetaDistributions">8.9</a>.</p>
</div>
<div class="example">
<p><span id="exm:BetaTanks" class="example"><strong>Example 8.14  (Beta distributions) </strong></span>The bulk storage tanks of a fuel retailed are filled each Monday.
The retailer has observed that over many weeks the proportion of the available fuel supply sold is well modelled by a beta distribution with <span class="math inline">\(m = 4\)</span> and <span class="math inline">\(n = 2\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> denotes the proportion of the total supply sold in a given week, the mean proportion of fuel sold each week is
<span class="math display">\[
   \operatorname{E}[X] = m/(m + n) = 4/6 = 2/3.
\]</span></p>
<p>To find the probability that at least <span class="math inline">\(90\)</span>% of the supply will sell in a given week, compute:
<span class="math display">\[\begin{align*}
   \Pr(X &gt; 0.9)
   &amp;= \int_{0.9}^1\frac{\Gamma(4 + 2)}{\Gamma(4)\Gamma(2)}x^3(1 - x)dx\\
   &amp;= 20\int_{0.9}^1 (x^3 - x^4))\,dx\\
   &amp;= 20(0.004)\\
   &amp;= 0.08
\end{align*}\]</span>
It is unlikely that <span class="math inline">\(90\)</span>% of the supply will be sold in a given week.
In <strong>R</strong>:</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">pbeta</a></span><span class="op">(</span><span class="fl">0.9</span>, </span>
<span>          shape1 <span class="op">=</span> <span class="fl">4</span>, </span>
<span>          shape2 <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.08146</span></span></code></pre></div>
</div>
<p></p>
</div>
<div id="TransformationsChiSquared" class="section level2" number="8.7">
<h2>
<span class="header-section-number">8.7</span> The chi-squared distribution<a class="anchor" aria-label="anchor" href="#TransformationsChiSquared"><i class="fas fa-link"></i></a>
</h2>
<p>USE AS AN EXMAPLE??</p>
<p>Examples <a href="ChapterTransformations.html#exm:TransformationNon11">6.8</a> and <a href="ChapterTransformations.html#exm:TransformB">6.13</a> produce the chi-square distribution, which is an important model in statistical theory (Theorem <a href="SamplingDistributions.html#thm:ChiSquare">12.6</a>).</p>
<div class="definition">
<p><span id="def:ChiSquaredDistribution" class="definition"><strong>Definition 8.12  (Chi-squared distribution) </strong></span>A continuous random variable <span class="math inline">\(X\)</span> with probability density function
<span class="math display">\[\begin{equation}
   f_X(x)
   = \frac{x^{(\nu/2) - 1}e^{-x/2}}{2^{\nu/2}\Gamma(\nu/2)}\quad\text{for $x &gt; 0$}
\end{equation}\]</span>
is said to have a <em>chi-square distribution</em> with parameter <span class="math inline">\(\nu &gt; 0\)</span>.
The parameter <span class="math inline">\(\nu\)</span> is called the <em>degrees of freedom</em>.
We write <span class="math inline">\(X \sim \chi^2(\nu)\)</span>.</p>
</div>
<p>Some plots of <span class="math inline">\(\chi^2\)</span>-distributions are shown in Fig. <a href="ContinuousDistributions.html#fig:ChisqPlots">8.10</a>.</p>
<div class="linkBox link">
<p>The chi-squared distribution is a special case of the gamma distribution, with <span class="math inline">\(\alpha = \nu/2\)</span> and <span class="math inline">\(\beta = 2\)</span> (Exercise <a href="ChapterTransformations.html#exr:ChiSquaredGamma">6.19</a>).
This means that properties of the chi-squared distribution can be obtained directly from those for the gamma distribution (Sect. <a href="ContinuousDistributions.html#GammaDistribution">8.5</a>).</p>
</div>
<div class="figure">
<span style="display:block;" id="fig:ChisqPlots"></span>
<img src="08-SpecificContinuous_files/figure-html/ChisqPlots-1.png" alt="Some $\chi^2$-distributions." width="100%"><p class="caption">
FIGURE 8.10: Some <span class="math inline">\(\chi^2\)</span>-distributions.
</p>
</div>
<p>The basic properties of the chi-square follow directly from those of the gamma distribution (Theorem <a href="ContinuousDistributions.html#thm:GammaProperties">8.7</a>).</p>
<div class="theorem">
<p><span id="thm:ChisqProperties" class="theorem"><strong>Theorem 8.10  (Properties of chi-squared distribution) </strong></span>If <span class="math inline">\(X\sim\chi^2(\nu)\)</span> then</p>
<ul>
<li>
<span class="math inline">\(\operatorname{E}(X) = \nu\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}(X) = 2\nu\)</span>.</li>
<li>
<span class="math inline">\(M_X(t) = (1 - 2t)^{-\nu/2}\)</span>.</li>
</ul>
</div>
<div class="proof">
<p><span id="unlabeled-div-50" class="proof"><em>Proof</em>. </span>See Theorem <a href="ContinuousDistributions.html#thm:GammaProperties">8.7</a>.</p>
</div>
<p>The importance of the chi-square distribution is hinted at in Examples <a href="ChapterTransformations.html#exm:TransformationNon11">6.8</a> and <a href="ChapterTransformations.html#exm:TransformB">6.13</a>, which essentially prove the following theorem.</p>
<div class="theorem">
<p><span id="thm:ChiSqDistribution" class="theorem"><strong>Theorem 8.11  (Chi-square distribution with 1 df) </strong></span>If <span class="math inline">\(Z\sim N(0, 1)\)</span> then <span class="math inline">\(Z^2\)</span> has a chi-square distribution with one degree of freedom.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-51" class="proof"><em>Proof</em>. </span>Exercise; see Example <a href="ChapterTransformations.html#exm:TransformationNon11">6.8</a>.</p>
</div>
<p>A useful property of the chi-square distribution is that the sum of independent random variables, each with a chi-square distribution, also has a chi-square distribution.
This property is given in the following theorem, which will be used later.</p>
<div class="theorem">
<p><span id="thm:SumSquaredNormals" class="theorem"><strong>Theorem 8.12  (Chi-squared distribution) </strong></span>If <span class="math inline">\(Z_1, Z_2,\dots, Z_n\)</span> are independently and identically distributed (iid) as <span class="math inline">\(N(0, 1)\)</span>, then the sum of squares <span class="math inline">\(S = \sum_i Z_i^2\)</span> has a <span class="math inline">\(\chi^2(n)\)</span> distribution.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-52" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(S\)</span> is a linear combination of known distributions, using the MGF method is appropriate.
Since <span class="math inline">\(Z_i \sim \chi^2(1)\)</span>, from Theorem <a href="ContinuousDistributions.html#thm:ChisqProperties">8.10</a>
<span class="math display">\[
   M_{Z_i}(t)
   = (1 - 2t)^{-1/2}.
\]</span>
From Theorem <a href="ChapExpectation.html#thm:MGFIndependent">5.6</a> then, <span class="math inline">\(S = \sum_{i = 1}^n Z_i^2\)</span> has MGF
<span class="math display">\[\begin{align*}
   M_{S}(t)
   &amp;= \prod_{i = 1}^n (1 - 2t)^{-1/2}\\
   &amp;= \left[(1 - 2t)^{-1/2}\right]^n
    = (1 - 2t)^{-n/2},
\end{align*}\]</span>
which is the MGF of <span class="math inline">\(\chi^2(n)\)</span>.</p>
</div>
<p>Chi-square probabilities cannot in general be calculated without computers or tables.</p>
<div class="softwareBox software">
<p>The four <strong>R</strong> functions for working with the chi-squared distribution have the form <code>[dpqr]chisq(df)</code>, where <code>df</code><span class="math inline">\({} = \nu\)</span> refers to the degrees of freedom (see Appendix <a href="UseRDistributions.html#UseRDistributions">D</a>).</p>
</div>
<div class="example">
<p><span id="exm:ChisqProb" class="example"><strong>Example 8.15  (Chi-squared distributions) </strong></span>The variable <span class="math inline">\(X\)</span> has a chi-square distribution with <span class="math inline">\(12\)</span> df.
Determine the value of <span class="math inline">\(X\)</span> below which lies 90% of the distribution.</p>
<p>We seek a value <span class="math inline">\(c\)</span> such that <span class="math inline">\(\Pr(X &lt; c) = F_X(c) = 0.90\)</span> where <span class="math inline">\(X\sim\chi^2(12)\)</span>.
In <strong>R</strong>:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq</a></span><span class="op">(</span><span class="fl">0.9</span>, df <span class="op">=</span> <span class="fl">12</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 18.54935</span></span></code></pre></div>
<p>That is, about <span class="math inline">\(90\)</span>% of the distribution lies below 18.549.</p>
</div>
</div>
<div id="BVNormalDistribution" class="section level2" number="8.8">
<h2>
<span class="header-section-number">8.8</span> The bivariate normal distribution<a class="anchor" aria-label="anchor" href="#BVNormalDistribution"><i class="fas fa-link"></i></a>
</h2>
<p>
A specific example of a <em>continuous</em> multivariate distribution is the <em>bivariate normal distribution</em>.</p>
<div class="definition">
<p><span id="def:BVNormalDistribution" class="definition"><strong>Definition 8.13  (The bivariate normal distribution) </strong></span>If a pair of random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have the joint PDF
<span class="math display" id="eq:bivarnormalPDF">\[\begin{equation}
   f_{X, Y}(x, y; \mu_x, \mu_Y, \sigma^2_X, \sigma^2_Y, \rho) =
   \frac{1}{2\pi\sigma_X\sigma_Y\sqrt{1 - \rho^2}}\exp(-Q/2)
   \tag{8.13}
\end{equation}\]</span>
where
<span class="math display">\[
   Q = \frac{1}{1-\rho^2}\left[
                      \left(\frac{x-\mu_X}{\sigma_X}\right)^2 -
                2\rho\left( \frac{x-\mu_X}{\sigma_X}\right)\left(\frac{y-\mu_Y}{\sigma_Y}\right)
                +     \left(\frac{y-\mu_Y}{\sigma_Y}\right)^2 \right],
\]</span>
then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have a <em>bivariate normal distribution</em>.
We write
<span class="math display">\[
   (X, Y) \sim N_2(\mu_X, \mu_Y, \sigma^2_X, \sigma^2_Y, \rho ).
\]</span></p>
</div>
<p>A typical graph of the bivariate normal surface above the <span class="math inline">\(x\)</span>–<span class="math inline">\(y\)</span> plane is shown
below.
Showing <span class="math inline">\(\int^\infty_{-\infty}\!\int^\infty_{-\infty}f_{X,Y}(x,y)\,dx\,dy = 1\)</span> is not straightforward and involves writing Eq. <a href="ContinuousDistributions.html#eq:bivarnormalPDF">(8.13)</a> using polar coordinates.</p>
<p>Some important facts about the bivariate normal distribution are contained in the theorem below.</p>
<div class="theorem">
<p><span id="thm:BivarNormalProperties" class="theorem"><strong>Theorem 8.13  (Bivariate normal distribution properties) </strong></span>For <span class="math inline">\((X, Y)\)</span> with PDF given in Eq. <a href="ContinuousDistributions.html#eq:bivarnormalPDF">(8.13)</a>:</p>
<ol style="list-style-type: decimal">
<li>The marginal distributions of <span class="math inline">\(X\)</span> and of <span class="math inline">\(Y\)</span> are <span class="math inline">\(N(\mu_X, \sigma^2_X)\)</span> and <span class="math inline">\(N(\mu_Y, \sigma^2_Y)\)</span> respectively.</li>
<li>The parameter <span class="math inline">\(\rho\)</span> appearing in Eq. <a href="ContinuousDistributions.html#eq:bivarnormalPDF">(8.13)</a> is the correlation coefficient between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>the conditional distributions of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y = y\)</span>, and of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X = x\)</span>, are respectively
<span class="math display">\[\begin{align*}
  &amp;N\left( \mu_X + \rho \sigma_X(y - \mu_Y)/\sigma_Y, \sigma^2_X(1 - \rho^2)\right); \\
  &amp;N\left( \mu_Y + \rho \sigma_Y(x - \mu_X)/\sigma_X, \sigma^2_Y(1 - \rho^2)\right).
  \end{align*}\]</span>
</li>
</ol>
</div>
<div class="proof">
<p><span id="unlabeled-div-53" class="proof"><em>Proof</em>. </span>Recall that the marginal PDF of <span class="math inline">\(X\)</span> is <span class="math inline">\(f_X(x) = \int^\infty_{-\infty} f_{X, Y}(x, y)\,dy\)</span>.
In the integral, put <span class="math inline">\(u = (x - \mu_X)/\sigma_X, v = (y - \mu_Y)/\sigma_Y,\, dy = \sigma_Y\,dv\)</span> and complete the square in the exponent on <span class="math inline">\(v\)</span>:
<span class="math display">\[\begin{align*}
     g(x)
     &amp;= \frac{1}{2\pi\sigma_X\sqrt{1 - \rho^2}\sigma_Y}\int^\infty_{-\infty}\exp\left\{ -\frac{1}{2(1 - \rho^2)}\left[ u^2 - 2\rho uv + v^2\right]\right\} \sigma_Y\,dv\\[2mm]
     &amp;= \frac{1}{2\pi \sigma_X\sqrt{1 - \rho^2}}\int^\infty_{-\infty} \exp\left\{ -\frac{1}{2(1 - \rho^2)}\left[ (v - \rho u)^2 + u^2 - \rho^2u^2\right]\right\}\,dv\\[2mm]
     &amp;= \frac{e^{-u^2/2}}{\sqrt{2\pi} \sigma_X} \ \underbrace{\int^\infty_{-\infty} \frac{1}{\sqrt{2\pi (1 - \rho^2)}} \exp\left\{ -\frac{1}{2(1 - \rho^2)}(v - \rho u)^2\right\}\,dv}_{=1}.
\end{align*}\]</span>
Replacing <span class="math inline">\(u\)</span> by <span class="math inline">\((x - \mu_X )/\sigma_X\)</span>, we see from the PDF that <span class="math inline">\(X \sim N(\mu_X, \sigma^2_X)\)</span>.
Similarly for the marginal PDF of <span class="math inline">\(Y\)</span>; i.e., <span class="math inline">\(f_Y(y)\)</span>.</p>
<p>To show that <span class="math inline">\(\rho\)</span> in Eq. <a href="ContinuousDistributions.html#eq:bivarnormalPDF">(8.13)</a> is the correlation coefficient of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, recall that
<span class="math display">\[\begin{align*}
     \rho_{X,Y}
     &amp;= \operatorname{Cov}(X,Y)/\sigma_X\sigma_Y=\operatorname{E}[(X-\mu_X)(Y - \mu_Y)]/\sigma_X\sigma_Y   \\[2mm]
     &amp; = \int^\infty_{-\infty}\!\int^\infty_{-\infty} \frac{(x - \mu_X)}{\sigma_X}\frac{(y - \mu_Y)}{\sigma_Y}f(x,y)\,dx\,dy\\[2mm]
     &amp;= \int^\infty_{-\infty}\!\int^\infty_{-\infty} uv\frac{1}{2\pi\sqrt{1 - \rho^2} \sigma_X\sigma_Y}\exp\left\{ -\frac {1}{2(1 - \rho^2)}[u^2 - 2\rho uv + v^2]\right\} \sigma_X\sigma_Y\,du\,dv.
\end{align*}\]</span></p>
<p>The exponent is
<span class="math display">\[
   -\frac{[(u - \rho v)^2 + v^2 - \rho^2 v^2]}{2(1 - \rho^2)}
   = - \frac{1}{2} \left\{\frac{(u - \rho v)^2}{(1 - \rho^2)} + v^2\right\}.
\]</span>
Then:
<span class="math display">\[\begin{align*}
   \rho_{X, Y}
   &amp;=\int^\infty_{-\infty}\frac{v e^{-v^2/2}}{\sqrt{2\pi}}\underbrace{\int^\infty_{-\infty} \frac{u}{\sqrt{2\pi
  (1 - \rho^2)}}\exp\{ -(u - \rho v)^2/2(1 - \rho^2)\}\,du}_{\displaystyle{= \operatorname{E}[U]\text{ where } u \sim N(\rho
  v, 1 - \rho^2) = \rho v}}\,dv \\[2mm]
   &amp;= \rho \int^\infty_{-\infty} \frac{v^2}{\sqrt{2\pi}}e^{-v^2/2}\,dv\\[2mm]
   &amp;= \rho\quad \text{since the integral is $\operatorname{E}[V^2]$ where $V \sim N(0,1)$.}
\end{align*}\]</span></p>
<p>In finding the conditional PDF of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y = y\)</span>, use
<span class="math display">\[
   f_{X \mid Y = y}(x) = f_{X, Y}(x, y)/f_Y(y).
\]</span>
Then in this ratio, the constant is
<span class="math display">\[
  \frac{\sqrt{2\pi} \sigma_Y}{2\pi \sigma_X\sigma_Y \sqrt{1 - \rho^2}}
  = \frac{1}{\sqrt{2\pi}\sigma_X\sqrt{1 - \rho^2}}.
\]</span>
The exponent is
<span class="math display">\[\begin{align*}
       &amp; \frac{\exp\left\{ -\left[ \displaystyle{\frac{(x - \mu_X)^2}{\sigma^2_X}} -
  \displaystyle{\frac{2\rho(x - \mu_X)(y - \mu_Y)}{\sigma_X\sigma_Y}} +
  \displaystyle{\frac{(y - \mu_Y)^2}{\sigma^2_Y}}\right] / 2(1 - \rho^2) \right\}  }{\exp\left[ -(y - \mu_Y)^2 / 2\sigma^2_Y\right]}\\[2mm]
       &amp;= \exp\left\{ - \frac{1}{2(1 - \rho^2)} \left[ \frac{(x - \mu_X)^2}{\sigma^2_X} - \frac{2\rho (x - \mu_X)(y - \mu_Y)}{\sigma_X\sigma_Y} +
  \frac{(y - \mu_Y)^2}{\sigma^2_Y} (1 - 1 + \rho^2)\right] \right\}\\[2mm]
       &amp;= \exp\left\{ - \frac{1}{2\sigma^2_X(1 - \rho^2)}
       \left[ (x - \mu_X)^2 - 2\rho \frac{\sigma_X}{\sigma_Y} (x - \mu_X)(y - \mu_Y) +
       \frac{\rho^2 \sigma^2_X}{\sigma^2_Y}(y - \mu_Y)^2\right]\right\}\\[2mm]
       &amp;= \exp \left\{ - \frac{1}{2(1 - \rho^2)\sigma^2_X} \left[ x - \mu_X - \rho\frac{\sigma_X}{\sigma_Y}(y - \mu_Y)\right]^2\right\}.
\end{align*}\]</span>
So the conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y = y\)</span> is
<span class="math display">\[
   N\left( \mu_X + \rho\frac{\sigma_X}{\sigma_Y}(y - \mu_Y), \sigma^2_X(1 - \rho^2)\right).
\]</span>
Recall the interpretation of the conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y = y\)</span> (Sect. <a href="ChapBivariate.html#ConditionalDistributions">4.5</a>) and note the shape of this density
below.</p>
</div>
<p>Comments about Theorem <a href="ContinuousDistributions.html#thm:BivarNormalProperties">8.13</a>:</p>
<ul>
<li>From the first and third parts, <span class="math inline">\(\operatorname{E}[X] = \mu_X\)</span> and <span class="math inline">\(\operatorname{E}[X \mid Y = y] = \mu_X + \rho \sigma_X (y - \mu_Y)/\sigma_Y\)</span> (and similarly for <span class="math inline">\(Y\)</span>).
Notice that <span class="math inline">\(\operatorname{E}[X \mid Y = y]\)</span> is a linear function of <span class="math inline">\(y\)</span>; i.e., if <span class="math inline">\((X, Y)\)</span> is bivariate normal, the regression line of <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> (and <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>) is linear.</li>
<li>An important result follows from the second part.
If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are uncorrelated (i.e., if <span class="math inline">\(\rho = 0\)</span>) then <span class="math inline">\(f_{X, Y}(x, y) = f_X(x) f_Y(y)\)</span> and thus <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.
That is, if two normally distributed random variables are uncorrelated, they are also independent.</li>
</ul>
<div class="example">
<p><span id="exm:BivariateHeights" class="example"><strong>Example 8.16  (Bivariate normal: Heights) </strong></span><span class="citation">(<a href="references.html#ref-data:Marsh1988:ExploringData">Badiou, Marsh, and Gauchet 1988</a>)</span> gives data from <span class="math inline">\(200\)</span> married men and their wives from the OPCS study of heights and weights of adults in Great Britain in 1980.
Histograms of the husbands’ and wives’ heights are given in Fig. <a href="ContinuousDistributions.html#fig:HtsPlots">8.11</a> (left and centre panels); the marginal distributions are approximately normal.
The scatterplot of the heights is shown in Fig. <a href="ContinuousDistributions.html#fig:HtsPlots">8.11</a> (right panel).</p>
<p>From the histograms, there is reason to suspect that a bivariate normal distribution would be appropriate.
Using <span class="math inline">\(H\)</span> to refer to heights (in mm) of husbands and <span class="math inline">\(W\)</span> to the heights (in mm) of wives, the sample statistics are shown below (and where the estimate of the correlation is <span class="math inline">\(+0.364\)</span>):</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>Statistic</th>
<th>Husbands</th>
<th>Wives</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Sample mean (in mm):</td>
<td>1732</td>
<td>1602</td>
</tr>
<tr class="even">
<td>Sample std dev (in mm):</td>
<td>68.8</td>
<td>62.4</td>
</tr>
</tbody>
</table></div>
<p>Note that <span class="math inline">\(\rho\)</span> is positive; this implies taller men marry taller women on average.
Using this sample information, the bivariate normal distribution can be estimated.
This <span class="math inline">\(3\)</span>-dimensional density function can be difficult to plot on a two-dimensional page, but see
below.</p>
<p>The PDF for the bivariate normal distribution for the heights of the husbands and wives could be written down in the form of <a href="ContinuousDistributions.html#eq:bivarnormalPDF">(8.13)</a> for the values of <span class="math inline">\(\mu_H\)</span>, <span class="math inline">\(\mu_W\)</span>, <span class="math inline">\(\sigma^2_H\)</span>, <span class="math inline">\(\sigma^2_W\)</span> and <span class="math inline">\(\rho\)</span> above, but this is tedious.</p>
<p>Given the information, what is the probability that a randomly chosen man in the UK in 1980 who is <span class="math inline">\(173\,\text{cm}\)</span> tall had married a woman taller than himself?</p>
<p>The information implies that <span class="math inline">\(H = 1730\)</span> is given (remembering the data are given in millimetres).
So we need the <em>conditional distribution</em> of <span class="math inline">\(W \mid H = 1730\)</span>.
Using the results above, this conditional distribution will have mean
<span class="math display">\[\begin{align*}
   b
   &amp;= \mu_W + \rho\frac{\sigma_W}{\sigma_H}(y_H - \mu_H) \\
   &amp;= 1602 + 0.364\frac{62.4}{68.8}(1730 - 1732) \\
   &amp;= 1601.34
\end{align*}\]</span>
and variance
<span class="math display">\[
   \sigma_2^2(1 - \rho^2) = 62.4^2(1 - 0.364^2) = 377.85.
\]</span>
In summary, <span class="math inline">\(W \mid  (H = 1730) \sim N(1601.34, 3377.85)\)</span>.
Note that this conditional distribution has a univariate normal distribution, and so probabilities such as <span class="math inline">\(W &gt; 1730\)</span> are easily determined.
Then,
<span class="math display">\[\begin{align*}
   \Pr(W &gt; 1730 \mid H = 1730)
   &amp;= \Pr\left( Z &gt; \frac{1730 - 1601.34}{\sqrt{3377.85}}\right) \\
   &amp;= \Pr( Z &gt; 2.2137)\\
   &amp;= 0.013.
\end{align*}\]</span>
Approximately <span class="math inline">\(1.3\)</span>% of males <span class="math inline">\(173\,\text{cm}\)</span> tall had married women taller than themselves in the UK in 1980.</p>
</div>
<div class="figure">
<span style="display:block;" id="fig:HtsPlots"></span>
<img src="08-SpecificContinuous_files/figure-html/HtsPlots-1.png" alt="Plots of the heights data." width="100%"><p class="caption">
FIGURE 8.11: Plots of the heights data.
</p>
</div>
<pre><code>#&gt; INSIDE</code></pre>
<p></p>
</div>
<div id="OtherContinuousDistributions" class="section level2" number="8.9">
<h2>
<span class="header-section-number">8.9</span> Other notable continuous distributions<a class="anchor" aria-label="anchor" href="#OtherContinuousDistributions"><i class="fas fa-link"></i></a>
</h2>
<p>The distributions discussed in this chapter are standard and commonly-used continuous distributions.
The <em>continuous uniform distribution</em> is used to model complete randomness when all values in an interval are equally likely.
Generally, computers can only generate continuous uniform (pseudo-) random numbers; random numbers from other distributions must be produced by transforming (pseudo-) random number produced from a <em>continuous uniform distribution</em>.</p>
<p>The <em>normal distribution</em> is the most well-known continuous distribution <em>often kown as the ‘bell-shaped curve’)
It is defined over the entire real line.
Many natural processes, and many measurement errors, have a normal distribution.
Importantly, it is often used in statistics, due to its importance in the </em>Central Limit Theorem*.</p>
<p>Many natural process are onky defined for non-negative values, rather than over the entire real line (such as heights, times and distances).
The <em>exponential</em> and <em>gamma</em> distributions are defined over a suitable region.
The <em>exponential distribution</em> is right-skewed, and often used for modelling waiting times between Poisson arrivals, and the time between memoryless events.
The <em>gamma distribution</em> is more flexible than the exponential distribution, and is often used ot model insurance claims, rainfall, and waiting times.
The exponential distribution is a special case of the gamma distribution.</p>
<p>The <em>beta distribution</em> is used for modelling proportions (or probabilities) that are not counts of a fied number (when a <em>binomial distribution</em> is appropriate), such as cloud cover, fractional resource consumption, etc.</p>
<p>Countless other useful discrete distributions exist; we mentioned a few.
The <em>Weibull distribution</em> is defined on <span class="math inline">\([0, \infty)\)</span> (notice this <em>includes</em> zero) and is used to model lifetimes and failures, and is used in reliability analysis and survival analysis.</p>
<p>The <em>von Mises</em> distribution is used to model angles, and is defined on <span class="math inline">\([-\pi, \pi)\)</span>; it is sometimes called the ‘circular normal distribution’.
It is used to model wind directions and animal movements.</p>
<p>The <em>Cauchy distribution</em> is defined on the entire real-line, but has heavier tails than the normal distribution.
It is used to model the <em>ratio</em> of two independent normal variables.</p>
<p>The <em>lognormal distribution</em> is the a right-skewed distribution defined on the positive real numbers.
If <span class="math inline">\(\log X\sim N(\mu, \sigma^2)\)</span>, then <span class="math inline">\(X\)</span> has a lognormal distribution.
It is used to model incomes and stock prices (using the Black–Scholes equation).</p>
<p>The <em>arcsine distribution</em> is a special case of the beta distribution and hence defined on <span class="math inline">\((0, 1)\)</span>, with probability concentrated near the limits of the range at <span class="math inline">\(x = 0\)</span> and <span class="math inline">\(x = 1\)</span>.</p>
<p>Numerous other continuous distributions emerge when studying sampling (Chap. <a href="SamplingDistributions.html#SamplingDistributions">12</a>), and are usually related to the normal distribution.
The <em><span class="math inline">\(t\)</span>-distribution</em> is similar to a normal distribution (and defined on the entire real line), but with heavier tals.
The <em><span class="math inline">\(\chi^2\)</span> distribution</em>, defined on <span class="math inline">\((0, \infty)\)</span>, is related to the sums of independent squared normal distributions.
The <em><span class="math inline">\(F\)</span>-distribution</em>, defined on <span class="math inline">\((0, \infty)\)</span> is related to the ratio of independent <span class="math inline">\(\chi^2\)</span> distributions.</p>
</div>
<div id="SimulationContinuous" class="section level2" number="8.10">
<h2>
<span class="header-section-number">8.10</span> Simulation<a class="anchor" aria-label="anchor" href="#SimulationContinuous"><i class="fas fa-link"></i></a>
</h2>
<div id="examples" class="section level3" number="8.10.1">
<h3>
<span class="header-section-number">8.10.1</span> Examples<a class="anchor" aria-label="anchor" href="#examples"><i class="fas fa-link"></i></a>
</h3>
<p>As with discrete distributions (Sect. <a href="DiscreteDistributions.html#SimulationDiscrete">7.11</a>), simulation can be used with continuous distributions.
Again, in <strong>R</strong>, random numbers from a specific distribution use functions that start with the letter <code>r</code>; for example, to generate random numbers from a normal distribution, use <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code>:</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">3</span>, <span class="co"># Generate three random numbers...</span></span>
<span>      mean <span class="op">=</span> <span class="fl">4</span>,     <span class="co"># ... with mean = 4</span></span>
<span>      sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>       <span class="co"># ... with sd = 2</span></span>
<span><span class="co">#&gt; [1] 1.748524 4.082457 2.624341</span></span></code></pre></div>
<p>Suppose we are seeking women over <span class="math inline">\(173\,\text{cm}\)</span> tall for a study; what percentage of women are over <span class="math inline">\(173\,\text{cm}\)</span> tall?
Assume that adult females have heights modelled by a normal distribution with mean <span class="math inline">\(163\,\text{cm}\)</span> and a standard deviation of <span class="math inline">\(5\,\text{cm}\)</span> <span class="citation">(<a href="references.html#ref-data:ABS1995:MeasureUp">Australian Bureau of Statistics 1995</a>)</span>.
The percentage taller than <span class="math inline">\(173\,\text{cm}\)</span> is:</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">173</span>, mean <span class="op">=</span> <span class="fl">163</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.02275013</span></span></code></pre></div>
<p>Simulations can also be used, which allows us to consider more complex situations.
For this simple question initially (Fig. <a href="ContinuousDistributions.html#fig:HeightSimHistograms">8.12</a>, left panel):</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">htW</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>,  <span class="co"># One thousand women</span></span>
<span>             mean <span class="op">=</span> <span class="fl">163</span>,  <span class="co"># Mean ht</span></span>
<span>             sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>      <span class="co"># Sd of height</span></span>
<span><span class="va">pcTallWomen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">htW</span> <span class="op">&gt;</span> <span class="fl">173</span> <span class="op">)</span><span class="op">/</span><span class="fl">1000</span> <span class="op">*</span> <span class="fl">100</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Percentage 'tall' women:"</span>, <span class="va">pcTallWomen</span>, <span class="st">'%\n'</span><span class="op">)</span></span>
<span><span class="co">#&gt; Percentage 'tall' women: 2.3 %</span></span></code></pre></div>
<p>Now consider a more complex situation.
Suppose adult males have heights with a mean of <span class="math inline">\(175\,\text{cm}\)</span> with standard deviation of <span class="math inline">\(7\,\text{cm}\)</span>, and constitute <span class="math inline">\(44\)</span>% of the population.
Now, we are seeking women <em>or</em> men over <span class="math inline">\(173\,\text{cm}\)</span> tall (Fig. <a href="ContinuousDistributions.html#fig:HeightSimHistograms">8.12</a>, right panel):</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">personSex</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="fl">1000</span>,  <span class="co"># Select sex of each person</span></span>
<span>                    <span class="fl">1</span>,</span>
<span>                    <span class="fl">0.44</span><span class="op">)</span> <span class="co"># So 0 = Female; 1 = Male</span></span>
<span></span>
<span><span class="va">htP</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>,  <span class="co"># change ht parameters according to sex</span></span>
<span>             mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">personSex</span> <span class="op">==</span> <span class="fl">1</span>,</span>
<span>                           <span class="fl">175</span>,</span>
<span>                           <span class="fl">163</span><span class="op">)</span>,</span>
<span>             sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">personSex</span> <span class="op">==</span> <span class="fl">1</span>,</span>
<span>                         <span class="fl">7</span>, </span>
<span>                         <span class="fl">5</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">pcTallPeople</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">htP</span> <span class="op">&gt;</span> <span class="fl">173</span> <span class="op">)</span><span class="op">/</span><span class="fl">1000</span> <span class="op">*</span> <span class="fl">100</span></span>
<span><span class="va">pcFemales</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span> <span class="va">personSex</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">)</span> <span class="op">/</span> <span class="fl">1000</span> <span class="op">*</span> <span class="fl">100</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Percentage 'tall' people:"</span>, <span class="va">pcTallPeople</span>, <span class="st">'%\n\n'</span><span class="op">)</span></span>
<span><span class="co">#&gt; Percentage 'tall' people: 28.1 %</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Percentage females:"</span>, <span class="va">pcFemales</span>, <span class="st">'%\n\n'</span><span class="op">)</span></span>
<span><span class="co">#&gt; Percentage females: 56.8 %</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Percentage of 'tall' people that are female:"</span>, </span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">htP</span> <span class="op">&gt;</span> <span class="fl">173</span> <span class="op">&amp;</span> <span class="va">personSex</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">htP</span> <span class="op">&gt;</span> <span class="fl">173</span><span class="op">)</span> <span class="op">*</span> <span class="fl">100</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>    <span class="st">'%\n\n'</span><span class="op">)</span></span>
<span><span class="co">#&gt; Percentage of 'tall' people that are female: 4.3 %</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Variance of heights: "</span>, <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">htP</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Variance of heights:  74.2899</span></span></code></pre></div>
<div class="figure">
<span style="display:block;" id="fig:HeightSimHistograms"></span>
<img src="08-SpecificContinuous_files/figure-html/HeightSimHistograms-1.png" alt="The distribution of heights of women (left panel) and men and women combined (right panel)." width="90%"><p class="caption">
FIGURE 8.12: The distribution of heights of women (left panel) and men and women combined (right panel).
</p>
</div>
</div>
<div id="relationships-between-distributions" class="section level3" number="8.10.2">
<h3>
<span class="header-section-number">8.10.2</span> Relationships between distributions<a class="anchor" aria-label="anchor" href="#relationships-between-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>As seen before (Sect. <a href="DistributionRandomVariables.html#RVsStatisticalComputing">3.7</a>), many statistical distributions are generated from existing distributions.
These relationships can be shown using computer simulation.</p>
<p>As an example, the gamma distribution is related to the exponential distribution.
If a random variable <span class="math inline">\(Y\)</span> has an exponential distribution with rate parameter <span class="math inline">\(\lambda\)</span>, then the distribution of
<span class="math display">\[
  X = \sum_{i = 1}^k Y
\]</span>
has a gamma distribution, with shape parameter <span class="math inline">\(\alpha = k\)</span> and rate parameter <span class="math inline">\(\lambda\)</span>.
This can be shown using simulation (Fig. <a href="ContinuousDistributions.html#fig:GammaExpSimFig">8.13</a>):</p>
<div class="sourceCode" id="cb75"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">67433</span><span class="op">)</span></span>
<span></span>
<span><span class="co">### An exponential variate with  rate = 2 </span></span>
<span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5000</span>,</span>
<span>          rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span> data <span class="op">=</span> <span class="va">Y</span>,</span>
<span>             ncol <span class="op">=</span> <span class="fl">5</span>, <span class="co"># Place 5 values in each of 1000 rows</span></span>
<span>             nrow <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="co"># Sum five values in each row</span></span>
<span></span>
<span><span class="co">### Set up for two plots, side-by-side</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span> <span class="op">)</span></span>
<span></span>
<span><span class="co">### Plot two histograms: Y and X</span></span>
<span><span class="co">###  truehist  is part of the MASS package,which must be loaded first, using: </span></span>
<span><span class="co">###  library(MASS)</span></span>
<span><span class="fu">truehist</span><span class="op">(</span><span class="va">Y</span>,</span>
<span>         las <span class="op">=</span> <span class="fl">1</span>,</span>
<span>         main <span class="op">=</span> <span class="st">"Exponential density"</span>,</span>
<span>         xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">italic</span><span class="op">(</span><span class="va">Y</span><span class="op">)</span> <span class="op">)</span>,</span>
<span>         ylab <span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span></span>
<span><span class="fu">truehist</span><span class="op">(</span><span class="va">X</span>,</span>
<span>         las <span class="op">=</span> <span class="fl">1</span>,</span>
<span>         main <span class="op">=</span> <span class="st">"Gamma density"</span>,</span>
<span>         xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html">expression</a></span><span class="op">(</span><span class="fu">italic</span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op">)</span>,</span>
<span>         ylab <span class="op">=</span> <span class="st">"Density"</span><span class="op">)</span></span>
<span></span>
<span><span class="co">### Now plot the theoretical gamma distribution</span></span>
<span><span class="co"># Use these values of X:</span></span>
<span><span class="va">x_Plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>,</span>
<span>              length <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span>
<span><span class="co"># Add lines to the histogram of chi-square random values</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html">lines</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x_Plot</span>, shape <span class="op">=</span> <span class="fl">5</span>, rate <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">~</span> <span class="va">x_Plot</span>,</span>
<span>       type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>       lwd <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="co"># dgamma()  is the density function for a gamma distribution</span></span></code></pre></div>
<div class="figure" style="text-align: centre">
<span style="display:block;" id="fig:GammaExpSimFig"></span>
<img src="08-SpecificContinuous_files/figure-html/GammaExpSimFig-1.png" alt="Left: histogram of $5000$ simulated values from an exponential distribution. Right: histogram of the sum of five independent exponential distributions. The solid lines on the right panel is the theoretical distribution of a gamma distribution with a shape parameter of\ $5$." width="100%"><p class="caption">
FIGURE 8.13: Left: histogram of <span class="math inline">\(5000\)</span> simulated values from an exponential distribution. Right: histogram of the sum of five independent exponential distributions. The solid lines on the right panel is the theoretical distribution of a gamma distribution with a shape parameter of <span class="math inline">\(5\)</span>.
</p>
</div>
</div>
</div>
<div id="ContinuousExercises" class="section level2" number="8.11">
<h2>
<span class="header-section-number">8.11</span> Exercises<a class="anchor" aria-label="anchor" href="#ContinuousExercises"><i class="fas fa-link"></i></a>
</h2>
<p>Selected answers appear in Sect. <a href="selected-solutions.html#AnswersChapContinuousDistributions">E.8</a>.</p>
<div class="exercise">
<p><span id="exr:BetaRepara" class="exercise"><strong>Exercise 8.1  </strong></span>Write the beta distribution parameters <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span> in terms of the mean and variance.</p>
</div>
<div class="exercise">
<p><span id="exr:SpeedSimUnif" class="exercise"><strong>Exercise 8.2  </strong></span>In a study modelling pedestrian road-crossing behaviour <span class="citation">(<a href="references.html#ref-shaaban2017agent">Shaaban and Abdel-Warith 2017</a>)</span>, the uniform distribution is used in the simulation to model the vehicle speeds.
The speeds have a minimum value of <span class="math inline">\(30\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>, and a maximum value of <span class="math inline">\(72\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>.</p>
<ol style="list-style-type: decimal">
<li>Using this model, compute the mean and standard deviation of vehicle speeds.</li>
<li>Compute and plot the PDF and distribution function.</li>
<li>If <span class="math inline">\(X\)</span> is the vehicle speed, compute <span class="math inline">\(\Pr(X &gt; 60)\)</span>, where <span class="math inline">\(60\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup> is the posted speed limit.</li>
<li>Compute <span class="math inline">\(\Pr(X &gt; 65\mid X &gt; 60)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:SpeedSimNorm" class="exercise"><strong>Exercise 8.3  </strong></span>In a study modelling pedestrian road-crossing behaviour <span class="citation">(<a href="references.html#ref-shaaban2017agent">Shaaban and Abdel-Warith 2017</a>)</span>, the normal distribution is used in the simulation to model the vehicle speeds.
The normal model has a mean of <span class="math inline">\(48\)</span> km/h, with a standard deviation<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Although the article calls it the ‘variance’…&lt;/p&gt;"><sup>2</sup></a> of <span class="math inline">\(8.8\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>.</p>
<ol style="list-style-type: decimal">
<li>The article ignores all vehicles travelling slower than <span class="math inline">\(30\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup> and faster than <span class="math inline">\(72\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>.
What proportion of vehicles are excluded using this criterion?</li>
<li>Write the PDF for this truncated normal distribution.</li>
<li>Plot the PDF and df for this truncated normal distribution.</li>
<li>Compute the mean and variance for this truncated normal distribution.</li>
<li>Suppose a vehicle is caught speeding (i.e., exceeding <span class="math inline">\(60\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>); what is the probability that the vehicle is exceeding the speed limit by less than <span class="math inline">\(5\)</span> km.h<sup><span class="math inline">\(-1\)</span></sup>?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ConcreteDiffusion" class="exercise"><strong>Exercise 8.4  </strong></span>A study of the service life of concrete in various conditions <span class="citation">(<a href="references.html#ref-liu2012stochastic">Liu and Shi 2012</a>)</span> modelled the diffusion coefficients using a gamma distribution, with <span class="math inline">\(\alpha = 27.05\)</span> and <span class="math inline">\(\beta = 1.42\)</span> (unitless).</p>
<ol style="list-style-type: decimal">
<li>Plot the PDF and df.</li>
<li>Determine the mean and standard deviation of the chloride diffusion coefficients that were used in the simulation.</li>
<li>If <span class="math inline">\(C\)</span> represents the chloride diffusion coefficients, compute <span class="math inline">\(\Pr(C &gt; 30\mid C &lt; 50)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ConcreteSurfaceCholride" class="exercise"><strong>Exercise 8.5  </strong></span>A study of the service life of concrete in various conditions <span class="citation">(<a href="references.html#ref-liu2012stochastic">Liu and Shi 2012</a>)</span> used normal distributions to model the surface chloride concentrations.
In one model, the mean was set as <span class="math inline">\(\mu = 2\)</span> kg.m<sup><span class="math inline">\(-3\)</span></sup> and the standard deviation as <span class="math inline">\(\sigma = 0.2\)</span> kg.m<sup><span class="math inline">\(-3\)</span></sup>.</p>
<ol style="list-style-type: decimal">
<li>Plot the PDF and df.</li>
<li>Let <span class="math inline">\(Y\)</span> be the surface chloride concentration.
Compute <span class="math inline">\(\Pr(Y &gt; 2.4)\)</span>.</li>
<li>
<span class="math inline">\(80\)</span>% of the time, surface chloride concentrations are below what value?</li>
<li>
<span class="math inline">\(15\)</span>% of the time, surface chloride concentrations exceed what value?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Kumaraswamy" class="exercise"><strong>Exercise 8.6  </strong></span>An alternative to the beta distribution with a closed form is the <em>Kumaraswamy distribution</em>, with PDF
<span class="math display">\[
   p_X(x) =
   \begin{cases}
      ab x^{a - 1} (1 - x^a)^{b - 1} &amp; \text{for $0 &lt; x &lt; 1$};\\
      0                              &amp; \text{elsewhere}
   \end{cases}
\]</span>
for <span class="math inline">\(a &gt; 0\)</span> and <span class="math inline">\(b &gt; 0\)</span>.
We write <span class="math inline">\(X\sim \text{Kumaraswamy}(a, b)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot some densities for the Kumaraswamy distribution showing its different shapes.</li>
<li>Show that the df is <span class="math inline">\(F_X(x) = 1 - (1 - x^a)^b\)</span> for <span class="math inline">\(0 &lt; x &lt; 1\)</span>.
Plot the distribution functions corresponding to the PDFs in Part 1.</li>
<li>If <span class="math inline">\(X\sim \text{Kumaraswamy}(a, 1)\)</span>, then show that <span class="math inline">\(X\sim \text{Beta}(a, 1)\)</span>.</li>
<li>If <span class="math inline">\(X\sim \text{Kumaraswamy}(1, 1)\)</span>, then show that <span class="math inline">\(X\sim \text{Unif}(0, 1)\)</span>.</li>
<li>If <span class="math inline">\(X\sim \text{Kumaraswamy}(a, 1)\)</span>, then show that <span class="math inline">\((1 - X) \sim \text{Kumaraswamy}(1, a)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:GammaCV" class="exercise"><strong>Exercise 8.7  </strong></span>Show that the gamma distribution has a constant <em>coefficient of variation</em>, where the <em>coefficient of variation</em> is the standard deviation divided by the mean.</p>
</div>
<div class="exercise">
<p><span id="exr:BetaHospital" class="exercise"><strong>Exercise 8.8  </strong></span>In a study modelling waiting times at a hospital <span class="citation">(<a href="references.html#ref-khadem2008evaluating">Khadem et al. 2008</a>)</span>, patients are classified into one of three categories:</p>
<ul>
<li>Red: Critically ill or injured patients.</li>
<li>Yellow: Moderately ill or
injured patients.</li>
<li>Green: Minimally injured or
uninjured patients.</li>
</ul>
<p>For ‘Green’ patients, the service time <span class="math inline">\(S\)</span> was modelled as <span class="math inline">\(S = 4.5 + 11V\)</span>, where <span class="math inline">\(V \sim \text{Beta}(0.287, 0.926)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Find the mean and standard deviation of the service times <span class="math inline">\(S\)</span>.</li>
<li>Produce well-labelled plots of the PDF and distribution function of <span class="math inline">\(V\)</span>, showing important features.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ExpHospital" class="exercise"><strong>Exercise 8.9  </strong></span>In a study modelling waiting times at a hospital <span class="citation">(<a href="references.html#ref-khadem2008evaluating">Khadem et al. 2008</a>)</span>, patients are classified into one of three categories:</p>
<ul>
<li>Red: Critically ill or injured patients.</li>
<li>Yellow: Moderately ill or
injured patients.</li>
<li>Green: Minimally injured or
uninjured patients.</li>
</ul>
<p>The time (in minutes) spent in the reception are for ‘Yellow’ patients, say <span class="math inline">\(T\)</span>, is modelled as <span class="math inline">\(T = 0.5 + W\)</span>, where <span class="math inline">\(W\sim \text{Exp}(\beta = 16.5)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Find the mean and standard deviation of the waiting times <span class="math inline">\(T\)</span>.</li>
<li>Plot the PDF and distribution function of <span class="math inline">\(W\)</span>.</li>
<li>Determine <span class="math inline">\(\Pr(T &gt; 1)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:NormalHospital" class="exercise"><strong>Exercise 8.10  </strong></span>In a study modelling waiting times at a hospital <span class="citation">(<a href="references.html#ref-khadem2008evaluating">Khadem et al. 2008</a>)</span>, patients are classified into one of three categories:</p>
<ul>
<li>Red: Critically ill or injured patients.</li>
<li>Yellow: Moderately ill or
injured patients.</li>
<li>Green: Minimally injured or
uninjured patients.</li>
</ul>
<p>The time (in minutes) spent in the reception are for ‘Green’ patients, say <span class="math inline">\(T\)</span>, is modelled as a normal with mean <span class="math inline">\(\mu = 45.4\,\text{mins}\)</span> and standard deviation <span class="math inline">\(\sigma = 23.4\,\text{mins}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Find the mean and standard deviation of the waiting times <span class="math inline">\(T\)</span>.</li>
<li>Plot the PDF and distribution function of <span class="math inline">\(T\)</span>.</li>
<li>What proportion of ‘Green’ patients wait longer than an hour?</li>
<li>How long to the slowest <span class="math inline">\(10\)</span>% of patients need to wait?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:GammaRain" class="exercise"><strong>Exercise 8.11  </strong></span>In a study of rainfall <span class="citation">(<a href="references.html#ref-watterson2003simulated">Watterson and Dix 2003</a>)</span>, rainfall <em>on wet days</em> in SE Australia (37<sup><span class="math inline">\(\circ\)</span></sup>S; 146<sup><span class="math inline">\(\circ\)</span></sup>E) was simulated using a gamma distribution with <span class="math inline">\(\alpha = 0.62\)</span> and <span class="math inline">\(\beta = 7.1\)</span>mm.</p>
<ol style="list-style-type: decimal">
<li>Rainfall below <span class="math inline">\(0.0017\,\text{mm}\)</span> cannot be recorded by the equipment used.
What proportion of days does this represent?</li>
<li>Plot the PDF and df.</li>
<li>What is the probability that more than <span class="math inline">\(3\,\text{mm}\)</span> falls <em>on a wet day</em>?</li>
<li>The proportion of wet days is <span class="math inline">\(0.43\)</span>.
What proportion <em>of all days</em> receive more than <span class="math inline">\(3\,\text{mm}\)</span>?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:DisaggregationDuration" class="exercise"><strong>Exercise 8.12  </strong></span>In a study of rainfall disaggregation <span class="citation">(<a href="references.html#ref-connolly1998daily">Connolly, Schirmer, and Dunn 1998</a>)</span> (extracting small-scale rainfall features from large-scale measurements), the duration (in fractions of day) of non-overlapping rainfall events per day at Katherine was modelled using a Gamma distribution with <span class="math inline">\(\alpha = 2\)</span>, and <span class="math inline">\(\beta = 0.04\)</span> in summer and <span class="math inline">\(\beta = 0.03\)</span> in winter.</p>
<p>Denote the duration of rainfall events, in fractions of a day, be denoted in summer as <span class="math inline">\(S\)</span>, and in winter as <span class="math inline">\(W\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the rainfall event duration distributions, and compare summer and winter.</li>
<li>What is the probability of a rainfall event lasting more than <span class="math inline">\(6\,\text{h}\)</span> in winter?</li>
<li>What is the probability of a rainfall event lasting more than <span class="math inline">\(6\,\text{h}\)</span> in summer?</li>
<li>Describe what is <em>meant</em> by the statement <span class="math inline">\(\Pr(S &gt; 3/24 \mid S &gt; 1/24)\)</span>, and compute the probability.</li>
<li>Describe what is <em>meant</em> by the statement <span class="math inline">\(\Pr(W &lt; 2/24 \mid W &gt; 1/24)\)</span>, and compute the probability.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:DisaggregationDuration2" class="exercise"><strong>Exercise 8.13  </strong></span>In a study of rainfall disaggregation <span class="citation">(<a href="references.html#ref-connolly1998daily">Connolly, Schirmer, and Dunn 1998</a>)</span> (extracting small-scale rainfall features from large-scale measurements), the starting time of the first rainfall event at Katherine each day (scaled from 0 to 1) was modelled using a beta distribution with parameters <span class="math inline">\((1.16, 1.50)\)</span> in summer and <span class="math inline">\((0.44, 0.56)\)</span> in winter.</p>
<p>Denote the number of rainfall events in summer as <span class="math inline">\(S\)</span>, and in winter as <span class="math inline">\(W\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the two starting-time distributions, and compare summer and winter.</li>
<li>Compute the mean and standard deviation of starting <em>times</em> for both seasons.</li>
<li>What is the probability that the first rain event in winter is after 6am?</li>
<li>What is the probability that the first rain event in summer is after 6am?</li>
<li>Describe what is meant by the statement <span class="math inline">\(\Pr(S &gt; 3 \mid S &gt; 1)\)</span>, and compute the probability.</li>
<li>Describe what is meant by the statement <span class="math inline">\(\Pr(W &gt; 2 \mid W &gt; 1)\)</span>, and compute the probability.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Diarrhoea" class="exercise"><strong>Exercise 8.14  </strong></span>A study of the impact of diarrhoea <span class="citation">(<a href="references.html#ref-schmidt2009simulation">Schmidt, Genser, and Chalabi 2009</a>)</span> used a gamma distribution to model the duration of symptoms.
In Guatemala, duration (in days) was modelled using a gamma distribution with <span class="math inline">\(\alpha = 1.11\)</span> and <span class="math inline">\(\beta = 3.39\)</span>.
Let <span class="math inline">\(X\)</span> refer to the duration of symptoms.</p>
<ol style="list-style-type: decimal">
<li>Compute the mean and standard deviation of the duration.</li>
<li>The value of <span class="math inline">\(\alpha\)</span> is close to one.
Plot the PDF of the gamma distribution and the near-equivalent exponential distribution, and comment.</li>
<li>Compute <span class="math inline">\(\Pr(X &gt; 4)\)</span> using both the gamma and exponential distributions, and comment.</li>
<li>The patients in the <span class="math inline">\(5\)</span>% with symptoms the longest had symptoms for how long?
Again, compare both models, and comment.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:NormalLeaveTime" class="exercise"><strong>Exercise 8.15  </strong></span>In a study of office occupancy at a university <span class="citation">(<a href="references.html#ref-luo2017performance">Luo et al. 2017</a>)</span>, the leaving-times of professors were modelled as a normal distribution, with a mean leaving time of 6pm, with a standard deviation of <span class="math inline">\(1.5\,\text{h}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Using this model, what proportion of professors leave before 5pm?</li>
<li>Suppose a professor is still at work at 5pm; what is the probability that the professor leaves after 7pm?</li>
<li>The latest-leaving <span class="math inline">\(15\)</span>% of professors leave after what time?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:BetaClay" class="exercise"><strong>Exercise 8.16  </strong></span>The percentage of clay content in soil has been modelled using a beta distribution.
In one study <span class="citation">(<a href="references.html#ref-haskett1995use">Haskett, Pachepsky, and Acock 1995</a>)</span>, two counties in Iowa were modelled with beta-distributions: County A with parameters <span class="math inline">\(m = 11.52\)</span> and <span class="math inline">\(n = 4.75\)</span>, and County B with parameters <span class="math inline">\(m = 3.85\)</span> and <span class="math inline">\(n = 3.65\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the two distributions, and comment (in context).</li>
<li>Compute the mean and standard deviation of each county.</li>
<li>What percentage of soil samples exceed <span class="math inline">\(50\)</span>% clay in the two counties?
Comment.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-54" class="exercise"><strong>Exercise 8.17  </strong></span>A study of water uptake in plants in grasssland and savanna ecosystems <span class="citation">(<a href="references.html#ref-nippert2015challenging">Nippert and Holdo 2015</a>)</span> used a beta distribution to model the distribution of root depth <span class="math inline">\(D\)</span>.
The MRD (maximum root density) was <span class="math inline">\(70\,\text{cm}\)</span>, so the beta distribution used was defined over the interval <span class="math inline">\([0, 70]\)</span>.
For one simulation, the beta-distribution parameters were <span class="math inline">\(m = 1\)</span> and <span class="math inline">\(n = 5\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the PDF, and explain what it means in this context.</li>
<li>Determine the probability that the root depth was deeper than <span class="math inline">\(50\,\text{cm}\)</span>.</li>
<li>Determine the root depth of the plants with the deepest <span class="math inline">\(20\)</span>% of roots.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-55" class="exercise"><strong>Exercise 8.18  </strong></span>Suppose that the measured voltage in a certain electrical circuit has a normal distribution with mean <span class="math inline">\(120\,\text{V}\)</span> and standard deviation <span class="math inline">\(2\,\text{V}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>What is the probability that a measurement will be between <span class="math inline">\(116\)</span> and <span class="math inline">\(118\,\text{V}\)</span>?</li>
<li>If five independent measurements of the voltage are made, what is the probability that three of the five measurements will be between <span class="math inline">\(116\)</span> and <span class="math inline">\(118\,\text{V}\)</span>?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-56" class="exercise"><strong>Exercise 8.19  </strong></span>A firm buys <span class="math inline">\(500\)</span> identical components, whose failure times are independent and exponentially distributed with mean <span class="math inline">\(100\,\text{h}\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Determine the probability that one component will survive at least <span class="math inline">\(150\,\text{h}\)</span>.</li>
<li>What is the probability that at least <span class="math inline">\(125\)</span> components will survive at least <span class="math inline">\(150\,\text{h}\)</span>?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Headway" class="exercise"><strong>Exercise 8.20  </strong></span>A <em>headway</em> is the time gap (front-bumper to front-bumper) separating consecutive motor vehicles in a lane of road traffic.
Suppose headways <span class="math inline">\(X\)</span> (in seconds) on a section of a traffic lane are described by a <em>shifted gamma distribution</em>, with PDF
<span class="math display">\[
   f_X(x) =
   \frac{1}{\beta^\alpha \Gamma(\alpha)}
   (x - \Delta)^{\alpha - 1}
   \exp\left( -(x - \Delta)/\beta\right)
   \quad\text{for $x &gt; \Delta$},
\]</span>
where <span class="math inline">\(\alpha = 2.5\)</span>, <span class="math inline">\(\beta = 0.8\)</span> and <span class="math inline">\(\Delta = 1.2\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Determine the theoretical mean and variance of this distribution.</li>
<li>Simulate <span class="math inline">\(1000\)</span> headways using <strong>R</strong>, and plot a histogram of the data.
Comment.</li>
<li>Using the simulation results, estimate the probability that a headway is within two standard deviations of the mean.</li>
<li>Confirm that Tchebyshev’s inequality holds for the above probability.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-57" class="exercise"><strong>Exercise 8.21  </strong></span>Another commonly-used distribution is the <em>Weibull distribution</em>:
<span class="math display">\[
   f_Y(y) = \frac{k}{\lambda} \left( \frac{x}{\lambda} \right)^{k - 1} \exp( -(x/\lambda)^k)\quad\text{for $x &gt; 0$},
\]</span>
where <span class="math inline">\(\lambda &gt; 0\)</span> is called a <em>scale parameter</em>, and <span class="math inline">\(k &gt; 0\)</span> is called a <em>shape parameter</em>.</p>
<ol style="list-style-type: decimal">
<li>Produce some sketches in <strong>R</strong> to show the variety on the shapes of the density function.</li>
<li>Derive the mean and variance of the Weibull distribution.</li>
<li>Derive the cdf for the Weibull distribution.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-58" class="exercise"><strong>Exercise 8.22  </strong></span><span class="citation">Raschke (<a href="references.html#ref-raschke2011empirical">2011</a>)</span> modelled the humidity at the Haarweg Wageningen (Netherlands) weather station in May 2007 and 2008 using beta distributions.
In May 2007, the relative humidity was modelled with a <span class="math inline">\(\text{Beta}(6.356, 1.970)\)</span> distribution; in May 2008, with the <span class="math inline">\(\text{Beta}(2.803, 1.456)\)</span> distribution.</p>
<ol style="list-style-type: decimal">
<li>With the given models, determine the mean and variance of the humidity for both months.</li>
<li>On the same graph, plot both distributions, and comment.</li>
<li>For May 2008, compute <span class="math inline">\(\Pr(X &gt; 60)\)</span>, where <span class="math inline">\(X\)</span> is the relative humidity, based on the model.</li>
<li>For May 2008, compute <span class="math inline">\(\Pr(X &gt; 60 \mid X &gt; 50)\)</span>, where <span class="math inline">\(X\)</span> is the relative humidity, based on the model.</li>
<li>For May 2008, <span class="math inline">\(80\)</span>% of days have a relative humidity less than what value, based on the model?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:SimulationGirlHeights" class="exercise"><strong>Exercise 8.23  </strong></span>Based on <span class="citation">Pfizer Australia (<a href="references.html#ref-data:AustralianGirls">2008</a>)</span>, the <em>mean</em> height <span class="math inline">\(Y\)</span> of Australian girls aged between <span class="math inline">\(2\)</span> and <span class="math inline">\(5\)</span> years of age based on their age <span class="math inline">\(X\)</span> is approximately given by
<span class="math display">\[
   \hat{y} = 7.5x + 70.
\]</span>
Similarly, the <em>standard deviation</em> <span class="math inline">\(s\)</span> of the heights at age <span class="math inline">\(x\)</span> is approximately given by
<span class="math display">\[
   s = 0.4575x + 1.515.
\]</span></p>
<ol style="list-style-type: decimal">
<li>Suppose that, Australia-wide, day-care facilities have <span class="math inline">\(32\)</span>% of children aged <span class="math inline">\(2\)</span>, <span class="math inline">\(33\)</span>% of children aged <span class="math inline">\(3\)</span>, <span class="math inline">\(25\)</span>% of children aged <span class="math inline">\(4\)</span>, and the remainder aged <span class="math inline">\(5\)</span>.
Use <strong>R</strong> to simulate the distribution of the heights of children at day-care facilities.</li>
<li>Using the normal distributions implied, what percentage of children are taller than <span class="math inline">\(100\,\text{cm}\)</span> for each age?</li>
<li>Use the simulation to determine the proportion of children taller than <span class="math inline">\(100\,\text{cm}\)</span>.</li>
<li>Use the simulation to determine the mean and <em>variance</em> of the height of the children at the day-care facility.</li>
<li>Use the simulation to determine the heights for the tallest <span class="math inline">\(15\)</span>% of children at the facility.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:TweedieVarFn" class="exercise"><strong>Exercise 8.24  </strong></span>Show that the variance of the normal, Poisson and gamma distributions can all be written in the form <span class="math inline">\(\operatorname{var}[X] = \phi \operatorname{E}[X]^p\)</span> for <span class="math inline">\(p = 0, 1\)</span> and <span class="math inline">\(2\)</span> respectively <span class="citation">(<a href="references.html#ref-mypapers:dunnsmyth:glms">Dunn and Smyth 2018</a>)</span>.
These are all speical cases of the <em>Tweedie distributions</em>.</p>
</div>
<div class="exercise">
<p><span id="exr:BetaCloud" class="exercise"><strong>Exercise 8.25  </strong></span><span class="citation">Chia and Hutchinson (<a href="references.html#ref-chia1991beta">1991</a>)</span> used the beta distribution to model cloud duration in Darwin, defined as (p. 195)</p>
<blockquote>
<p>…the fraction of observable daylight hours not receiving bright sunshine.</p>
</blockquote>
<p>In January, the fitted parameters were <span class="math inline">\(m = 0.859\)</span> and <span class="math inline">\(n = 0.768\)</span>; in July, the fitted parameters were <span class="math inline">\(m = 0.110\)</span> and <span class="math inline">\(b = 1.486\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot both PDFs on the same graph, and comment on what this tells you about cloud cover in Darwin</li>
<li>Writing <span class="math inline">\(C\)</span> for the cloud duration, compute <span class="math inline">\(\Pr(C &gt; 0.5)\)</span> for both January and July.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ContinuousSpinner" class="exercise"><strong>Exercise 8.26  </strong></span>Suppose a spinning wheel has a circumference of one metre, and at some point on the outer edge of the wheel is a point of interest (Fig. <a href="ContinuousDistributions.html#fig:OneMCircle">8.14</a>).</p>
<p>When the wheel is spun hard, what is the probability that the point finishes between locations <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> when it stops?</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:OneMCircle"></span>
<img src="08-SpecificContinuous_files/figure-html/OneMCircle-1.png" alt="A wheel to spin." width="40%"><p class="caption">
FIGURE 8.14: A wheel to spin.
</p>
</div>
<div class="exercise">
<p><span id="exr:BetaPrimeA" class="exercise"><strong>Exercise 8.27  </strong></span>Suppose a random variable <span class="math inline">\(Y\)</span> has a beta distribution (Sect. <a href="ContinuousDistributions.html#BetaDistribution">8.6</a>), which can be used for modelling proportions.
Proportions are related to <em>odds</em>, where
<span class="math display">\[
  \text{odds} = \frac{p}{1 - p}
\]</span>
for <span class="math inline">\(0 \le p &lt; 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Using simulation, find and plot the density function for the distribution of the odds for <span class="math inline">\(p = 0.5\)</span>.</li>
<li>Using simulation, find and plot the density function for the distribution of the odds for <span class="math inline">\(p = 0.25\)</span>.</li>
</ol>
<p>(This is the beta prime distribution.)</p>
</div>

</div>
</div>

<hr>
<div class="footer"><span style="color: gray; font-size:0.7em">Peter K. Dunn, 2024: <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span></div>
  <div class="chapter-nav">
<div class="prev"><a href="DiscreteDistributions.html"><span class="header-section-number">7</span> Standard discrete distributions</a></div>
<div class="next"><a href="ChapterMixedDistributions.html"><span class="header-section-number">9</span> Mixed distributions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ContinuousDistributions"><span class="header-section-number">8</span> Standard continuous distributions</a></li>
<li><a class="nav-link" href="#introduction-2"><span class="header-section-number">8.1</span> Introduction</a></li>
<li><a class="nav-link" href="#ContinuousUniform"><span class="header-section-number">8.2</span> Continuous uniform distribution</a></li>
<li>
<a class="nav-link" href="#Normal"><span class="header-section-number">8.3</span> Normal distribution</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#NormalUsual"><span class="header-section-number">8.3.1</span> Definition and properties</a></li>
<li><a class="nav-link" href="#StandardNormal"><span class="header-section-number">8.3.2</span> The standard normal distribution</a></li>
<li><a class="nav-link" href="#FindNormalProbs"><span class="header-section-number">8.3.3</span> Determining normal probabilities</a></li>
<li><a class="nav-link" href="#NormalApproxBinomial"><span class="header-section-number">8.3.4</span> Normal approximation to the binomial</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#ExponentialDistribution"><span class="header-section-number">8.4</span> Exponential distribution</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ExponentialDerivation"><span class="header-section-number">8.4.1</span> Derivation</a></li>
<li><a class="nav-link" href="#ExponentialDefinition"><span class="header-section-number">8.4.2</span> Definition and properties</a></li>
</ul>
</li>
<li><a class="nav-link" href="#GammaDistribution"><span class="header-section-number">8.5</span> Gamma distribution</a></li>
<li><a class="nav-link" href="#BetaDistribution"><span class="header-section-number">8.6</span> Beta distribution</a></li>
<li><a class="nav-link" href="#TransformationsChiSquared"><span class="header-section-number">8.7</span> The chi-squared distribution</a></li>
<li><a class="nav-link" href="#BVNormalDistribution"><span class="header-section-number">8.8</span> The bivariate normal distribution</a></li>
<li><a class="nav-link" href="#OtherContinuousDistributions"><span class="header-section-number">8.9</span> Other notable continuous distributions</a></li>
<li>
<a class="nav-link" href="#SimulationContinuous"><span class="header-section-number">8.10</span> Simulation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#examples"><span class="header-section-number">8.10.1</span> Examples</a></li>
<li><a class="nav-link" href="#relationships-between-distributions"><span class="header-section-number">8.10.2</span> Relationships between distributions</a></li>
</ul>
</li>
<li><a class="nav-link" href="#ContinuousExercises"><span class="header-section-number">8.11</span> Exercises</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PeterKDunn/DistTheory/blob/main/08-SpecificContinuous.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PeterKDunn/DistTheory/edit/main/08-SpecificContinuous.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>The Theory of Statistical Distributions</strong>" was written by Peter K. Dunn. It was last built on Last updated: 2025-12-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
