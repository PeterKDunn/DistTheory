<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>11 Expectations for multivariate distributions* | The Theory of Statistical Distributions</title>
<meta name="author" content="Peter K. Dunn">
<meta name="description" content="11.1 Expectation Results involving expectations naturally generalise from the bivariate to the multivariate case. Firstly, the expectation of a linear combination of random variables. Theorem 11.1...">
<meta name="generator" content="bookdown 0.45 with bs4_book()">
<meta property="og:title" content="11 Expectations for multivariate distributions* | The Theory of Statistical Distributions">
<meta property="og:type" content="book">
<meta property="og:description" content="11.1 Expectation Results involving expectations naturally generalise from the bivariate to the multivariate case. Firstly, the expectation of a linear combination of random variables. Theorem 11.1...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="11 Expectations for multivariate distributions* | The Theory of Statistical Distributions">
<meta name="twitter:description" content="11.1 Expectation Results involving expectations naturally generalise from the bivariate to the multivariate case. Firstly, the expectation of a linear combination of random variables. Theorem 11.1...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><script src="libs/rglWebGL-binding-1.3.31/rglWebGL.js"></script><link href="libs/rglwidgetClass-1.3.31/rgl.css" rel="stylesheet">
<script src="libs/rglwidgetClass-1.3.31/rglClass.min.js"></script><script src="libs/CanvasMatrix4-1.3.31/CanvasMatrix.min.js"></script><link rel="shortcut icon" href="icons/iconmonstr-chart-1-240.png">
<script>
    document.addEventListener('DOMContentLoaded', function() {
      // Find all R code blocks that should be toggleable.
      // Our Lua filter adds the 'r-code-box' class to the code block.
      var codeBlocks = document.querySelectorAll('.r-code-box');

      codeBlocks.forEach(function(codeBlock) {
        // Create the button element
        var button = document.createElement('button');
        button.textContent = 'Show R Code'; // Initial text for the button
        button.className = 'code-toggle-button'; // Assign CSS class

        // Insert the button directly before the code block.
        // The codeBlock's parentNode is the div.figure-with-code container.
        // We insert the button as a sibling of the codeBlock within that container.
        codeBlock.parentNode.insertBefore(button, codeBlock);

        // Hide the code block initially by default.
        codeBlock.style.display = 'none';

        // Add a click event listener to the button
        button.addEventListener('click', function() {
          if (codeBlock.style.display === 'none') {
            codeBlock.style.display = 'block'; // Show the code block
            button.textContent = 'Hide R Code'; // Change button text
          } else {
            codeBlock.style.display = 'none'; // Hide the code block
            button.textContent = 'Show R Code'; // Change button text back
          }
        });
      });
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/columns.css">
<link rel="stylesheet" href="html/largerDie.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">The Theory of Statistical Distributions</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li class="book-part">Theoretical foundations</li>
<li><a class="" href="ChapterSetTheory.html"><span class="header-section-number">1</span> Essentials of set theory</a></li>
<li><a class="" href="ChapterProbability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="" href="DistributionRandomVariables.html"><span class="header-section-number">3</span> Random variables and their distributions</a></li>
<li><a class="" href="ChapBivariate.html"><span class="header-section-number">4</span> Bivariate distributions</a></li>
<li><a class="" href="ChapExpectation.html"><span class="header-section-number">5</span> Mathematical expectation</a></li>
<li><a class="" href="ChapterTransformations.html"><span class="header-section-number">6</span> Transformations of random variables</a></li>
<li class="book-part">Standard univariate probability distributions</li>
<li><a class="" href="DiscreteDistributions.html"><span class="header-section-number">7</span> Standard discrete distributions</a></li>
<li><a class="" href="ContinuousDistributions.html"><span class="header-section-number">8</span> Standard continuous distributions</a></li>
<li><a class="" href="ChapterMixedDistributions.html"><span class="header-section-number">9</span> Mixed distributions</a></li>
<li class="book-part">Multivariate random variables and distributions*</li>
<li><a class="" href="ChapMultivariate.html"><span class="header-section-number">10</span> Multivariate distributions*</a></li>
<li><a class="active" href="MultivariateExtensions.html"><span class="header-section-number">11</span> Expectations for multivariate distributions*</a></li>
<li class="book-part">Sampling distributions</li>
<li><a class="" href="SamplingDistributions.html"><span class="header-section-number">12</span> Describing samples</a></li>
<li><a class="" href="OrderStatisticsChapter.html"><span class="header-section-number">13</span> Order statistcs</a></li>
<li><a class="" href="BayesianIntro.html"><span class="header-section-number">14</span> Introduction to Bayesian statistics</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="SymbolsUsed.html"><span class="header-section-number">A</span> Symbols used</a></li>
<li><a class="" href="UsefulSeries.html"><span class="header-section-number">B</span> Some useful series</a></li>
<li><a class="" href="ShortRIntro.html"><span class="header-section-number">C</span> Short R introduction</a></li>
<li><a class="" href="UseRDistributions.html"><span class="header-section-number">D</span> Using R with distributions</a></li>
<li><a class="" href="selected-solutions.html"><span class="header-section-number">E</span> Selected solutions</a></li>
<li><a class="" href="references.html"><span class="header-section-number">F</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PeterKDunn/DistTheory">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="MultivariateExtensions" class="section level1" number="11">
<h1>
<span class="header-section-number">11</span> Expectations for multivariate distributions*<a class="anchor" aria-label="anchor" href="#MultivariateExtensions"><i class="fas fa-link"></i></a>
</h1>
<div id="MultivariateExpectation" class="section level2" number="11.1">
<h2>
<span class="header-section-number">11.1</span> Expectation<a class="anchor" aria-label="anchor" href="#MultivariateExpectation"><i class="fas fa-link"></i></a>
</h2>
<p>Results involving expectations naturally generalise from the bivariate to the multivariate case.
Firstly, the expectation of a linear combination of random variables.</p>
<div class="theorem">
<p><span id="thm:ExpLinear" class="theorem"><strong>Theorem 11.1  (Expectation of linear combinations) </strong></span>If <span class="math inline">\(X_1, X_2,\dots, X_n\)</span> are random variables and <span class="math inline">\(a_1, a_2,\ldots a_n\)</span> are any constants then
<span class="math display">\[
   \operatorname{E}\left[\sum_{i = 1}^n a_i X_i \right]
   =\sum_{i = 1}^n a_i \, \operatorname{E}[X_i]
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-59" class="proof"><em>Proof</em>. </span>The proof follows directly from Theorem <a href="ChapExpectation.html#thm:ExpTwoRV">5.8</a> by induction.</p>
</div>
<p>The variance of a linear combination of random variables is given in the following theorem.</p>
<div class="theorem">
<p><span id="thm:LinearCombVariance" class="theorem"><strong>Theorem 11.2  (Variance of a linear combination) </strong></span>If <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> are random variables and <span class="math inline">\(a_1, a_2,\ldots a_n\)</span> are any constants then
<span class="math display">\[
   \operatorname{var}\left[\sum_{i = 1}^n a_i X_i \right]
   =
   \sum^n_{i = 1}a^2_i\operatorname{var}[X_i] + 2{\sum\sum}_{i&lt;j}a_i a_j\operatorname{Cov}(X_i, X_j).
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-60" class="proof"><em>Proof</em>. </span>For convenience, put <span class="math inline">\(Y = \sum_{i = 1}^n a_iX_i\)</span>.
Then by definition of variance
<span class="math display">\[\begin{align*}
     \operatorname{var}[Y]
     &amp;= \operatorname{E}\big[Y - \operatorname{E}(Y)\big]^2\\
     &amp;= \operatorname{E}[a_1 X_1 + \dots + a_n X_n - a_1\mu_1 - \dots a_n\mu_n]^2\\
     &amp;= \operatorname{E}[a_1(X_1 - \mu_1) + \dots + a_n(X_n - \mu_n)]^2\\
     &amp;= \operatorname{E}\left[ \sum_i a^2_i(X_i - \mu_i)^2 + 2\mathop{\sum\sum}_{i &lt; j}a_i a_j(X_i - \mu_i)X_j - \mu_j)\right]\\
     &amp;= \sum_i a^2_i\operatorname{E}[X_i - \mu_i]^2 + 2\mathop{\sum\sum}_{i &lt; j}a_i a_j\operatorname{E}[X_i - \mu_i] (X_j - \mu_j)\\
        %\quad \text{using Theorem\ \@ref(thm:ExpLinear)}\\
     &amp;= \sum_i a^2_i\sigma^2_i + 2\mathop{\sum\sum}_{i&lt;j}a_i a_j\operatorname{Cov}(X_i, X_j).
\end{align*}\]</span></p>
</div>
<p>In statistical theory, an important special case of Theorem <a href="MultivariateExtensions.html#thm:LinearCombVariance">11.2</a> occurs when the <span class="math inline">\(X_i\)</span> are independently and identically distributed (IID).
That is, each of <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> has the same distribution and are independent of each other.
(We see the relevance of this in Chap. <a href="SamplingDistributions.html#SamplingDistributions">12</a>.)
Because of its importance this special case is called a corollary of Theorems <a href="MultivariateExtensions.html#thm:ExpLinear">11.1</a> and <a href="MultivariateExtensions.html#thm:LinearCombVariance">11.2</a>.</p>
<div class="corollary">
<p><span id="cor:IID" class="corollary"><strong>Corollary 11.1  (IID rvs) </strong></span>If <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> are independently distributed (IID) random variables, each with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, and <span class="math inline">\(a_1, a_2,\ldots a_n\)</span> are any constants, then
<span class="math display">\[\begin{align*}
   \operatorname{E}\left[\sum_{i = 1}^n a_i X_i \right]
   &amp;= \mu\sum_{i = 1}^n a_i;\\
   \operatorname{var}\left[\sum_{i = 1}^n a_i X_i \right]
   &amp;= \sigma^2\sum^n_{i = 1}a^2_i.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-61" class="proof"><em>Proof</em>. </span>Exercise!</p>
</div>
</div>
<div id="Vectors" class="section level2" number="11.2">
<h2>
<span class="header-section-number">11.2</span> Vector formulation<a class="anchor" aria-label="anchor" href="#Vectors"><i class="fas fa-link"></i></a>
</h2>
<p>With the standard rules of matrix multiplication, Theorems <a href="MultivariateExtensions.html#thm:ExpLinear">11.1</a> and <a href="MultivariateExtensions.html#thm:LinearCombVariance">11.2</a> applied to Eq. <a href="MultivariateExtensions.html#eq:BivarCombination">(11.1)</a> then give respectively (check!)
<span class="math display">\[\begin{equation}
   \operatorname{E}[Y]
   = \operatorname{E}[\mathbf{a}^T\mathbf{X}]
   = [a_1, a_2]
   \begin{bmatrix}
      \mu_1 \\
      \mu_2
    \end{bmatrix}
   = \mathbf{a}^T\boldsymbol{\mu}
\end{equation}\]</span>
and
<span class="math display">\[\begin{align}
  \operatorname{var}[Y]
  &amp;= \operatorname{var}[\mathbf{a}^T\mathbf{X}\mathbf{a}]\nonumber\\
  &amp;= [a_1, a_2]
  \begin{bmatrix}
     \sigma^2_1 &amp; \sigma_{12} \\
     \sigma_{21}&amp; \sigma^2_2
  \end{bmatrix}
  \begin{bmatrix}
     a_1 \\
     a_2
  \end{bmatrix} \nonumber\\
  &amp;= \mathbf{a}^T\mathbf{\Sigma}\mathbf{a}.
\end{align}\]</span></p>
<p>The vector formulation of these results apply directly in the multivariate case as described below.
Write
<span class="math display">\[\begin{align*}
  \mathbf{X}
  &amp;= [X_1, X_2, \ldots, X_n]^T; \\
     \operatorname{E}[\mathbf{X}]
  &amp;= [\mu_1, \ldots, \mu_n]^T = \boldsymbol{\mu}^T; \\
     \operatorname{var}[\mathbf{X}]
  &amp;= \mathbf{\Sigma}; \\
     \mathbf{a}^T &amp; = \left[a_1,a_2,\ldots, a_n \right].
\end{align*}\]</span>
Now Theorems <a href="MultivariateExtensions.html#thm:ExpLinear">11.1</a> and <a href="MultivariateExtensions.html#thm:LinearCombVariance">11.2</a> can be expressed in vector form.</p>
<div class="theorem">
<p><span id="thm:MeanVarVector" class="theorem"><strong>Theorem 11.3  (Bivariate mean and variance (vector form)) </strong></span>If <span class="math inline">\(\mathbf{X}\)</span> is a random vector of length <span class="math inline">\(n\)</span> with mean <span class="math inline">\(\boldsymbol{\mu}\)</span> and variance <span class="math inline">\(\mathbf{\Sigma}\)</span>, and <span class="math inline">\(\mathbf{a}\)</span> is any constant vector of length <span class="math inline">\(n\)</span>, then
<span class="math display">\[\begin{align*}
   \operatorname{E}[\mathbf{a}^T\mathbf{X}]
   &amp;= \mathbf{a}^T\boldsymbol{\mu}; \\
   \operatorname{var}[\mathbf{a}^T\mathbf{X}]
   &amp;= \mathbf{a}^T\mathbf{\Sigma}\mathbf{a}.
\end{align*}\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-62" class="proof"><em>Proof</em>. </span>Exercise.</p>
</div>
<p>These elegant statements concerning linear combinations are a feature of vector formulations that extend to many statistical results in the theory of statistics.
One obvious advantage of this formulation is the implementation in vector-based computer programming used by packages such as <strong>R</strong>.</p>
<p>One further result is presented (without proof) involving two linear combinations.</p>
<div class="theorem">
<p><span id="thm:LinearCombCovar" class="theorem"><strong>Theorem 11.4  (Covariance of combinations) </strong></span>If <span class="math inline">\(\mathbf{X}\)</span> is a random vector of length <span class="math inline">\(n\)</span> with mean <span class="math inline">\(\boldsymbol{\mu}\)</span> and variance <span class="math inline">\(\mathbf{\Sigma}\)</span>, and <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span> are any constant vectors, each of length <span class="math inline">\(n\)</span>, then
<span class="math display">\[
   \operatorname{Cov}(\mathbf{a}^T\mathbf{X},\mathbf{b}^T\mathbf{X})
   =
   \mathbf{a}^T\mathbf{\Sigma}\mathbf{b}.
\]</span></p>
</div>
<div class="example">
<p><span id="exm:VectorExp" class="example"><strong>Example 11.1  (Expectations using vectors) </strong></span>Suppose the random variables <span class="math inline">\(X_1, X_2, X_3\)</span> have respective means <span class="math inline">\(1\)</span>, <span class="math inline">\(2\)</span>, and <span class="math inline">\(3\)</span>, respective variances <span class="math inline">\(4\)</span>, <span class="math inline">\(5\)</span>, and <span class="math inline">\(6\)</span>, and covariances <span class="math inline">\(\operatorname{Cov}(X_1, X_2) = -1\)</span>, <span class="math inline">\(\operatorname{Cov}(X_1, X_3) = 1\)</span> and <span class="math inline">\(\operatorname{Cov}(X_2, X_3) = 0\)</span>.</p>
<p>Consider the random variables <span class="math inline">\(Y_1 = 3X_1 + 2X_2 - X_3\)</span> and <span class="math inline">\(Y_2 = X_3 - X_1\)</span>.
Determine <span class="math inline">\(\operatorname{E}[Y_1]\)</span>, <span class="math inline">\(\operatorname{E}[Y_2]\)</span>, <span class="math inline">\(\operatorname{var}[Y_1]\)</span>, <span class="math inline">\(\operatorname{var}[Y_2]\)</span> and <span class="math inline">\(\operatorname{Cov}(Y_1,Y_2)\)</span>.</p>
<p>A vector formulation of this problem allows us to use Theorems <a href="MultivariateExtensions.html#thm:MeanVarVector">11.3</a> and <a href="MultivariateExtensions.html#thm:LinearCombCovar">11.4</a> directly.
Putting <span class="math inline">\(\mathbf{a}^T = [3, 2, -1]\)</span> and <span class="math inline">\(\mathbf{b}^T = [-1, 0, 1]\)</span>:
<span class="math display">\[
   Y_1 = \mathbf{a}^T\mathbf{X}
   \quad\text{and}\quad
   Y_2 = \mathbf{b}^T\mathbf{X}
\]</span>
where <span class="math inline">\(\mathbf{X}^T = [X_1, X_2, X_3]\)</span>.
Also define <span class="math inline">\(\boldsymbol{\mu}^T = [1, 2, 3]\)</span> and
<span class="math inline">\(\mathbf{\Sigma} =
\begin{bmatrix}
  4 &amp; -1 &amp; 1\\
-1 &amp; 5 &amp; 0\\
  1 &amp; 0 &amp; 6
\end{bmatrix}\)</span>
as the mean and variance–covariance matrix respectively of <span class="math inline">\(\mathbf{X}\)</span>.
Then
<span class="math display">\[
   \operatorname{E}[Y_1]
   = \mathbf{a}^T\boldsymbol{\mu}
   = [3, 2, -1]
   \begin{bmatrix}
      1\\
      2\\
      3
      \end{bmatrix}
   = 4
\]</span>
and
<span class="math display">\[
   \operatorname{var}[Y_1]
   = \mathbf{a}^T\mathbf{\Sigma}\mathbf{a}
   = [3, 2, -1]
   \begin{bmatrix}
      4 &amp; -1 &amp; 1\\
      -1 &amp; 5 &amp; 0\\
       1 &amp; 0 &amp; 6
    \end{bmatrix}
    \begin{bmatrix}
      3\\
      2\\
      -1
   \end{bmatrix}
   = 44.
\]</span>
Similarly <span class="math inline">\(\operatorname{E}[Y_2] = 2\)</span> and <span class="math inline">\(\operatorname{var}[Y_2] = 8\)</span>.
Finally:
<span class="math display">\[
   \operatorname{Cov}(Y_1, Y_2)
   = \mathbf{a}^T\mathbf{\Sigma}\mathbf{b}
   = [3, 2, -1]^T
   \begin{bmatrix}
      4 &amp; -1 &amp; 1\\
      -1 &amp; 5 &amp; 0\\
      1 &amp; 0 &amp; 6
      \end{bmatrix}
      \begin{bmatrix}
        -1\\
        0\\
        1
      \end{bmatrix}
  = -12.
\]</span></p>
</div>
</div>
<div id="expectation-and-covariance" class="section level2" number="11.3">
<h2>
<span class="header-section-number">11.3</span> Expectation and covariance<a class="anchor" aria-label="anchor" href="#expectation-and-covariance"><i class="fas fa-link"></i></a>
</h2>
<p>Consider a random vector of <span class="math inline">\(n\)</span> random variables
<span class="math display">\[
  \mathbf{X} = [X_1, X_2, \dots, X_n]^T.
\]</span>
The <em>mean vector</em> of <span class="math inline">\(\mathbf{X}\)</span> is
<span class="math display">\[
  \boldsymbol{\mu}
  = E[\mathbf{X}]
  =
  \begin{bmatrix}
    E[X_1] \\
    \vdots \\
    E[X_n]
  \end{bmatrix}.
\]</span></p>
<p>The <em>covariance matrix</em> is
<span class="math display">\[
  \Sigma = \text{Cov}(\mathbf{X})
  = E\!\left[(\mathbf{X} - \boldsymbol{\mu})(\mathbf{X} - \boldsymbol{\mu})^T\right].
\]</span></p>
<p>The entries are <span class="math inline">\(\Sigma_{ij} = \text{Cov}(X_i, X_j)\)</span>.
The diagonal entries are variances, while the off-diagonal entries are covariances.</p>
<p>The <em>correlation matrix</em> is obtained by normalisation:
<span class="math display">\[
  \rho_{ij} = \frac{\Sigma_{ij}}{\sqrt{\Sigma_{ii}\,\Sigma_{jj}}}.
\]</span></p>
</div>
<div id="independence" class="section level2" number="11.4">
<h2>
<span class="header-section-number">11.4</span> Independence<a class="anchor" aria-label="anchor" href="#independence"><i class="fas fa-link"></i></a>
</h2>
<p>The components <span class="math inline">\(X_1, \dots, X_n\)</span> are independent if and only if
<span class="math display">\[
  f(x_1, \dots, x_n) = \prod_{i = 1}^n f_{X_i}(x_i).
\]</span></p>
<p>Linear combinations of random variables are most elegantly dealt with using the methods and notation of vectors and matrices, especially as the dimension grows beyond the bivariate case.
In the bivariate case we define
<span class="math display">\[\begin{align}
   \mathbf{X}
   &amp;= \begin{bmatrix}
       X_1 \\
       X_2
      \end{bmatrix};
  \label{EQN:matrix1} \\
  \operatorname{E}[\mathbf{X}]
  &amp; =
   \operatorname{E}
   \left[
   \begin{bmatrix}
      X_1 \\
      X_2
   \end{bmatrix}
   \right]
   =
   \begin{bmatrix}
      \operatorname{E}[X_1] \\
      \operatorname{E}[X_2]
   \end{bmatrix}
   =  
   \begin{bmatrix}
     \mu_1 \\
     \mu_2
   \end{bmatrix} =
  \boldsymbol{\mu};\label{EQN:matrix2} \\
  \operatorname{var}[\mathbf{X}]
  &amp; = \operatorname{var}
  \left[
  \begin{bmatrix}
     X_1 \\
     X_2
  \end{bmatrix}
  \right]
  =
  \begin{bmatrix}
     \sigma^2_1  &amp; \sigma_{12} \\
     \sigma_{21} &amp; \sigma^2_2
  \end{bmatrix}
  = \mathbf{\Sigma}.\label{EQN:matrix3}
\end{align}\]</span></p>
<p>The vector <span class="math inline">\(\boldsymbol{\mu}\)</span> is the mean vector, and the matrix <span class="math inline">\(\mathbf{\Sigma}\)</span> is called the <em>variance–covariance</em> matrix, which is square and symmetric since <span class="math inline">\(\sigma_{12} = \sigma_{21}\)</span> (the covariance).</p>
<p>The linear combination <span class="math inline">\(Y = a_1 X_1 + a_2 X_2\)</span> can be expressed as
<span class="math display" id="eq:BivarCombination">\[\begin{equation}
   Y
   = a_1 X_1 + a_2 X_2
   = [a_1, a_2]
   \begin{bmatrix}
      X_1 \\
      X_2
   \end{bmatrix}
   = \mathbf{a}^T\mathbf{X}
   \tag{11.1}
\end{equation}\]</span>
where the (column) vector <span class="math inline">\(\mathbf{a} = \begin{bmatrix} a_1 \\ a_2 \end{bmatrix}\)</span>, and the superscript <span class="math inline">\(T\)</span> means ‘transpose’.</p>
</div>
<div id="IndependentRVs" class="section level2" number="11.5">
<h2>
<span class="header-section-number">11.5</span> Independent random variables<a class="anchor" aria-label="anchor" href="#IndependentRVs"><i class="fas fa-link"></i></a>
</h2>
<p>Recall that events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent if, and only if,
<span class="math display">\[
   something nmissing!
\]</span></p>
</div>
<div id="SimulationBivariate" class="section level2" number="11.6">
<h2>
<span class="header-section-number">11.6</span> Simulation<a class="anchor" aria-label="anchor" href="#SimulationBivariate"><i class="fas fa-link"></i></a>
</h2>
<p>As with univariate distributions (Sects. <a href="DiscreteDistributions.html#SimulationDiscrete">7.11</a> and <a href="ContinuousDistributions.html#SimulationContinuous">8.10</a>), simulation can be used with bivariate distributions.
Random numbers from the <em>bivariate normal</em> distribution (Sect. <a href="ContinuousDistributions.html#BVNormalDistribution">8.8</a>) are generated using the function <code><a href="https://rdrr.io/pkg/mnorm/man/dmnorm.html">dmnorm()</a></code> from the library <code>mnorm</code>.
Random numbers from the <em>multinomial</em> distribution (Sect. <a href="DiscreteDistributions.html#MultinomialDistribution">7.9</a>) are generated using the function <code><a href="https://rdrr.io/r/stats/Multinom.html">rmultinom()</a></code>.
More commonly, univariate distributions are combined.</p>
<p>Monthly rainfall, for example, is commonly modelled using gamma distributions (for example, <span class="citation">Husak, Michaelsen, and Funk (<a href="references.html#ref-husak2007use">2007</a>)</span>).
Simulating rainfall is then used in others models (such as for cropping simulations; for example <span class="citation">Ines and Hansen (<a href="references.html#ref-ines2006bias">2006</a>)</span>).
As an example, consider a location where the monthly rainfall is well-modelled by a gamma distribution with a shape parameter <span class="math inline">\(\alpha = 1.6\)</span> and a scale parameter of <span class="math inline">\(\beta = 220\)</span> (Fig. <a href="MultivariateExtensions.html#fig:RainfallSim">11.1</a>, left panel):</p>
<div class="sourceCode" id="cb84"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st">"mnorm"</span><span class="op">)</span> <span class="co"># Need to explicitly load  mnorm  library</span></span>
<span><span class="va">MRain</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">rgamma</a></span><span class="op">(</span> <span class="fl">2000</span>,</span>
<span>                 shape <span class="op">=</span> <span class="fl">1.6</span>,</span>
<span>                 scale <span class="op">=</span> <span class="fl">220</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rainfall exceeding 900mm:"</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">MRain</span> <span class="op">&gt;</span> <span class="fl">900</span><span class="op">)</span> <span class="op">/</span> <span class="fl">2000</span> <span class="op">*</span> <span class="fl">100</span>, <span class="st">"%\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rainfall exceeding 900mm: 4.95 %</span></span>
<span><span class="co"># Directly:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="fl">900</span>, shape <span class="op">=</span> <span class="fl">1.6</span>, scale <span class="op">=</span> <span class="fl">220</span><span class="op">)</span> <span class="op">)</span> <span class="op">*</span> <span class="fl">100</span>, <span class="fl">2</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 4.95</span></span></code></pre></div>
<p>The percentage of months with rainfall exceeding <span class="math inline">\(1000\,\text{mm}\)</span> was also computed.
However, now suppose that the shape parameter <span class="math inline">\(\alpha\)</span> also varies, with an exponential distribution with mean <span class="math inline">\(2\)</span> (Fig. <a href="MultivariateExtensions.html#fig:RainfallSim">11.1</a>, centre panel):</p>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">MRain2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">rgamma</a></span><span class="op">(</span> <span class="fl">1000</span>,</span>
<span>                  shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">1000</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>                  scale <span class="op">=</span> <span class="fl">220</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rainfall exceeding 900mm:"</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">MRain2</span> <span class="op">&gt;</span> <span class="fl">900</span><span class="op">)</span> <span class="op">/</span> <span class="fl">1000</span> <span class="op">*</span> <span class="fl">100</span>, <span class="st">"%\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rainfall exceeding 900mm: 13.3 %</span></span></code></pre></div>
<p>Using simulation, it is also easy to simulate the impact of the scale parameter <span class="math inline">\(\beta\)</span> varying also, suppose with a normal distribution mean of <span class="math inline">\(200\)</span> and variance of <span class="math inline">\(16\)</span> (Fig. <a href="MultivariateExtensions.html#fig:RainfallSim">11.1</a>, right panel):</p>
<div class="sourceCode" id="cb86"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">MRain3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">rgamma</a></span><span class="op">(</span> <span class="fl">1000</span>,</span>
<span>                  shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Exponential.html">rexp</a></span><span class="op">(</span><span class="fl">1000</span>, rate <span class="op">=</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>                  scale <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span>, mean <span class="op">=</span> <span class="fl">200</span>, sd <span class="op">=</span> <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Rainfall exceeding 900:"</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">MRain3</span> <span class="op">&gt;</span> <span class="fl">900</span><span class="op">)</span> <span class="op">/</span> <span class="fl">1000</span> <span class="op">*</span> <span class="fl">100</span>, <span class="st">"%\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Rainfall exceeding 900: 11.4 %</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:RainfallSim"></span>
<img src="11-MultivariateExpectation_files/figure-html/RainfallSim-1.png" alt="Three simulations using the gamma distribution." width="100%"><p class="caption">
FIGURE 11.1: Three simulations using the gamma distribution.
</p>
</div>
</div>
<div id="MultivariateExpectationExercises" class="section level2" number="11.7">
<h2>
<span class="header-section-number">11.7</span> Exercises<a class="anchor" aria-label="anchor" href="#MultivariateExpectationExercises"><i class="fas fa-link"></i></a>
</h2>
<p>Selected answers appear in Sect. <a href="selected-solutions.html#AnswerMultivariateExtensions">E.11</a>.</p>
<div class="exercise">
<p><span id="exr:SampleMean" class="exercise"><strong>Exercise 11.1  </strong></span>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> are independently distributed random variables, each with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.
Define the sample mean as <span class="math inline">\(\overline{X} = \left( \sum_{i=1}^n X_i\right)/n\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Prove that <span class="math inline">\(\operatorname{E}[\overline{X}] = \mu\)</span>.</li>
<li>Find the variance of <span class="math inline">\(\overline{X}\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:PoissonGammaRainfall" class="exercise"><strong>Exercise 11.2  </strong></span><strong>NO LONGER NEEDED:</strong></p>
<p>The <em>Poisson-gamma distributions</em> (e.g., see <span class="citation">Hasan and Dunn (<a href="references.html#ref-mypapers:Hasan:simplePG">2010b</a>)</span>), used for modelling rainfall, can be developed as follows:</p>
<ul>
<li>Let <span class="math inline">\(N\)</span> be the number of rainfall events in a month, where <span class="math inline">\(N\sim \text{Pois}(\lambda)\)</span>.
If no rainfall events are recorded in any month, then the monthly rainfall is <span class="math inline">\(Z = 0\)</span>.</li>
<li>For each rainfall event (that is, when <span class="math inline">\(N &gt; 0\)</span>), say <span class="math inline">\(i\)</span> for <span class="math inline">\(i = 1, 2, \dots N\)</span>, the <em>amount</em> of rain in event <span class="math inline">\(i\)</span>, say <span class="math inline">\(Y_i\)</span>, is modelled using a gamma distribution with parameter <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</li>
<li>The total monthly rainfall is then <span class="math inline">\(Z = \sum_{i = 1}^N Y_i\)</span>.</li>
</ul>
<p>Suppose the monthly rainfall station at a particular station can be modelled using <span class="math inline">\(\lambda = 0.78\)</span>, <span class="math inline">\(\alpha = 0.5\)</span> and <span class="math inline">\(\beta = 6\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Use a simulation to produce a one-month rainfall total using this model.</li>
<li>Repeat for <span class="math inline">\(1\,000\)</span> simulations (i.e., simulate <span class="math inline">\(1\,000\)</span> months), and plot the distribution.</li>
<li>What type of random variable is the monthly rainfall: discrete, continuous, or mixed?
Explain.</li>
<li>Based on the <span class="math inline">\(1\,000\)</span> simulations, approximately how often does a month have exactly zero rainfall?</li>
<li>Based on the <span class="math inline">\(1\,000\)</span> simulations, what is the mean monthly rainfall?</li>
<li>Based on the <span class="math inline">\(1\,000\)</span> simulations, what is the mean monthly rainfall in months where rain is recorded?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:LinearCombinCovariance" class="exercise"><strong>Exercise 11.3  </strong></span><span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span> are uncorrelated random variables with expected values <span class="math inline">\(\mu_x\)</span>, <span class="math inline">\(\mu_y\)</span> and <span class="math inline">\(\mu_z\)</span> and standard deviations <span class="math inline">\(\sigma_x\)</span>, <span class="math inline">\(\sigma_y\)</span> and <span class="math inline">\(\sigma_z\)</span>.
<span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are defined by
<span class="math display">\[\begin{align*}
   U&amp;= X - Z;\\
   V&amp;= X - 2Y + Z.
\end{align*}\]</span></p>
<ol style="list-style-type: decimal">
<li>Find the expected values of <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>.</li>
<li>Find the variance of <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>.</li>
<li>Find the covariance between <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>.</li>
<li>Under what conditions on <span class="math inline">\(\sigma_x\)</span>, <span class="math inline">\(\sigma_y\)</span> and <span class="math inline">\(\sigma_z\)</span> are <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> uncorrelated?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:JointDiscrete11" class="exercise"><strong>Exercise 11.4  </strong></span>Suppose <span class="math inline">\((X, Y)\)</span> has joint probability function given by
<span class="math display">\[
  \Pr(X = x, Y = y) = \frac{|x - y|}{11}
\]</span>
for <span class="math inline">\(x = 0, 1, 2\)</span> and <span class="math inline">\(y = 1, 2, 3\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Find <span class="math inline">\(\operatorname{E}[X \mid Y = 2]\)</span>.</li>
<li>Find <span class="math inline">\(\operatorname{E}[Y \mid X\ge 1]\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:CorrContDist" class="exercise"><strong>Exercise 11.5  </strong></span>The PDF of <span class="math inline">\((X, Y)\)</span> is given by
<span class="math display">\[
   f_{X, Y}(x, y) = 1 - \alpha(1 - 2x)(1 - 2y),
\]</span>
for <span class="math inline">\(0 \le x \le 1\)</span>, <span class="math inline">\(0 \le y \le 1\)</span> and <span class="math inline">\(-1 \le \alpha \le 1\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Find the marginal distributions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>Evaluate the correlation coefficient <span class="math inline">\(\rho_{XY}\)</span>.</li>
<li>For what value of <span class="math inline">\(\alpha\)</span> are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> independent?</li>
<li>Find <span class="math inline">\(\Pr(X &lt; Y)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-63" class="exercise"><strong>Exercise 11.6  </strong></span>The random variables <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, and <span class="math inline">\(X_3\)</span> have y</p>
<ul>
<li>
<span class="math inline">\(X_1\)</span>: mean <span class="math inline">\(\mu_1 = 5\)</span> with standard deviation <span class="math inline">\(\sigma_1 = 2\)</span>.</li>
<li>
<span class="math inline">\(X_2\)</span>: mean <span class="math inline">\(\mu_2 = 3\)</span> with standard deviation <span class="math inline">\(\sigma_2 = 3\)</span>.</li>
<li>
<span class="math inline">\(X_3\)</span>: mean <span class="math inline">\(\mu_3 = 6\)</span> with standard deviation <span class="math inline">\(\sigma_3 = 4\)</span>.</li>
</ul>
<p>The correlations are: <span class="math inline">\(\rho_{12} = -\frac{1}{6}\)</span>, <span class="math inline">\(\rho_{13} = \frac{1}{6}\)</span> and <span class="math inline">\(\rho_{23} = \frac{1}{2}\)</span>.</p>
<p>If the random variables <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are defined by <span class="math inline">\(U = 2X_1 + X_2 - X_3\)</span> and <span class="math inline">\(V = X_1  - 2X_2 - X_3\)</span>, find</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\operatorname{E}[U]\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{var}[U]\)</span>.</li>
<li>
<span class="math inline">\(\operatorname{Cov}(U, V)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-64" class="exercise"><strong>Exercise 11.7  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be the body mass index (BMI) and percentage body fat for netball players attending the AIS.
Assume <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have a bivariate normal distribution with <span class="math inline">\(\mu_X = 23\)</span>, <span class="math inline">\(\mu_Y = 21\)</span>, <span class="math inline">\(\sigma_X = 3\)</span>, <span class="math inline">\(\sigma_Y = 6\)</span> and <span class="math inline">\(\rho_{XY} = 0.8\)</span>.
Find</p>
<ol style="list-style-type: decimal">
<li>the expected BMI of a netball player who has a percent body fat of <span class="math inline">\(30\)</span>.</li>
<li>the expected percentage body fat of a netball player who has a BMI of <span class="math inline">\(19\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-65" class="exercise"><strong>Exercise 11.8  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have a bivariate normal distribution with parameters <span class="math inline">\(\mu_x = 1\)</span>, <span class="math inline">\(\mu_y = 4\)</span>, <span class="math inline">\(\sigma^2_x = 4\)</span>, <span class="math inline">\(\sigma^2_y = 9\)</span> and <span class="math inline">\(\rho = 0.6\)</span>.
Find</p>
<ol style="list-style-type: decimal">
<li>
<span class="math inline">\(\Pr(-1.5 &lt; X &lt; 2.5)\)</span>.</li>
<li>
<span class="math inline">\(\Pr(-1.5 &lt; X &lt; 2.5 \mid Y = 3)\)</span>.</li>
<li>
<span class="math inline">\(\Pr(0 &lt; Y &lt; 8)\)</span>.</li>
<li>
<span class="math inline">\(\Pr(0 &lt; Y &lt; 8 \mid X = 0)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:GammaExp" class="exercise"><strong>Exercise 11.9  </strong></span>Consider <span class="math inline">\(n\)</span> random variables <span class="math inline">\(Z_i\)</span> such that <span class="math inline">\(Z_i \sim \text{Exp}(\beta)\)</span> for every <span class="math inline">\(i = 1, \dots, n\)</span>.
Show that the distribution of <span class="math inline">\(Z_1 + Z_2 + \cdots + Z_n\)</span> has a gamma distribution <span class="math inline">\(\text{Gam}(n, \beta)\)</span>, and determine the parameters of this gamma distribution.
(Hint: See Theorem <a href="ChapExpectation.html#thm:MGFIndependent">5.6</a>.)</p>
</div>
<div class="exercise">
<p><span id="exr:DailyTempBivar" class="exercise"><strong>Exercise 11.10  </strong></span><span class="citation">Daniel S. Wilks (<a href="references.html#ref-climate:wilks:statmethods">1995b</a>)</span> (p. 101) states that the maximum daily temperatures measured at Ithaca (<span class="math inline">\(I\)</span>) and Canandaigua (<span class="math inline">\(C\)</span>) in January 1987 are both symmetrical.
He also says that the two temperatures could be modelled with a bivariate normal
distribution with <span class="math inline">\(\mu_I = 29.87\)</span>, <span class="math inline">\(\mu_C = 31.77\)</span>, <span class="math inline">\(\sigma_I = 7.71\)</span>, <span class="math inline">\(\sigma_C = 7.86\)</span> and <span class="math inline">\(\rho_{IC} = 0.957\)</span>.
(All measurements are in degrees Fahrenheit.)</p>
<ol style="list-style-type: decimal">
<li>Explain, in context, what a correlation coefficient of <span class="math inline">\(0.957\)</span> means.</li>
<li>Determine the marginal distributions of <span class="math inline">\(C\)</span> and of <span class="math inline">\(I\)</span>.</li>
<li>Find the conditional distribution of <span class="math inline">\(C\mid I\)</span>.</li>
<li>Plot the PDF of Canandaigua maximum temperature.</li>
<li>Plot the conditional PDF of Canandaigua maximum temperature given that the maximum temperature at Ithaca is <span class="math inline">\(25^\circ\)</span>F.</li>
<li>Comment on the differences between the two PDFs plotted above.</li>
<li>Find <span class="math inline">\(\Pr(C &lt; 32 \mid I = 25)\)</span>.</li>
<li>Find <span class="math inline">\(\Pr(C &lt; 32)\)</span>.</li>
<li>Comment on the differences between the last two answers.</li>
<li>If temperature were measured in degrees Celsius instead of degrees Fahrenheit, how would the value of <span class="math inline">\(\rho_{IC}\)</span> change?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:DiscreteJointTable" class="exercise"><strong>Exercise 11.11  </strong></span>The discrete random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have the joint probability distribution shown in the following table:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th>Value of <span class="math inline">\(x\)</span>
</th>
<th><span class="math inline">\(y = 1\)</span></th>
<th><span class="math inline">\(y = 2\)</span></th>
<th><span class="math inline">\(y = 3\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x = 0\)</span></td>
<td>0.20</td>
<td>0.15</td>
<td>0.05</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x = 1\)</span></td>
<td>0.20</td>
<td>0.25</td>
<td>0.00</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x = 3\)</span></td>
<td>0.10</td>
<td>0.05</td>
<td>0.00</td>
</tr>
</tbody>
</table></div>
<ol style="list-style-type: decimal">
<li>Determine the marginal distribution of <span class="math inline">\(X\)</span>.</li>
<li>Calculate <span class="math inline">\(\Pr(X \ne Y)\)</span>.</li>
<li>Calculate <span class="math inline">\(\Pr(X + Y = 2 \mid X = Y)\)</span>.</li>
<li>Are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> independent?
Justify your answer.</li>
<li>Calculate the correlation of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; i.e., compute <span class="math inline">\(\text{Cor}(X,Y)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-66" class="exercise"><strong>Exercise 11.12  </strong></span>Suppose <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have the joint PDF
<span class="math display">\[
   f_{X, Y}(x, y) = \frac{2 + x + y}{8} \quad\text{for $-1 &lt; x &lt; 1$ and $-1 &lt; y &lt; 1$}.
\]</span></p>
<ol style="list-style-type: decimal">
<li>Sketch the distribution using <strong>R</strong>.</li>
<li>Determine the marginal PDF of <span class="math inline">\(X\)</span>.</li>
<li>Are <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> independent?
Give reasons.</li>
<li>Determine <span class="math inline">\(\Pr(X &gt; 0, Y &gt; 0)\)</span>.</li>
<li>Determine <span class="math inline">\(\Pr(X \ge 0, Y \ge 0, X + Y \le 1)\)</span>.</li>
<li>Determine <span class="math inline">\(\operatorname{E}[XY]\)</span>.</li>
<li>Determine <span class="math inline">\(\operatorname{var}[Y]\)</span>.</li>
<li>Determine <span class="math inline">\(\operatorname{Cov}(X, Y)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-67" class="exercise"><strong>Exercise 11.13  </strong></span>Historically, final marks in a certain course are approximately normally distributed with mean of <span class="math inline">\(64\)</span> and standard deviation <span class="math inline">\(8\)</span>.
Out of fifteen students completing the course, what is the probability that <span class="math inline">\(2\)</span> obtain HDs, <span class="math inline">\(3\)</span> Distinctions, <span class="math inline">\(4\)</span> Credits, <span class="math inline">\(5\)</span> Passes and <span class="math inline">\(2\)</span> Fails?</p>
</div>
<div class="exercise">
<p><span id="exr:IIDcubic" class="exercise"><strong>Exercise 11.14  </strong></span>Let <span class="math inline">\(X_1, X_2, X_3, \dots, X_n\)</span> denote are independently and identically distributed with PDF
<span class="math display">\[
   f_X(x) = 4x^3\quad \text{for $0 &lt; x &lt; 1$}.
\]</span></p>
<ol style="list-style-type: decimal">
<li>Write down an expression for the joint PDF of distribution of <span class="math inline">\(X_1, X_2, X_3, \dots, X_n\)</span>.</li>
<li>Determine the probability that the first observation <span class="math inline">\(X_1\)</span> is less than <span class="math inline">\(0.5\)</span>.</li>
<li>Determine the probability that <em>all</em> observations are less than <span class="math inline">\(0.5\)</span>.</li>
<li>Use the result above to deduce then the probability that the largest observation is less than <span class="math inline">\(0.5\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-68" class="exercise"><strong>Exercise 11.15  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have a bivariate normal distribution with <span class="math inline">\(\operatorname{E}[X] = 5\)</span>, <span class="math inline">\(\operatorname{E}[Y] = -2\)</span>, <span class="math inline">\(\operatorname{var}[X] = 4\)</span>, <span class="math inline">\(\operatorname{var}[Y] = 9\)</span>, and <span class="math inline">\(\operatorname{Cov}(X, Y) = -3\)</span>.
Determine the joint distribution of <span class="math inline">\(U = 3X + 4Y\)</span> and <span class="math inline">\(V = 5X - 6Y\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:TwoFairDie" class="exercise"><strong>Exercise 11.16  </strong></span>Two fair dice are rolled.
Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> denote, respectively, the maximum and minimum of the numbers of spots showing on the two dice.</p>
<ol style="list-style-type: decimal">
<li>Construct a table that enumerates the sample space.</li>
<li>Determine <span class="math inline">\(E(Y\mid X = 4)\)</span> for <span class="math inline">\(1\le x\le 6\)</span>.</li>
<li>Simulate this experiment using <strong>R</strong>.
Compare the simulated results with the theoretical results found above.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-69" class="exercise"><strong>Exercise 11.17  </strong></span>Let <span class="math inline">\(X\)</span> be a random variable for which <span class="math inline">\(\operatorname{E}[X] = \mu\)</span> and <span class="math inline">\(\operatorname{var}[X] = \sigma^2\)</span>, and let <span class="math inline">\(c\)</span> be an arbitrary constant.</p>
<ol style="list-style-type: decimal">
<li>Show that
<span class="math display">\[
   \operatorname{E}[(X - c)^2] = (\mu - c)^2 + \sigma^2.
\]</span>
</li>
<li>What does the result above tell us about the possible size of <span class="math inline">\(\operatorname{E}[(X - c)^2]\)</span>?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:DailyRainfallSim" class="exercise"><strong>Exercise 11.18  </strong></span>In Sect. <a href="MultivariateExtensions.html#SimulationBivariate">11.6</a>, simulation was used for monthly rainfall.
<em>Daily</em> rainfall, however, is more difficult to model as some days have exactly zero rainfall, and on some days a continuous amount of rainfalls; i.e., daily monthly is a <em>mixed</em> random variable (Sect. <a href="DistributionRandomVariables.html#RVsMixed">3.2.3</a>).</p>
<p>One way to model daily rainfall is to use a two-step process <span class="citation">(<a href="references.html#ref-climate:chandler:2002">Chandler and Wheater 2002</a>)</span>.
Firstly, model whether a day records rainfall or not (using a binomial distribution): the <em>occurrence model</em>.
Then, for days on which rain falls, model the amount of rainfall using a gamma distribution: the <em>amounts model</em>.</p>
<ol style="list-style-type: decimal">
<li>Use this information to model daily rainfall over one year (<span class="math inline">\(365\)</span> days), for a location where the probability of a wet day is <span class="math inline">\(0.32\)</span>, and the amount of rainfall on wet days follows a gamma distribution with <span class="math inline">\(\alpha = 2\)</span> and <span class="math inline">\(\beta = 20\)</span>.
Produce a histogram of the distribution of <em>annual</em> rainfall after <span class="math inline">\(1\,000\)</span> simulations.</li>
<li>Suppose that the probability of rainfall, <span class="math inline">\(p\)</span>, depends on the day of the year, such that:
<span class="math display">\[
p =  \left\{1 + \cos[ 2\pi\times(\text{day of year})/365]\right\} / 2.2.
\]</span>
Plot the change in <span class="math inline">\(p\)</span> over the day of the year.</li>
<li>Revise the first model using this value of <span class="math inline">\(p\)</span>.
Produce a histogram of the distribution of <em>annual</em> rainfall after <span class="math inline">\(1\,000\)</span> simulations.</li>
<li>Revise the <em>initial</em> model (where the probability of rain of Day 1 is still <span class="math inline">\(0.32\)</span>), so that the value of <span class="math inline">\(p\)</span> depends on what happened the day before:
If day <span class="math inline">\(i\)</span> receives rain, then the probability that the following day receives rain is <span class="math inline">\(p = 0.55\)</span>; if day <span class="math inline">\(i\)</span> does <em>not</em> receive rain, then the probability that the following day receives rain is just <span class="math inline">\(p = 0.15\)</span>.
Produce a histogram of the distribution of <em>annual</em> rainfall after <span class="math inline">\(1\,000\)</span> simulations.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:TrailMix" class="exercise"><strong>Exercise 11.19  </strong></span>A company produces a <span class="math inline">\(500\,\text{g}\)</span> packet of ‘trail mix’ that includes a certain weight of nuts <span class="math inline">\(X\)</span>, dried fruit <span class="math inline">\(Y\)</span>, and seeds <span class="math inline">\(Z\)</span>.
The actually weights of each ingredient vary randomly, depending on seasonality and availability.</p>
<ol style="list-style-type: decimal">
<li>Explain why there are really just two variables in this problem.</li>
<li>Suppose the weight of nuts <em>plus</em> dried fruit must be between <span class="math inline">\(300\,\text{g}\)</span> and <span class="math inline">\(400\,\text{g}\)</span>.
Draw the sample space.</li>
<li>
<em>In addition</em>, suppose the weight of nuts must be <em>at least</em> <span class="math inline">\(100\,\text{g}\)</span>, and the weight of dried fruit must be <em>at least</em> <span class="math inline">\(100\,\text{g}\)</span>.
Draw the sample space.</li>
<li>Under the above conditions, assume the weights of ingredients used in the trail mix are uniformly distributed.
Determine the probability function.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:MixedNuts" class="exercise"><strong>Exercise 11.20  </strong></span>Mixed nuts come in <span class="math inline">\(250\,\text{g}\)</span> packets, and comprise walnuts, almonds and peanuts.
The actual weights of each ingredient vary randomly, depending on seasonality and availability.</p>
<ol style="list-style-type: decimal">
<li>Explain why there are really just two variables in this problem.</li>
<li>While peanuts are the cheapest ingredient, guidelines state that the weight of peanuts must not exceed <span class="math inline">\(100\,\text{g}\)</span>.
Draw the sample space.</li>
<li>
<em>In addition</em>, suppose the weight of almonds must be <em>at least</em> <span class="math inline">\(25\,\text{g}\)</span>, and the weight of walnuts must be <em>at least</em> <span class="math inline">\(25\,\text{g}\)</span>.
Draw the sample space.</li>
<li>Under the above conditions, assume the weights of ingredients used in the mixed nuts packets are uniformly distributed.
Determine the probability function.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:MixedBiomarker" class="exercise"><strong>Exercise 11.21  </strong></span>Suppose <span class="math inline">\(X\)</span> is the concentration of a biomarker (in mmol.L<sup><span class="math inline">\(-1\)</span></sup>), and <span class="math inline">\(Y\)</span> is a disease indicator where <span class="math inline">\(Y = 1\)</span> refers to a patient with the disease and <span class="math inline">\(Y = 0\)</span> refers to a patient without the disease.<br>
The prevalence of the disease in the population is
<span class="math display">\[
  \Pr(Y = 1) = 0.10, \quad \Pr(Y = 0) = 0.90.
\]</span>
Conditional on disease status, biomarker concentrations follow different ??????normal?????? distributions.
If <span class="math inline">\(Y = 1\)</span>:<br><span class="math display">\[
  X \mid Y = 1 \sim \mathcal{N}(\mu_1=8, \, \sigma_1^2 = 1^2),
\]</span>
and if <span class="math inline">\(Y = 0\)</span>:
<span class="math display">\[
  X \mid Y = 0 \sim \mathcal{N}(\mu_0=5, \, \sigma_0^2 = 1^2).
\]</span>
1. Write down the joint density–mass function <span class="math inline">\(f_{X, Y}(x, y)\)</span>.<br>
2. Derive the marginal density of <span class="math inline">\(X\)</span>, <span class="math inline">\(f_X(x)\)</span>.<br>
3. Compute <span class="math inline">\(\Pr(Y = 1 \mid X = 7)\)</span> (the posterior probability of disease given biomarker level <span class="math inline">\(7\)</span>).<br>
4. Interpret this probability in plain language.</p>
</div>
<div class="exercise">
<p><span id="exr:MixedReliability" class="exercise"><strong>Exercise 11.22  </strong></span>A machine component can fail for one of three reasons:</p>
<ul>
<li>mechanical failure (<span class="math inline">\(Y = 1\)</span>), with probability <span class="math inline">\(0.5\)</span>;</li>
<li>electrical failure (<span class="math inline">\(Y = 2\)</span>), with probability <span class="math inline">\(0.3\)</span>;</li>
<li>thermal failure (<span class="math inline">\(Y = 3\)</span>), with probability <span class="math inline">\(0.2\)</span>.</li>
</ul>
<p>The random variable <span class="math inline">\(X\)</span> denotes the <em>time to failure</em> (in hundreds of hours).
Conditional on knowing the mode of failure, the time-to-failure has the distribution
<span class="math display">\[
  f_{X\mid Y}(x\mid Y = y)
  =  \lambda_y \exp(-\lambda_y x)
    \quad\text{for $x &gt; 0$}
\]</span>
where</p>
<ul>
<li>
<span class="math inline">\(\lambda_y = 1\)</span> if the failure is mechanical;</li>
<li>
<span class="math inline">\(\lambda_y = 0.5\)</span> if the failure is electrical; and</li>
<li>
<span class="math inline">\(\lambda_y = 0.25\)</span> if the failure is thermal.</li>
</ul>
<ol style="list-style-type: decimal">
<li>Write down the joint density–mass function <span class="math inline">\(f_{X, Y}(x, y)\)</span>.</li>
<li>Find the marginal density of the time to failure <span class="math inline">\(f_X(x)\)</span>.</li>
<li>Compute <span class="math inline">\(\Pr(Y = 1 \mid X \leq 2)\)</span>, the probability that the failure mode was mechanical given that the component failed within <span class="math inline">\(200\)</span> hours.</li>
<li>Interpret the result in words.</li>
</ol>
</div>

</div>
</div>



<hr>
<div class="footer"><span style="color: gray; font-size:0.7em">Peter K. Dunn, 2024: <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span></div>
  <div class="chapter-nav">
<div class="prev"><a href="ChapMultivariate.html"><span class="header-section-number">10</span> Multivariate distributions*</a></div>
<div class="next"><a href="SamplingDistributions.html"><span class="header-section-number">12</span> Describing samples</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#MultivariateExtensions"><span class="header-section-number">11</span> Expectations for multivariate distributions*</a></li>
<li><a class="nav-link" href="#MultivariateExpectation"><span class="header-section-number">11.1</span> Expectation</a></li>
<li><a class="nav-link" href="#Vectors"><span class="header-section-number">11.2</span> Vector formulation</a></li>
<li><a class="nav-link" href="#expectation-and-covariance"><span class="header-section-number">11.3</span> Expectation and covariance</a></li>
<li><a class="nav-link" href="#independence"><span class="header-section-number">11.4</span> Independence</a></li>
<li><a class="nav-link" href="#IndependentRVs"><span class="header-section-number">11.5</span> Independent random variables</a></li>
<li><a class="nav-link" href="#SimulationBivariate"><span class="header-section-number">11.6</span> Simulation</a></li>
<li><a class="nav-link" href="#MultivariateExpectationExercises"><span class="header-section-number">11.7</span> Exercises</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PeterKDunn/DistTheory/blob/main/11-MultivariateExpectation.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PeterKDunn/DistTheory/edit/main/11-MultivariateExpectation.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>The Theory of Statistical Distributions</strong>" was written by Peter K. Dunn. It was last built on Last updated: 2025-12-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
