<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>6 Transformations of random variables | The Theory of Statistical Distributions</title>
<meta name="author" content="Peter K. Dunn">
<meta name="description" content="On completion of this chapter, you should be able to: derive the distribution of a transformed variable, given the distribution of the original variable, using the distribution function method,...">
<meta name="generator" content="bookdown 0.45 with bs4_book()">
<meta property="og:title" content="6 Transformations of random variables | The Theory of Statistical Distributions">
<meta property="og:type" content="book">
<meta property="og:description" content="On completion of this chapter, you should be able to: derive the distribution of a transformed variable, given the distribution of the original variable, using the distribution function method,...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="6 Transformations of random variables | The Theory of Statistical Distributions">
<meta name="twitter:description" content="On completion of this chapter, you should be able to: derive the distribution of a transformed variable, given the distribution of the original variable, using the distribution function method,...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.9.0/transition.js"></script><script src="libs/bs3compat-0.9.0/tabs.js"></script><script src="libs/bs3compat-0.9.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><script src="libs/rglWebGL-binding-1.3.31/rglWebGL.js"></script><link href="libs/rglwidgetClass-1.3.31/rgl.css" rel="stylesheet">
<script src="libs/rglwidgetClass-1.3.31/rglClass.min.js"></script><script src="libs/CanvasMatrix4-1.3.31/CanvasMatrix.min.js"></script><link rel="shortcut icon" href="icons/iconmonstr-chart-1-240.png">
<script>
    document.addEventListener('DOMContentLoaded', function() {
      // Find all R code blocks that should be toggleable.
      // Our Lua filter adds the 'r-code-box' class to the code block.
      var codeBlocks = document.querySelectorAll('.r-code-box');

      codeBlocks.forEach(function(codeBlock) {
        // Create the button element
        var button = document.createElement('button');
        button.textContent = 'Show R Code'; // Initial text for the button
        button.className = 'code-toggle-button'; // Assign CSS class

        // Insert the button directly before the code block.
        // The codeBlock's parentNode is the div.figure-with-code container.
        // We insert the button as a sibling of the codeBlock within that container.
        codeBlock.parentNode.insertBefore(button, codeBlock);

        // Hide the code block initially by default.
        codeBlock.style.display = 'none';

        // Add a click event listener to the button
        button.addEventListener('click', function() {
          if (codeBlock.style.display === 'none') {
            codeBlock.style.display = 'block'; // Show the code block
            button.textContent = 'Hide R Code'; // Change button text
          } else {
            codeBlock.style.display = 'none'; // Hide the code block
            button.textContent = 'Show R Code'; // Change button text back
          }
        });
      });
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/columns.css">
<link rel="stylesheet" href="html/largerDie.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">The Theory of Statistical Distributions</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li class="book-part">Theoretical foundations</li>
<li><a class="" href="ChapterSetTheory.html"><span class="header-section-number">1</span> Essentials of set theory</a></li>
<li><a class="" href="ChapterProbability.html"><span class="header-section-number">2</span> Probability</a></li>
<li><a class="" href="DistributionRandomVariables.html"><span class="header-section-number">3</span> Random variables and their distributions</a></li>
<li><a class="" href="ChapBivariate.html"><span class="header-section-number">4</span> Bivariate distributions</a></li>
<li><a class="" href="ChapExpectation.html"><span class="header-section-number">5</span> Mathematical expectation</a></li>
<li><a class="active" href="ChapterTransformations.html"><span class="header-section-number">6</span> Transformations of random variables</a></li>
<li class="book-part">Standard univariate probability distributions</li>
<li><a class="" href="DiscreteDistributions.html"><span class="header-section-number">7</span> Standard discrete distributions</a></li>
<li><a class="" href="ContinuousDistributions.html"><span class="header-section-number">8</span> Standard continuous distributions</a></li>
<li><a class="" href="ChapterMixedDistributions.html"><span class="header-section-number">9</span> Mixed distributions</a></li>
<li class="book-part">Multivariate random variables and distributions*</li>
<li><a class="" href="ChapMultivariate.html"><span class="header-section-number">10</span> Multivariate distributions*</a></li>
<li><a class="" href="MultivariateExtensions.html"><span class="header-section-number">11</span> Expectations for multivariate distributions*</a></li>
<li class="book-part">Sampling distributions</li>
<li><a class="" href="SamplingDistributions.html"><span class="header-section-number">12</span> Describing samples</a></li>
<li><a class="" href="OrderStatisticsChapter.html"><span class="header-section-number">13</span> Order statistcs</a></li>
<li><a class="" href="BayesianIntro.html"><span class="header-section-number">14</span> Introduction to Bayesian statistics</a></li>
<li class="book-part">Appendices</li>
<li><a class="" href="SymbolsUsed.html"><span class="header-section-number">A</span> Symbols used</a></li>
<li><a class="" href="UsefulSeries.html"><span class="header-section-number">B</span> Some useful series</a></li>
<li><a class="" href="ShortRIntro.html"><span class="header-section-number">C</span> Short R introduction</a></li>
<li><a class="" href="UseRDistributions.html"><span class="header-section-number">D</span> Using R with distributions</a></li>
<li><a class="" href="selected-solutions.html"><span class="header-section-number">E</span> Selected solutions</a></li>
<li><a class="" href="references.html"><span class="header-section-number">F</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PeterKDunn/DistTheory">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ChapterTransformations" class="section level1" number="6">
<h1>
<span class="header-section-number">6</span> Transformations of random variables<a class="anchor" aria-label="anchor" href="#ChapterTransformations"><i class="fas fa-link"></i></a>
</h1>
<div class="objectivesBox objectives">
<p>On completion of this chapter, you should be able to:</p>
<ul>
<li>derive the distribution of a transformed variable, given the distribution of the original variable, using the distribution function method, the change of variable method, and the moment-generating function method as appropriate.</li>
<li>find the joint distribution of two transformed variables in a bivariate situation.</li>
</ul>
</div>
<div id="introduction" class="section level2" number="6.1">
<h2>
<span class="header-section-number">6.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction"><i class="fas fa-link"></i></a>
</h2>
<p>
In this chapter, we consider the distribution of a random variable <span class="math inline">\(Y = u(X)\)</span>, given a random variable <span class="math inline">\(X\)</span> with known distribution, and a function <span class="math inline">\(u(\cdot)\)</span>.
Among several available techniques, three are considered:</p>
<ol style="list-style-type: decimal">
<li>the change of variable method (Sect. <a href="ChapterTransformations.html#ChangeOfVariable">6.2</a>);</li>
<li>the distribution function method for continuous random variable only (Sect. <a href="ChapterTransformations.html#DistributonFunctionMethod">6.3</a>);</li>
<li>the moment-generating function method (Sect. <a href="ChapterTransformations.html#TransformationMoments">6.4</a>).</li>
</ol>
<p>An important concept in this context is a <em>one-to-one transformation</em>.</p>
<div class="definition">
<p><span id="def:OneOneTransformation" class="definition"><strong>Definition 6.1  (One-to-one transformation) </strong></span>Given random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> with range spaces <span class="math inline">\(\mathcal{R}_X\)</span> and <span class="math inline">\(\mathcal{R}_Y\)</span> respectively, the function <span class="math inline">\(u(\cdot)\)</span> is a <em>one-to-one transformation</em> (or mapping) if, for each <span class="math inline">\(y\in \mathcal{R}_Y\)</span>, there corresponds exactly one <span class="math inline">\(x\in \mathcal{R}_X\)</span>.</p>
</div>
<p>When <span class="math inline">\(Y = u(X)\)</span> is a one-to-one transformation, the inverse function is uniquely defined; that is, <span class="math inline">\(X\)</span> can be written uniquely in terms of <span class="math inline">\(Y\)</span>.
This is important when considering the distribution of <span class="math inline">\(Y\)</span> when the distribution of <span class="math inline">\(X\)</span> is known.</p>
<div class="example">
<p><span id="exm:OneToOneTransformation" class="example"><strong>Example 6.1  </strong></span>The transformation <span class="math inline">\(Y = (X - 1)^2\)</span> is not a one-to-one transformation for <span class="math inline">\(\mathcal{R}_X = \mathbb{R}\)</span>; that is, if <span class="math inline">\(X\)</span> is defined on <span class="math inline">\((-\infty, +\infty)\)</span>.
For example, the inverse transformation is <span class="math inline">\(X = 1 \pm \sqrt{Y}\)</span>, and two values of <span class="math inline">\(X\)</span> exists for any given value of <span class="math inline">\(Y &gt; 0\)</span> (Fig. <a href="ChapterTransformations.html#fig:TwoTransforms">6.1</a>, left panel).</p>
<p>However, if the random variable <span class="math inline">\(X\)</span> is only defined for <span class="math inline">\(X &gt; 2\)</span>, then the transformation is a one-to-one function (Fig. <a href="ChapterTransformations.html#fig:TwoTransforms">6.1</a>, right panel).</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:TwoTransforms"></span>
<img src="06-Transformations_files/figure-html/TwoTransforms-1.png" alt="Two transformations: a non-one-to-one transformation (left panel), and a one-to-one transformation (right panel)." width="80%"><p class="caption">
FIGURE 6.1: Two transformations: a non-one-to-one transformation (left panel), and a one-to-one transformation (right panel).
</p>
</div>
</div>
<div id="ChangeOfVariable" class="section level2" number="6.2">
<h2>
<span class="header-section-number">6.2</span> The change of variable method<a class="anchor" aria-label="anchor" href="#ChangeOfVariable"><i class="fas fa-link"></i></a>
</h2>
<p>
The method is relatively straightforward for one-to-one transformations (such as <span class="math inline">\(Y = 1 - X\)</span> or <span class="math inline">\(Y = \exp(X)\)</span>).
Considerable care needs to be exercised if the transformation is not one-to-one; examples are given below.
The discrete and continuous cases are considered separately.</p>
<div id="ChangeOfVarDiscrete" class="section level3" number="6.2.1">
<h3>
<span class="header-section-number">6.2.1</span> Discrete random variables<a class="anchor" aria-label="anchor" href="#ChangeOfVarDiscrete"><i class="fas fa-link"></i></a>
</h3>
<p>Let <span class="math inline">\(X\)</span> be a discrete random variable with probability function <span class="math inline">\(p_X(x)\)</span>, and let <span class="math inline">\(\mathcal{R}_X\)</span> denote the set of discrete points for which <span class="math inline">\(p_X(x) &gt; 0\)</span>.
Let <span class="math inline">\(Y = u(X)\)</span> define a <em>one-to-one transformation</em> that maps <span class="math inline">\(\mathcal{R}_X\)</span> onto <span class="math inline">\(\mathcal{R}_Y\)</span>, the set of discrete points for which the transformed variable <span class="math inline">\(Y\)</span> has a non-zero probability.
If we solve <span class="math inline">\(Y = u(X)\)</span> for <span class="math inline">\(X\)</span> in terms of <span class="math inline">\(Y\)</span>, say <span class="math inline">\(X = w(Y) = u^{-1}(Y)\)</span>, then for each <span class="math inline">\(y \in \mathcal{R}_Y\)</span>, we have <span class="math inline">\(x = w(y)\in \mathcal{R}_X\)</span>.</p>
<div class="example">
<p><span id="exm:Transform1" class="example"><strong>Example 6.2  (One-to-one transformation) </strong></span>Suppose
<span class="math display">\[
   p_X(x) =
   \begin{cases}
      x/15 &amp; \text{for $x = 1, 2, 3, 4, 5$};\\
      0    &amp; \text{elsewhere}.
   \end{cases}
\]</span>
To find the probability function of <span class="math inline">\(Y\)</span> where <span class="math inline">\(Y = 2X + 1\)</span> (i.e., <span class="math inline">\(u(x) = 2x + 1\)</span>), first see that <span class="math inline">\(\mathcal{R}_X = \{1, 2, 3, 4, 5\}\)</span>.
Hence <span class="math inline">\(\mathcal{R}_Y = \{3, 5, 7, 9, 11\}\)</span> and the mapping <span class="math inline">\(y = 2x + 1 = u(x)\)</span> is one-to-one.
Also, <span class="math inline">\(w(y) = u^{-1}(y) = (y - 1)/2\)</span>.
Hence,
<span class="math display">\[
   \Pr(Y = y)
   = \Pr(2X + 1 = y)
   = \Pr\left(X = \frac{y - 1}{2}\right)
   = \left(\frac{y - 1}{2}\right) \times\frac{1}{15}
   = \frac{y - 1}{30}.
\]</span>
So the probability function of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
   \Pr(Y = y)
   = \begin{cases}
      (y - 1)/30 &amp; \text{for $y = 3, 5, 7, 9, 11$};\\
      0          &amp; \text{elsewhere}.
    \end{cases}
\]</span>
(Note: The probabilities in this probability function add to <span class="math inline">\(1\)</span>.)</p>
</div>
<p>The above procedure when <span class="math inline">\(Y = u(X)\)</span> is a one-to-one mapping can be stated generally as
<span class="math display">\[\begin{align*}
   \Pr(Y = y)
   &amp;= \Pr\big(u(X) = y\big)\\
   &amp;= \Pr\big(X = u^{-1} (y)\big)\\
   &amp;= p_X\big(u^{-1}(y)\big), \quad\text{for $y\in \mathcal{R}_Y$}.
\end{align*}\]</span></p>
<div class="example">
<p><span id="exm:Transform2" class="example"><strong>Example 6.3  (Transformation (1:1)) </strong></span>Let <span class="math inline">\(X\)</span> have a binomial distribution with probability function
<span class="math display">\[
   p_X(x) = \begin{cases}
               \binom{3}{x}0.2^x (0.8)^{3 - x} &amp; \text{for $x = 0, 1, 2, 3$};\\
               0 &amp; \text{otherwise}.
            \end{cases}
\]</span>
To find the probability function of <span class="math inline">\(Y = X^2\)</span>, first note that <span class="math inline">\(Y = X^2\)</span> is <em>not</em> a one-to-one transformation in general, but is over the range space of <span class="math inline">\(X\)</span> (i.e., for <span class="math inline">\(x = 0, 1, 2, 3\)</span>).</p>
<p>The transformation <span class="math inline">\(y = u(x) = x^2\)</span>, <span class="math inline">\(\mathcal{R}_X = \{ x \mid x = 0, 1, 2, 3 \}\)</span> maps onto <span class="math inline">\(\mathcal{R}_Y = \{y \mid y = 0, 1, 4, 9\}\)</span>.
The inverse function is <span class="math inline">\(x = w(y) = \sqrt{y}\)</span>, and hence the probability function of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
   p_Y(y) = p_X(\sqrt{y})
   = \begin{cases}
               \binom{3}{\sqrt{y}}0.2^{\sqrt{y}} (0.8)^{3 - \sqrt{y}} &amp; \text{for $y = 0, 1, 4, 9$};\\
               0 &amp; \text{otherwise}.
     \end{cases}
\]</span></p>
</div>
<p>When the transformation  <span class="math inline">\(u(\cdot)\)</span> is <em>not</em> 1:1, more care is needed.</p>
<div class="example">
<p><span id="exm:TransformNot11" class="example"><strong>Example 6.4  (Transformation not 1:1) </strong></span>Suppose <span class="math inline">\(\Pr(X = x)\)</span> is defined as in Example <a href="ChapterTransformations.html#exm:Transform1">6.2</a>, and define <span class="math inline">\(Y = |X - 3|\)</span>.
Since <span class="math inline">\(\mathcal{R}_Y = \{0, 1, 2\}\)</span> the mapping is <em>not</em> one-to-one: the event <span class="math inline">\(Y = 0\)</span> occurs if <span class="math inline">\(X = 3\)</span>, the event <span class="math inline">\(Y = 1\)</span> occurs if <span class="math inline">\(X = 2\)</span> or <span class="math inline">\(X = 4\)</span>, and the event <span class="math inline">\(Y = 2\)</span> occurs if <span class="math inline">\(X = 1\)</span> or <span class="math inline">\(X = 5\)</span>.
Hence, <span class="math inline">\(\mathcal{R}_Y  \{ 0, 1, 2\}\)</span>.</p>
<p>To find the probability distribution of <span class="math inline">\(Y\)</span>:
<span class="math display">\[\begin{align*}
   \Pr(Y = 0)
   &amp;= \Pr(X = 3) = 3/15 = \frac{1}{5};\\
   \Pr(Y = 1)
   &amp;= \Pr(X = 2 \text{ or } 4) = \frac{2}{15} + \frac{4}{15} = \frac{2}{5};\\
   \Pr(Y = 2)
   &amp;= \Pr(X = 1 \text{ or } 5) = \frac{1}{15} + \frac{5}{15} = \frac{2}{5}.
\end{align*}\]</span>
The probability function of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
   p_Y(y) =
   \begin{cases}
       1/5 &amp; \text{for $y = 0$};\\
       2/5 &amp; \text{for $y = 1$};\\
       2/5 &amp; \text{for $y = 2$};\\
       0   &amp; \text{elsewhere}.
   \end{cases}
\]</span></p>
</div>
</div>
<div id="ChangeOfVarContinuous" class="section level3" number="6.2.2">
<h3>
<span class="header-section-number">6.2.2</span> Continuous random variables<a class="anchor" aria-label="anchor" href="#ChangeOfVarContinuous"><i class="fas fa-link"></i></a>
</h3>
<div class="theorem">
<p><span id="thm:ChangeOfVarCont" class="theorem"><strong>Theorem 6.1  (Change of variable (continuous rv)) </strong></span>If <span class="math inline">\(X\)</span> has PDF <span class="math inline">\(f_X(x)\)</span> for <span class="math inline">\(x\in \mathcal{R}_X\)</span> and <span class="math inline">\(u(\cdot)\)</span> is a one-to-one function for <span class="math inline">\(x\in \mathcal{R}_X\)</span>, then the random variable <span class="math inline">\(Y = u(X)\)</span> has PDF
<span class="math display">\[
   f_Y(y) = f_X(x) \left|\frac{dx}{dy}\right|
\]</span>
where the right-hand side is expressed as a function of <span class="math inline">\(y\)</span>.
The term <span class="math inline">\(\left|dx/dy\right|\)</span> is called the <em>Jacobian of the transformation</em>.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-23" class="proof"><em>Proof</em>. </span>Let the inverse function be <span class="math inline">\(X = w(Y)\)</span> so that <span class="math inline">\(w(y) = u^{-1}(x)\)</span>.</p>
<p><strong>Case 1:</strong> <span class="math inline">\(y = u(x)\)</span> is a strictly <em>increasing</em> function (Fig. <a href="ChapterTransformations.html#fig:Transformation">6.2</a>, left panel).
If <span class="math inline">\(a &lt; y &lt; b\)</span> then <span class="math inline">\(w(a) &lt; x &lt; w(b)\)</span> and <span class="math inline">\(\Pr(a &lt; Y &lt; b) = \Pr\big(w(a) &lt; X &lt;w(b)\big)\)</span>, so
<span class="math display">\[
   {\int^b_a f_Y(y)\,dy
   =\int^{w(b)}_{w(a)}f_X(x)\,dx
   =\int^b_af\big( w(y)\big)\frac{dx}{dy}\,\,dy}.
\]</span>
Therefore, <span class="math inline">\(\displaystyle {f_Y(y) = f_X\big( w(y) \big)\frac{dx}{dy}}\)</span>, where <span class="math inline">\(w(y) = u^{-1}(x)\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Transformation"></span>
<img src="06-Transformations_files/figure-html/Transformation-1.png" alt="A strictly increasing transformation function (left panel) and strictly decreasing function (right panel)." width="100%"><p class="caption">
FIGURE 6.2: A strictly increasing transformation function (left panel) and strictly decreasing function (right panel).
</p>
</div>
<p><strong>Case 2:</strong> <span class="math inline">\(y = u(x)\)</span> is a strictly <em>decreasing</em> function of <span class="math inline">\(x\)</span> (Fig. <a href="ChapterTransformations.html#fig:Transformation">6.2</a>, right panel).
If <span class="math inline">\(a &lt; y &lt; b\)</span> then <span class="math inline">\(w(b) &lt; x &lt; w(a)\)</span> and <span class="math inline">\(\Pr(a &lt; Y &lt; b) = \Pr\big(w(b) &lt; X &lt; w(a)\big)\)</span>, so that
<span class="math display">\[\begin{align*}
     \int^b_a f_Y(y)\,dy &amp; = \int^{w(a)}_{w(b)}f_X(x)\,dx\\
     &amp; = \int^a_bf_X(x)\frac{dx}{dy}\,\,dy\\
     &amp; = - \int ^b_a f_X(x)\frac{dx}{dy}\,dy.
\end{align*}\]</span>
Therefore <span class="math inline">\(f_Y(y) = -f_X\left( w(y) \right)\displaystyle{\frac{dx}{dy}}\)</span>.
But <span class="math inline">\(dx/dy\)</span> is negative in the case of a decreasing function, so in general
<span class="math display">\[
   f_Y(y) = f_X(x)\left|\frac{dx}{dy} \right|.
\]</span></p>
</div>
<div class="example">
<p><span id="exm:Transform3" class="example"><strong>Example 6.5  (Transformation) </strong></span>Let the PDF of <span class="math inline">\(X\)</span> be given by
<span class="math display">\[
   f_X(x) =
   \begin{cases}
      1 &amp; \text{for $0 &lt; x &lt; 1$};\\
      0 &amp; \text{elsewhere}.
   \end{cases}
\]</span>
Consider the transformation <span class="math inline">\(Y = u(X) = -2\log X\)</span> (where <span class="math inline">\(\log\)</span> refers to logarithms to base <span class="math inline">\(e\)</span>, or <em>natural logarithms</em>).
The transformation is one-to-one, and the inverse transformation is
<span class="math display">\[
   X = \exp( -Y/2) = u^{-1}(Y) = w(Y).
\]</span>
The space <span class="math inline">\(\mathcal{R}_X = \{x \mid 0 &lt; x &lt; 1\}\)</span> is mapped to <span class="math inline">\(\mathcal{R}_Y = \{y \mid 0 &lt; y &lt; \infty\}\)</span>.
Then,
<span class="math display">\[
   w'(y) = \frac{d}{dy} \exp(-y/2) = -\frac{1}{2}\exp(-y/2),
\]</span>
and so the <em>Jacobian</em> of the transformation <span class="math inline">\(|w'(y)| = \exp(-y/2)/2\)</span>.
The PDF of <span class="math inline">\(Y = -2\log X\)</span> is
<span class="math display">\[\begin{align*}
   f_Y(y)
   &amp;= f_X\big(w(y)\big) |w'(y)| \\
   &amp;= f_X\big(\exp(-y/2)\big) \exp(-y/2)/2 \\
   &amp;= \frac{1}{2}\exp(-y/2)\quad\text{for $y &gt; 0$}.
\end{align*}\]</span>
That is, <span class="math inline">\(Y\)</span> has an exponential distribution with <span class="math inline">\(\beta = 2\)</span>: <span class="math inline">\(Y \sim \text{Exp}(2)\)</span> (Def. <a href="ContinuousDistributions.html#def:ExponentialDistribution">8.8</a>).</p>
</div>
<div class="example">
<p><span id="exm:TransformSquRt" class="example"><strong>Example 6.6  (Square root transformation) </strong></span>Consider the random variable <span class="math inline">\(X\)</span> with PDF <span class="math inline">\(f_X(x) = e^{-x}\)</span> for <span class="math inline">\(x \geq 0\)</span>.
To find the PDF of <span class="math inline">\(Y = \sqrt{X}\)</span>, first see that <span class="math inline">\(y = \sqrt{x}\)</span> is a strictly increasing function for <span class="math inline">\(x \geq 0\)</span> (Fig. <a href="ChapterTransformations.html#fig:SqrtRt">6.3</a>).</p>
<p>The inverse relation is <span class="math inline">\(X = Y^2\)</span>, and <span class="math inline">\(dx/dy = |2y| = 2y\)</span> for <span class="math inline">\(x \ge 0\)</span>.
The PDF of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
    f_Y(y)
    = f_X(x)\left|\frac{dx}{dy}\right|
    = 2y e^{-y^2}\quad \text{for $y\geq0$}.
\]</span></p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:SqrtRt"></span>
<img src="06-Transformations_files/figure-html/SqrtRt-1.png" alt="The square-root transformation (left panel); the PDF of $X$ (centre panel) and the PDF of $Y$ (right panel)." width="100%"><p class="caption">
FIGURE 6.3: The square-root transformation (left panel); the PDF of <span class="math inline">\(X\)</span> (centre panel) and the PDF of <span class="math inline">\(Y\)</span> (right panel).
</p>
</div>
<div class="example">
<p><span id="exm:TransformationTan" class="example"><strong>Example 6.7  (Tan transformation) </strong></span>Let random variable <span class="math inline">\(X\)</span> be uniformly distributed on <span class="math inline">\([-\pi/2, \pi/2]\)</span>.
Suppose we seek the distribution of <span class="math inline">\(Y = \tan X\)</span> (Fig. <a href="ChapterTransformations.html#fig:TanXform">6.4</a>).</p>
<p>For the mapping <span class="math inline">\(Y = \tan X\)</span>, we see that <span class="math inline">\(\mathcal{R}_Y = \{ y\mid -\infty &lt;y&lt;\infty\}\)</span>.
The mapping is one-to-one, and so <span class="math inline">\(X = \tan^{-1}Y\)</span>, and <span class="math inline">\(dx/dy = 1/(1 + y^2)\)</span>.
Hence
<span class="math display">\[
   f_Y(y)
   = f_X(x)\left|\frac{dx}{dy}\right|
   = \frac{1}{\pi(1 + y^2)}.
\]</span>
This is the <a href="exr:C3Cauchy"><em>Cauchy distribution</em></a>.</p>
</div>
<!-- CONNECT TO KICKINGA  FOOTBALL -->
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:TanXform"></span>
<img src="06-Transformations_files/figure-html/TanXform-1.png" alt="The tan transformation (left panel); the PDF of $X$ (centre panel) and the PDF of $Y$ (right panel)." width="100%"><p class="caption">
FIGURE 6.4: The tan transformation (left panel); the PDF of <span class="math inline">\(X\)</span> (centre panel) and the PDF of <span class="math inline">\(Y\)</span> (right panel).
</p>
</div>
<p>A case where the function <span class="math inline">\(u(\cdot)\)</span> is <em>not</em> a one-to-one transformation is considered using an example, using a modification of Theorem <a href="ChapterTransformations.html#thm:ChangeOfVarCont">6.1</a>.</p>
<div class="example">
<p><span id="exm:TransformationNon11" class="example"><strong>Example 6.8  (Transformation (not 1:1)) </strong></span>Given a random variable <span class="math inline">\(Z\)</span> which follows a <span class="math inline">\(N(0, 1)\)</span> distribution, suppose we seek the probability distribution of <span class="math inline">\(Y = \frac{1}{2} Z^2\)</span>.</p>
<p>The relationship <span class="math inline">\(Y = u(Z) = \frac{1}{2}z^2\)</span> is not strictly increasing or decreasing in <span class="math inline">\((-\infty, \infty )\)</span> so Theorem <a href="ChapterTransformations.html#thm:ChangeOfVarCont">6.1</a> cannot be applied directly.
Instead, subdivide the range of <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span> so that in each portion the relationship <em>is</em> monotonic.
Then:
<span class="math display">\[
   f_Z(z) =
   \frac{1}{\sqrt{2\pi}}\,e^{-\frac{1}{2} z^2}\quad\text{for $-\infty &lt; z &lt; \infty$}.
\]</span>
The inverse relation, <span class="math inline">\(Z = u^{-1}(Y)\)</span> is <span class="math inline">\(Z = \pm \sqrt{2Y}\)</span>.
For a given value of <span class="math inline">\(Y\)</span>, two values of <span class="math inline">\(Z\)</span> are possible.
However, in the range <span class="math inline">\(-\infty &lt; z &lt; 0\)</span>, <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span> have a monotonic relationship.
Similarly, for <span class="math inline">\(0 &lt; z &lt;\infty\)</span>, <span class="math inline">\(Y\)</span> and <span class="math inline">\(Z\)</span> have a monotonic relationship.
Thus (see Fig. <a href="ChapterTransformations.html#fig:Non11Xform">6.5</a>),
<span class="math display">\[
   \Pr(a &lt; Y &lt;b) = \Pr(-\sqrt{2b} &lt; Z &lt; -\sqrt{2a}\,) + \Pr(\sqrt{2a} &lt; Z &lt; \sqrt{2b}\,).
\]</span>
The two terms on the right are equal because the distribution of <span class="math inline">\(Z\)</span> is symmetrical about <span class="math inline">\(z = 0\)</span>.
Thus <span class="math inline">\(\Pr(a &lt; Y &lt; b) = 2\Pr(\sqrt{2a} &lt; Z &lt; \sqrt{2b}\,)\)</span>, and
<span class="math display">\[\begin{align*}
     f_Y(y)
     &amp;= 2f_Z(z)\left| \frac{dz}{dy}\right|\\
     &amp;= 2\frac{1}{\sqrt{2\pi}}e^{-y}\frac{1}{\sqrt{2y}};
\end{align*}\]</span>
that is,
<span class="math display">\[
   f_Y(y)
   = e^{-y}y^{-\frac{1}{2}} / \sqrt{\pi}\quad\text{for $0 &lt; y &lt; \infty$}.
\]</span>
This PDF is a <a href="GammaDistribution">gamma distribution</a> with parameters <span class="math inline">\(\alpha = 1/2\)</span> and <span class="math inline">\(\beta = 1\)</span>.
It follows that if <span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>, then the PDF of <span class="math inline">\(Y = \frac{1}{2} (X - \mu )^2 / \sigma^2\)</span> is <span class="math inline">\(\text{Gamma}(\alpha = 1/2,\beta = 1)\)</span> since then <span class="math inline">\((X - \mu)/\sigma\)</span> is distributed as <span class="math inline">\(N(0, 1)\)</span>.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:Non11Xform"></span>
<img src="06-Transformations_files/figure-html/Non11Xform-1.png" alt="A transformation not 1:1." width="50%"><p class="caption">
FIGURE 6.5: A transformation not 1:1.
</p>
</div>
<p>Note that the probability can only be doubled as in Example <a href="ChapterTransformations.html#exm:TransformationNon11">6.8</a> if both <span class="math inline">\(Y = u(Z)\)</span> and the PDF of <span class="math inline">\(Z\)</span> are symmetrical about the same point.
</p>
</div>
<div id="ChangeOfVarDiscreteBivariate" class="section level3" number="6.2.3">
<h3>
<span class="header-section-number">6.2.3</span> Discrete bivariate case????<a class="anchor" aria-label="anchor" href="#ChangeOfVarDiscreteBivariate"><i class="fas fa-link"></i></a>
</h3>
<p>The bivariate case is similar to the univariate case.
Consider a joint probability function <span class="math inline">\(p_{X_1, X_2}(x_1, x_2)\)</span> of two discrete random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> defined on the two-dimensional set of points <span class="math inline">\(R^2_X\)</span> for which <span class="math inline">\(p(x_1, x_2) &gt; 0\)</span>.
There are now two <em>one-to-one transformations</em>:
<span class="math display">\[
   y_1 = u_1( x_1, x_2)\qquad\text{and}\qquad y_2 = u_2( x_1, x_2)
\]</span>
that map <span class="math inline">\(R^2_X\)</span> onto <span class="math inline">\(R^2_Y\)</span> (the two-dimensional set of points for which <span class="math inline">\(p(y_1, y_2) &gt; 0\)</span>).
The two inverse functions are
<span class="math display">\[
   x_1 = w_1( y_1, y_2)\qquad\text{and}\qquad x_2 = w_2( y_1, y_2).
\]</span>
Then the joint probability function of the new (transformed) random variables is
<span class="math display">\[
   p_{Y_1, Y_2}(y_1, y_2) =
   \begin{cases}
      p_{X_1, X_2}\big( w_1(y_1, y_2), w_2(y_1, y_2)\big) &amp; \text{where $(y_1, y_2)\in R^2_Y$};\\
      0 &amp; \text{elsewhere}.
   \end{cases}
\]</span></p>
<div class="example">
<p><span id="exm:TransformBivariate" class="example"><strong>Example 6.9  (Transformation (bivariate)) </strong></span>Let the two discrete random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> have the joint probability function shown in Table <a href="ChapterTransformations.html#tab:Bivar4">6.1</a>.
Consider the two one-to-one transformations
<span class="math display">\[
   Y_1 = X_1 + X_2 \qquad\text{and}\qquad Y_2 = 2 X_1.
\]</span>
The joint probability function of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> can be found by noting where the <span class="math inline">\((x_1, x_2)\)</span> pairs are mapped to in the <span class="math inline">\(y_1, y_2\)</span> space:</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="center"><span class="math inline">\((x_1, x_2)\)</span></th>
<th align="center"><span class="math inline">\(\mapsto\)</span></th>
<th align="center"><span class="math inline">\((y_1,y_2)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\((-1, 0)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((-1, -2)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\((-1, 1)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((0, -2)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\((-1, 2)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((1, -2)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\((1, 0)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((1, 2)\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\((1, 1)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((2, 2)\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\((1, 2)\)</span></td>
<td align="center"><span class="math inline">\(\mapsto\)</span></td>
<td align="center"><span class="math inline">\((3, 2)\)</span></td>
</tr>
</tbody>
</table></div>
<p>The joint probability function can then be constructed as shown in Table <a href="ChapterTransformations.html#tab:Bivar5">6.2</a>.</p>
</div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:Bivar4">TABLE 6.1: </span>A bivariate probability function
</caption>
<thead><tr>
<th style="text-align:right;font-weight: bold;">
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(x_2 = 0\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(x_2 = 1\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(x_2 = 2\)</span>
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
<span class="math inline">\(x_1 = -1\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.3\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(x_1 = +1\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
</tr>
</tbody>
</table></div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:Bivar5">TABLE 6.2: </span>The joint probability function for <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>
</caption>
<thead><tr>
<th style="text-align:right;font-weight: bold;">
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(y_1 = -1\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(y_1 = 0\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(y_1 = 1\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(y_1 = 2\)</span>
</th>
<th style="text-align:right;font-weight: bold;">
<span class="math inline">\(y_1 = 3\)</span>
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
<span class="math inline">\(y_2 = -2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.3\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.0\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.0\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;">
<span class="math inline">\(y_2 = +2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.0\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.0\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.2\)</span>
</td>
<td style="text-align:right;">
<span class="math inline">\(0.1\)</span>
</td>
</tr>
</tbody>
</table></div>
<p>Sometimes, a joint probability function of two random variables is given, but only <em>one</em> new random variable is required.
In this case, a second (dummy) transformation is used, usually a very simple transformation.</p>
<div class="example">
<p><span id="exm:TransformBivariate2" class="example"><strong>Example 6.10  (Transformation (bivariate)) </strong></span>Let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> be two independent random variables with the joint probability function
<span class="math display">\[
   p_{X_1, X_2}(x_1, x_2) =
         \frac{\mu_1^{x_1} \mu_x^{x_2} \exp( -\mu_1 - \mu_2 )}{x_1!\, x_2!}
         \quad\text{for $x_1$ and $x_2 = 0, 1, 2, \dots$}
\]</span>
This is the joint probability function of two independent Poisson random variables.
Suppose we wish to find the probability function of <span class="math inline">\(Y_1 = X_1 + X_2\)</span>.</p>
<p>Consider the two <em>one-to-one transformations</em>, where <span class="math inline">\(Y_2 = X_2\)</span> is just a dummy transformation:
<span class="math display">\[\begin{align}
   y_1 &amp;= x_1 + x_2             = u_1(x_1, x_2)\\
   y_2 &amp;= x_2\phantom{{} + x_2} = u_2(x_1, x_2)
\end{align}\]</span>
which map the points in <span class="math inline">\(R^2_X\)</span> onto
<span class="math display">\[
   R^2_Y = \left\{ (y_1, y_2)\mid y_1 = 0, 1, 2, \dots; y_2 = 0, 1, 2, \dots, y_1\right\}.
\]</span>
<span class="math inline">\(Y_2\)</span> is a dummy transform, and so is chosen to be very simple.
Any second transform could be chosen (as it is not of direct interest), and so choose one that is simple.
The inverse functions are
<span class="math display">\[\begin{align*}
   x_1 &amp;= y_1 - y_2              = w_1(y_1, y_2)\\
   x_2 &amp;= y_2 \phantom{{} - y_2} = w_2(y_2)
\end{align*}\]</span>
by rearranging the original transformations.
Then the <em>joint</em> probability function of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> is
<span class="math display">\[\begin{align*}
   p_{Y_1, Y_2}(y_1, y_2)
   &amp;= p_{X_1, X_2}\big( w_1(y_1, y_2), w_2(y_1, y_2)\big) \\
   &amp;= \frac{\mu_1^{y_1 - y_2}\mu_2^{y_2} \exp(-\mu_1 - \mu_2)}{(y_1 - y_2)! y_2!}\quad
   \text{for $(y_1, y_2)\in R^2_Y$}.
\end{align*}\]</span>
Recall that we seek the probability function of just <span class="math inline">\(Y_1\)</span>, so we need to find the marginal probability function of <span class="math inline">\(p_{Y_1, Y_2}(y_1, y_2)\)</span>.
The marginal probability function of <span class="math inline">\(Y_1\)</span> is
<span class="math display">\[
   p_{Y_1}(y_1) = \sum_{y_2 = 0}^{y_1} p_{Y_1, Y_2}(y_1, y_2)
   = \sum_{y_2 = 0}^{y_1} \frac{\mu_1^{y_1 - y_2}\mu_2^{y_2} \exp(-\mu_1 - \mu_2)}{(y_1 - y_2)!\, y_2!},
\]</span>
which is equivalent to
<span class="math display">\[
   p_{Y_1}(y_1) =
   \begin{cases}
      \displaystyle{\frac{(\mu_1 + \mu_2)^{y_1}\exp\big[-(\mu_1 + \mu_2)\big]}{y_1!}} &amp; \text{for $y_1 = 0, 1, 2, \dots$}\\
      0 &amp; \text{otherwise}.
   \end{cases}
\]</span>
You should recognise this as the probability function of a Poisson random variable (Def. <a href="DiscreteDistributions.html#def:PoissonDistribution">7.12</a>) with mean <span class="math inline">\(\mu_1 + \mu_2\)</span>.
Thus <span class="math inline">\(Y_1 \sim \text{Pois}(\lambda = \mu_1 + \mu_2)\)</span>.</p>
</div>
</div>
</div>
<div id="DistributonFunctionMethod" class="section level2" number="6.3">
<h2>
<span class="header-section-number">6.3</span> The distribution function method<a class="anchor" aria-label="anchor" href="#DistributonFunctionMethod"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<div class="importantBox important">
<p>This method only works for continuous random variables.</p>
</div>
<p>The distribution function method involves two steps:</p>
<ol style="list-style-type: decimal">
<li>Find the <em>distribution function</em> of the transformed variable.</li>
<li>Differentiate this distribution function to find the <em>probability density function</em>.</li>
</ol>
<p>The procedure is best demonstrated using an example.</p>
<div class="example">
<p><span id="exm:DFMethod" class="example"><strong>Example 6.11  (Distribution function method) </strong></span>Consider the random variable <span class="math inline">\(X\)</span> with PDF
<span class="math display">\[
   f_X(x) = \begin{cases}
               x/4 &amp; \text{for $1 &lt; x &lt; 3$};\\
               0 &amp; \text{elsewhere}.
            \end{cases}
\]</span>
To find the PDF of the random variable <span class="math inline">\(Y\)</span> where <span class="math inline">\(Y = X^2\)</span>, first see that <span class="math inline">\(1 &lt; y &lt; 9\)</span> and the transformation is monotonic over this region.
The distribution function for <span class="math inline">\(Y\)</span> is
<span class="math display">\[\begin{align*}
   F_Y(y)
   &amp;= \Pr(Y\le y) \qquad\text{(by definition)}\\
   &amp;= \Pr(X^2 \le y) \qquad\text{(since $Y = X^2$)}\\
   &amp;= \Pr(X\le \sqrt{y}\,).
\end{align*}\]</span>
This last step is not trivial, but is critical.
Sometimes, more care is needed (see Example <a href="ChapterTransformations.html#exm:TransformA">6.12</a>).
In this case, there is a one-to-one relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> over the region of which <span class="math inline">\(X\)</span> is defined (i.e., has a positive probability); see Fig. <a href="ChapterTransformations.html#fig:SquaringXform">6.6</a>.</p>
<p>Then continue as follows:
<span class="math display">\[\begin{align*}
   F_Y(y)
    =\Pr( X\le \sqrt{y}\,)
   &amp;= F_X\big(\sqrt{y}\,\big) \qquad\text{(definition of $F_X(x)$)} \\
   &amp;= \int_1^{\sqrt{y}} (x/4) \,dx
    = (y - 1)/8
\end{align*}\]</span>
for <span class="math inline">\(1 &lt; y &lt; 9\)</span>, and is zero elsewhere.
This is the <em>distribution function</em> of <span class="math inline">\(Y\)</span>; to find the PDF:
<span class="math display">\[
   f_Y(y)
   = \frac{d}{dy} (y - 1)/8
   = \begin{cases}
        1/8 &amp; \text{for $1 &lt; y &lt; 9$};\\
        0 &amp; \text{elsewhere}.
     \end{cases}
\]</span>
Note the range for which <span class="math inline">\(Y\)</span> is defined; since <span class="math inline">\(1 &lt; x &lt; 3\)</span>, then <span class="math inline">\(1 &lt; y &lt; 9\)</span>.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:SquaringXform"></span>
<img src="06-Transformations_files/figure-html/SquaringXform-1.png" alt="The transformation $Y = X^2$ when $X$ is defined from $1$ to $3$. The thicker line corresponds to the region where the transformation applies. Note that if $Y &lt; y$, then $2 - \sqrt{y - 1} &lt; X &lt; 2 + \sqrt{y - 1}$." width="100%"><p class="caption">
FIGURE 6.6: The transformation <span class="math inline">\(Y = X^2\)</span> when <span class="math inline">\(X\)</span> is defined from <span class="math inline">\(1\)</span> to <span class="math inline">\(3\)</span>. The thicker line corresponds to the region where the transformation applies. Note that if <span class="math inline">\(Y &lt; y\)</span>, then <span class="math inline">\(2 - \sqrt{y - 1} &lt; X &lt; 2 + \sqrt{y - 1}\)</span>.
</p>
</div>
<div class="example">
<p><span id="exm:TransformA" class="example"><strong>Example 6.12  (Transformation) </strong></span>Consider the same random variable <span class="math inline">\(X\)</span> as in the previous example, but the transformation <span class="math inline">\(Y = (X - 2)^2 + 1\)</span> (Fig. <a href="ChapterTransformations.html#fig:SquaringXform2">6.7</a>).</p>
<p>In this case, the transformation is <strong>not</strong> a one-to-one transform.
Proceed as before to find the distribution function of <span class="math inline">\(Y\)</span>:
<span class="math display">\[\begin{align*}
   F_Y(y)
   &amp;= \Pr(Y\le y) \qquad\text{(by definition)}\\
   &amp;= \Pr\big( (X - 2)^2 + 1  \le y\big)
\end{align*}\]</span>
since <span class="math inline">\(Y = (X - 2)^2 + 1\)</span>.
From Fig. <a href="ChapterTransformations.html#fig:SquaringXform2">6.7</a>, whenever <span class="math inline">\((X - 2)^2 + 1 &lt; y\)</span> for some value <span class="math inline">\(y\)</span>, then <span class="math inline">\(X\)</span> must be in the range <span class="math inline">\(2 - \sqrt{y - 1}\)</span> to <span class="math inline">\(2 + \sqrt{y - 1}\)</span>.
So:
<span class="math display">\[\begin{align*}
   F_Y(y)
   &amp;= \Pr\big( (X - 2)^2 + 1 \le y\big) \\
   &amp;= \Pr\left( 2 - \sqrt{y - 1} &lt; X &lt; 2 + \sqrt{y - 1} \right)\\
   &amp;= \int_{2-\sqrt{y - 1}}^{2 + \sqrt{y - 1}} x/4\,dx \\
   &amp;= \left.\frac{1}{8} x^2\right|_{2 - \sqrt{y - 1}}^{2 + \sqrt{y - 1}} \\
   &amp;= \frac{1}{8} \left[ \left(2 + \sqrt{y - 1}\right)^2 - \left(2 - \sqrt{y - 1}\right)^2\right] \\
   &amp;=  \sqrt{y - 1}.
\end{align*}\]</span>
Again, this is the distribution function; so differentiating:
<span class="math display">\[
   f_Y(y) = \begin{cases}
               \frac{1}{2\sqrt{y - 1}} &amp; \text{for $1 &lt; y &lt; 2$};\\
               0 &amp; \text{elsewhere}.
            \end{cases}
\]</span></p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:SquaringXform2"></span>
<img src="06-Transformations_files/figure-html/SquaringXform2-1.png" alt="The transformation $Y = (X - 2)^2 + 1$ when $X$ is defined from $1$ to $3$. The thicker line corresponds to the region where the transformation applies. Note that if $Y &lt; y$, then $2 - \sqrt{y - 1} &lt; X &lt; 2 + \sqrt{y - 1}$." width="480"><p class="caption">
FIGURE 6.7: The transformation <span class="math inline">\(Y = (X - 2)^2 + 1\)</span> when <span class="math inline">\(X\)</span> is defined from <span class="math inline">\(1\)</span> to <span class="math inline">\(3\)</span>. The thicker line corresponds to the region where the transformation applies. Note that if <span class="math inline">\(Y &lt; y\)</span>, then <span class="math inline">\(2 - \sqrt{y - 1} &lt; X &lt; 2 + \sqrt{y - 1}\)</span>.
</p>
</div>
<div class="example">
<p><span id="exm:TransformB" class="example"><strong>Example 6.13  (Transformation) </strong></span>Example <a href="ChapterTransformations.html#exm:TransformationNon11">6.8</a> is repeated here using the distribution function method.
Given <span class="math inline">\(Z\)</span> is distributed <span class="math inline">\(N(0, 1)\)</span> we seek the probability distribution of <span class="math inline">\(Y = \frac{1}{2} Z^2\)</span>.
First,
<span class="math display">\[
   f_Z(z)
   = (2\pi )^{-\frac 12}\,e^{-z^2/2}\quad\text{for $z\in (-\infty ,\,\infty )$}.
\]</span>
Let <span class="math inline">\(Y\)</span> have PDF <span class="math inline">\(f_Y(y)\)</span> and df <span class="math inline">\(F_Y(y)\)</span>.
Then
<span class="math display">\[\begin{align*}
     F_Y(y)
      = \Pr(Y\leq y)
     &amp;= \Pr\left(\frac{1}{2}Z^2\leq y\right)\\
     &amp;= \Pr(Z^2\leq 2y)\\
     &amp; = \Pr(-\sqrt{2y}\leq Z\leq \sqrt{2y}\,)\\
     &amp; = F_Z(\sqrt{2y}\,) - F_Z(-\sqrt{2y}\,)
\end{align*}\]</span>
where <span class="math inline">\(F_Z\)</span> is the distribution function of <span class="math inline">\(Z\)</span>.
Hence
<span class="math display">\[\begin{align*}
     f_Y(y)
       = F_Y'(y)
     &amp;= F_Z'(\sqrt{2y}\,)-F_Z'(-\sqrt{2y}\,)\\
     &amp;= \frac{\sqrt{2}}{2\sqrt{y}}f_Z(\sqrt{2y}\,) - \frac{\sqrt{2}}{-
2\sqrt{y}}f_Z(-\sqrt{2y}\,)\\[2mm]
     &amp;= \frac{1}{\sqrt{2y}}[f_Z(\sqrt{2y}\,) + f_Z(-\sqrt{2y}\,)]\\
     &amp;= \frac{1}{\sqrt{2y}} \left[ \frac{1}{\sqrt{2\pi}}\,e^{-y}+\frac{1}{\sqrt{2\pi}}\,e^{-y}\right]\\
     &amp;= \frac{e^{-y}y^{-\frac{1}{2}}}{\sqrt{\pi}}
\end{align*}\]</span>
as before.</p>
</div>
<p>Care is needed to ensure the steps are followed logically.
Diagrams like Fig. <a href="ChapterTransformations.html#fig:SquaringXform">6.6</a> and <a href="ChapterTransformations.html#fig:SquaringXform2">6.7</a> are encouraged.</p>
<div class="importantBox important">
<p>The functions that are produced should be PDFs; check that this is the case.</p>
</div>
<p>This method can also be used when there is more than one variable of interest, but we do not cover this.
</p>
</div>
<div id="TransformationMoments" class="section level2" number="6.4">
<h2>
<span class="header-section-number">6.4</span> The moment-generating function method<a class="anchor" aria-label="anchor" href="#TransformationMoments"><i class="fas fa-link"></i></a>
</h2>
<p>
The moment-generating function (MGF) method is useful for finding the distribution of a linear combination of <span class="math inline">\(n\)</span> independent random variables.
The method essentially involves the computation of the MGF of the transformed variable <span class="math inline">\(Y = u(X_1, X_2, \dots, X_n)\)</span> when the joint distribution of independent <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> is given.</p>
<p>The MGF method relies on this observation: since the MGF of a random variable (if it exists) completely specifies the distribution of the random variable, then if two random variables have the same MGF they must have identical distributions.
Below, the transformation <span class="math inline">\(Y = X_1 + X_2 + \cdots X_n\)</span> is demonstrated, but the same principles can be applied for other linear combinations also.</p>
<p>Consider <span class="math inline">\(n\)</span> independent random variables <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> with MGFs <span class="math inline">\(M_{X_1}(t)\)</span>, <span class="math inline">\(M_{X_2}(t)\)</span>, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(M_{X_n}(t)\)</span>, and consider the transformation <span class="math inline">\(Y = X_1 + X_2 + \cdots X_n\)</span>.
Since the <span class="math inline">\(X_i\)</span> are independent, <span class="math inline">\(f_{X_1,X_2\dots X_n}(x_1, x_2, \dots, x_n) = f_{X_1}(x_1).f_{X_2}(x_2)\dots f_{X_n}(x_n)\)</span>.
So, by definition of the MGF,
<span class="math display">\[\begin{align*}
   M_Y(t)
   &amp;= \operatorname{E}(\exp(tY)) \\
   &amp;= \operatorname{E}(\exp[t(X_1 + X_2 + \cdots X_n)]) \\
   &amp;= \int\!\!\!\int\!\!\!\cdots\!\!\!\int \exp[t(x_1 + x_2 + \cdots x_n)] f(x_1, x_2, \dots x_n)\,dx_n\dots dx_2\, dx_1 \\
   &amp;= \int\!\!\!\int\!\!\!\cdots\!\!\!\int \exp(tx_1) f(x_1) \exp(t{x_2}) f(x_2)\dots \exp(t{x_n})f(x_n) \,dx_n\dots dx_2\, dx_1 \\
   &amp;= \int \exp(t x_1) f(x_1)\,dx_1 \int \exp(t{x_2}) f(x_2)\,dx_2 \dots \int \exp(t{x_n})f(x_n)\,dx_n \\
   &amp;= M_{X_1}(t) M_{X_2}(t)\dots M_{X_n}(t) \\
   &amp;= \prod_{i = 1}^n M_{X_i}(t).
\end{align*}\]</span>
(<span class="math inline">\(\prod\)</span> is the symbol for a <em>product</em> of terms, in the same way that <span class="math inline">\(\sum\)</span> is the symbol for a <em>summation</em> of terms.)
The above result also holds for discrete variables, where summations replace integrations.</p>
<p>This result follows: if <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> are independent random variables and <span class="math inline">\(Y  =  X_1 + X_2 + \dots + X_n\)</span>, then the MGF of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
   M_Y(t)  =  \prod_{i = 1}^n M_{X_i}(t)
\]</span>
where <span class="math inline">\(M_{X_i}(t)\)</span> is the MGF of <span class="math inline">\(X_i\)</span> at <span class="math inline">\(t\)</span> for <span class="math inline">\(i = 1, 2, \dots, n\)</span>.</p>
<div class="example">
<p><span id="exm:MGFLinearX" class="example"><strong>Example 6.14  (MGF method for transformations) </strong></span>Suppose that <span class="math inline">\(X_i \sim \text{Pois}(\lambda_i)\)</span> for <span class="math inline">\(i  =  1, 2, \dots, n\)</span>, and we wish to find the distribution of <span class="math inline">\(Y  =  X_1  +  X_2  + \dots  +  X_n\)</span>.</p>
<p>Since <span class="math inline">\(X_i\)</span> has a Poisson distribution with parameter <span class="math inline">\(\lambda_i\)</span> for <span class="math inline">\(i, 2, \dots n\)</span>, the MGF of <span class="math inline">\(X_i\)</span> is
<span class="math display">\[
   M_{X_i}(t) = \exp[ \lambda_i(e^t - 1)].
\]</span>
The MGF of <span class="math inline">\(Y  = X_1 + X_2 + \cdots X_n\)</span> is
<span class="math display">\[\begin{align*}
   M_Y(t)
   &amp;= \prod_{i = 1}^n \exp[ \lambda_i(e^t - 1)] \\
   &amp;= \exp[ \lambda_1(e^t - 1)] \exp[ \lambda_2(e^t - 1)] \dots \exp[ \lambda_n(e^t - 1)] \\
   &amp;= \exp\left[ (e^t - 1)\sum_{i = 1}^n \lambda_i\right].
\end{align*}\]</span>
Using <span class="math inline">\(\Lambda = \sum_{i = 1}^n \lambda_i\)</span>, the MGF of <span class="math inline">\(Y\)</span> is
<span class="math display">\[
   M_Y(t) = \exp\left[ (e^t - 1)\Lambda \right],
\]</span>
which is the MGF of a Poisson distribution with mean <span class="math inline">\(\Lambda = \sum_{i = 1}^n \lambda_i\)</span>.
This means that the sum of <span class="math inline">\(n\)</span> independent Poisson distribution is also a Poisson distribution, whose mean is the sum of the individual Poisson means.</p>
</div>
<p></p>
<p></p>
</div>
<div id="exercises" class="section level2" number="6.5">
<h2>
<span class="header-section-number">6.5</span> Exercises<a class="anchor" aria-label="anchor" href="#exercises"><i class="fas fa-link"></i></a>
</h2>
<p>Selected answers appear in Sect. <a href="selected-solutions.html#AnswersChapterTransformations">E.6</a>.</p>
<div class="exercise">
<p><span id="exr:X2" class="exercise"><strong>Exercise 6.1  </strong></span>Suppose the PDF of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[
   f_X(x) = \begin{cases}
                x/2 &amp; \text{$0 &lt; x &lt; 2$};\\
                0 &amp; \text{otherwise}.
             \end{cases}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Find the PDF of <span class="math inline">\(Y = X^3\)</span> using the change of variable method.</li>
<li>Find the PDF of <span class="math inline">\(Y = X^3\)</span> using the distribution function method.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:JointDiscrete" class="exercise"><strong>Exercise 6.2  </strong></span>The discrete bivariate random vector <span class="math inline">\((X_1, X_2)\)</span> has the joint probability function
<span class="math display">\[
   f_{X_1, X_2}(x_1, x_2) =
   \begin{cases}
      (2x_1+ x _2)/6 &amp; \text{for $x_1 = 0, 1$ and $x_2 = 0, 1$};\\
      0               &amp; \text{elsewhere}.
   \end{cases}
\]</span>
Consider the transformations
<span class="math display">\[\begin{align*}
   Y_1 &amp;= X_1 + X_2 \\
   Y_2 &amp;= \phantom{X_1+{}} X_2
\end{align*}\]</span></p>
<ol style="list-style-type: decimal">
<li>Determine the joint probability function of <span class="math inline">\((Y_1, Y_2)\)</span>.</li>
<li>Deduce the distribution of <span class="math inline">\(Y_1\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:GammaSum" class="exercise"><strong>Exercise 6.3  </strong></span>Consider <span class="math inline">\(n\)</span> random variables <span class="math inline">\(X_i\)</span> such that <span class="math inline">\(X_i \sim \text{Gam}(\alpha_i, \beta)\)</span>.
Determine the distribution of <span class="math inline">\(Y = \sum_{i = 1}^n X_i\)</span> using MGFs.</p>
</div>
<div class="exercise">
<p><span id="exr:CauchySquared" class="exercise"><strong>Exercise 6.4  </strong></span>The random variable <span class="math inline">\(X\)</span> has PDF
<span class="math display">\[
   f_X(x) = \frac{1}{\pi(1 + x^2)}
\]</span>
for <span class="math inline">\(-\infty &lt; x &lt; \infty\)</span>.
Find the PDF of <span class="math inline">\(Y\)</span> where <span class="math inline">\(Y = X^2\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:ContTransform" class="exercise"><strong>Exercise 6.5  </strong></span>A random variable <span class="math inline">\(X\)</span> has distribution function
<span class="math display">\[
   F_X(x) =
   \begin{cases}
      0                &amp; \text{for $x \le -0.5$};\\
      \frac{2x + 1}{2} &amp; \text{for $-0.5 &lt; x &lt; 0.5$};\\
      1                &amp; \text{for $x \ge 0.5$}.
   \end{cases}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Find, and plot, the PDF of <span class="math inline">\(X\)</span>.</li>
<li>Find the distribution function, <span class="math inline">\(F_Y(y)\)</span>, of the random variable <span class="math inline">\(Y = 4 - X^2\)</span>.</li>
<li>Hence find, and plot, the PDF of <span class="math inline">\(Y\)</span>, <span class="math inline">\(f_Y(y)\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Projectile" class="exercise"><strong>Exercise 6.6  </strong></span>Suppose a projectile is fired at an angle <span class="math inline">\(\theta\)</span> from the horizontal with velocity <span class="math inline">\(v\)</span>.
The horizontal distance that the projectile travels <span class="math inline">\(D\)</span> is
<span class="math display">\[
   D = \frac{v^2}{g} \sin 2\theta,
\]</span>
where <span class="math inline">\(g\)</span> is the acceleration due to gravity (<span class="math inline">\(g\approx 9.8\)</span> m.s<sup><span class="math inline">\(-2\)</span></sup>).</p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(\theta\)</span> is uniformly distributed over the range <span class="math inline">\((0, \pi/4)\)</span>, find the probability density function of <span class="math inline">\(D\)</span>.</li>
<li>Sketch the PDF of <span class="math inline">\(D\)</span> over a suitable range for <span class="math inline">\(v = 12\)</span> and using <span class="math inline">\(g\approx 9.8\)</span>m.s<sup><span class="math inline">\(-2\)</span></sup>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:RandomExp" class="exercise"><strong>Exercise 6.7  </strong></span>Most computers have facilities to generate continuous uniform (pseudo-)random numbers between zero and one, say <span class="math inline">\(X\)</span>.
When needed, exponential random numbers are obtained from <span class="math inline">\(X\)</span> using the transformation <span class="math inline">\(Y = -\alpha\ln X\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Show that <span class="math inline">\(Y\)</span> has an exponential distribution and determine its parameters.</li>
<li>Deduce the mean and variance of <span class="math inline">\(Y\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:RandomW" class="exercise"><strong>Exercise 6.8  </strong></span>Consider a random variable <span class="math inline">\(W\)</span> for which <span class="math inline">\(\Pr(W = 2) = 1/6\)</span>, <span class="math inline">\(\Pr(W = -2) = 1/3\)</span> and <span class="math inline">\(\Pr(W = 0) = 1/2\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the probability function of <span class="math inline">\(W\)</span>.</li>
<li>Find the mean and variance of <span class="math inline">\(W\)</span>.</li>
<li>Determine the distribution of <span class="math inline">\(V = W^2\)</span>.</li>
<li>Find the distribution function of <span class="math inline">\(W\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:NormalMixture" class="exercise"><strong>Exercise 6.9  </strong></span>In a study to model the load on bridges <span class="citation">(<a href="references.html#ref-lu2019evaluating">Lu, Ma, and Liu 2019</a>)</span>, the researchers modelled the Gross Vehicle Weight (GVM, in kilonewtons) weight of smaller trucks <span class="math inline">\(S\)</span> using <span class="math inline">\(S\sim N(390, 740\)</span>, and the weight of bigger trucks <span class="math inline">\(B\)</span> using <span class="math inline">\(L\sim N(865, 142)\)</span>.
The total load distribution <span class="math inline">\(L\)</span> was then modelled as <span class="math inline">\(L = 0.24S + 0.76B\)</span>, reflecting the expected proportion if smaller and bigger trucks using the bridge.</p>
<ol style="list-style-type: decimal">
<li>Plot the distribution of <span class="math inline">\(L\)</span>.</li>
<li>Compute the mean and standard deviation of <span class="math inline">\(L\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:LogNormal" class="exercise"><strong>Exercise 6.10  </strong></span>Suppose the random variable <span class="math inline">\(X\)</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.
The random variable <span class="math inline">\(Y = \exp X\)</span> is said to have a <em>log-normal distribution</em>.</p>
<ol style="list-style-type: decimal">
<li>Determine the distribution function of <span class="math inline">\(Y\)</span> in terms of the function <span class="math inline">\(\Phi(\cdot)\)</span> (see Def. <a href="ContinuousDistributions.html#def:StdNormalPhiNotation">8.7</a>).</li>
<li>Differentiate to find the PDF of <span class="math inline">\(Y\)</span>.</li>
<li>Plot the log-normal distribution for various parameter values.</li>
<li>Determine <span class="math inline">\(\Pr(Y &gt; 2 | Y &lt; 1)\)</span> when <span class="math inline">\(\mu = 2\)</span> and <span class="math inline">\(\sigma^2 = 2\)</span>.</li>
</ol>
<p>(<strong>Hint</strong>: Use the <code><a href="https://rdrr.io/r/stats/Lognormal.html">dlnorm()</a></code> and <code><a href="https://rdrr.io/r/stats/Lognormal.html">plnorm()</a></code> functions in <strong>R</strong>, where <span class="math inline">\(\mu = {}\)</span><code>meanlog</code> and <span class="math inline">\(\sigma = {}\)</span><code>sdlog</code>.)</p>
</div>
<div class="exercise">
<p><span id="exr:BinomXform" class="exercise"><strong>Exercise 6.11  </strong></span>If <span class="math inline">\(X\)</span> is a random variable with probability function
<span class="math display">\[
   \Pr(X = x) = \binom{4}{x} (0.2)^x (0.8)^{4 - x} \quad \text{for $x = 0, 1, 2, 3, 4$},
\]</span>
find the probability function of the random variable defined by <span class="math inline">\(Y = \sqrt{X}\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:Xminus3" class="exercise"><strong>Exercise 6.12  </strong></span>Given the random variable <span class="math inline">\(X\)</span> with probability function
<span class="math display">\[
   \Pr(X = x) = \frac{x^2}{30} \quad \text{for $x = 1, 2, 3, 4$},
\]</span>
find the probability function of <span class="math inline">\(Y= (X - 3)^2\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:GiveDF2" class="exercise"><strong>Exercise 6.13  </strong></span>A random variable <span class="math inline">\(X\)</span> has distribution function
<span class="math display">\[
   F_X(x) =
   \begin{cases}
      0 &amp; \text{for $x &lt; -0.5$};\\
      \frac{2x + 1}{2}, &amp; \text{for $-0.5 &lt; x &lt; 0.5$}; \\
      1 &amp; \text{for $x &gt; 0.5$}.
   \end{cases}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Find the distribution function, <span class="math inline">\(F_Y(y)\)</span>, of the random variable <span class="math inline">\(Y = 4 - X^2\)</span>.</li>
<li>Hence find the PDF of <span class="math inline">\(Y\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-24" class="exercise"><strong>Exercise 6.14  </strong></span>If the random variable <span class="math inline">\(X\)</span> has an exponential distributed with mean <span class="math inline">\(1\)</span>, show that the distribution of <span class="math inline">\(-\log(X)\)</span> has a Gumbel distribution (Eq. <a href="ChapExpectation.html#eq:Gumbel">(5.7)</a>) with <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\sigma = 1\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-25" class="exercise"><strong>Exercise 6.15  </strong></span>Let <span class="math inline">\(X\)</span> have a gamma distribution with parameters <span class="math inline">\(\alpha &gt; 2\)</span> and <span class="math inline">\(\beta &gt; 0\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Prove that the mean of <span class="math inline">\(1/X\)</span> is <span class="math inline">\(\beta/(\alpha - 1)\)</span>.</li>
<li>Prove that the variance of <span class="math inline">\(1/X\)</span> is <span class="math inline">\(\beta^2/[(\alpha - 1)^2(\alpha - 2)]\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:BetaHospital2" class="exercise"><strong>Exercise 6.16  </strong></span>In a study modelling waiting times at a hospital <span class="citation">(<a href="references.html#ref-khadem2008evaluating">Khadem et al. 2008</a>)</span>, patients are classified into one of three categories:</p>
<ul>
<li>Red: Critically ill or injured patients.</li>
<li>Yellow: Moderately ill or
injured patients.</li>
<li>Green: Minimally injured or
uninjured patients.</li>
</ul>
<p>For ‘Green’ patients, the service time <span class="math inline">\(S\)</span> was modelled as <span class="math inline">\(S = 4.5 + 11V\)</span>, where <span class="math inline">\(V \sim \text{Beta}(0.287, 0.926)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Produce well-labelled plots of the PDF and df of <span class="math inline">\(S\)</span>, showing important features.</li>
<li>What proportion of patients have a service time exceeding <span class="math inline">\(15\,\text{mins}\)</span>?</li>
<li>The quickest <span class="math inline">\(20\)</span>% of patients are serviced within what time?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ExpHospital2" class="exercise"><strong>Exercise 6.17  </strong></span>In a study modelling waiting times at a hospital <span class="citation">(<a href="references.html#ref-khadem2008evaluating">Khadem et al. 2008</a>)</span>, patients are classified into one of three categories:</p>
<ul>
<li>Red: Critically ill or injured patients.</li>
<li>Yellow: Moderately ill or
injured patients.</li>
<li>Green: Minimally injured or
uninjured patients.</li>
</ul>
<p>The time (in minutes) spent in the reception are for ‘Yellow’ patients, say <span class="math inline">\(T\)</span>, is modelled as <span class="math inline">\(T = 0.5 + W\)</span>, where <span class="math inline">\(W\sim \text{Exp}(16.5)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Plot the PDF and df of <span class="math inline">\(T\)</span>.</li>
<li>What proportion of patients waits more than <span class="math inline">\(20 mins\)</span>, if they have already been waiting for <span class="math inline">\(10\,\text{mins}\)</span>?</li>
<li>How long to the slowest <span class="math inline">\(10\)</span>% of patients need to wait?</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:Not1to1" class="exercise"><strong>Exercise 6.18  </strong></span>Suppose the random variable <span class="math inline">\(Z\)</span> has the PDF
<span class="math display">\[
  f_Z(z) =
  \begin{cases}
    \frac{1}{3} &amp; \text{for $-1 &lt; z &lt; 2$};\\
    0 &amp; \text{elsewhere}.
  \end{cases}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Find the <em>probability density function</em> of <span class="math inline">\(Y\)</span>, where <span class="math inline">\(Y = Z^2\)</span>, using the <strong>distribution function method</strong>.</li>
<li>Confirm that your final PDF of <span class="math inline">\(Y\)</span> is a valid PDF.</li>
<li>Produce a well-labelled plot of the PDF of <span class="math inline">\(Y\)</span>.
Ensure all important features and points are clearly labelled.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:ChiSquaredGamma" class="exercise"><strong>Exercise 6.19  </strong></span>Show that the chi-squared distribution is a special case of the gamma distribution, with <span class="math inline">\(\alpha = \nu/2\)</span> and <span class="math inline">\(\beta = 2\)</span>.</p>
</div>
<div class="exercise">
<p><span id="exr:TrickyXform1" class="exercise"><strong>Exercise 6.20  </strong></span>Suppose the random variable <span class="math inline">\(X\)</span> is defined as shown in Fig. <a href="ChapterTransformations.html#fig:TrickyX">6.8</a>.</p>
<ol style="list-style-type: decimal">
<li>Determine the distribution function for <span class="math inline">\(X\)</span>.</li>
<li>Find the probability density function for the random variable <span class="math inline">\(Y\)</span>, where <span class="math inline">\(Y = 6 - 2X\)</span>.</li>
<li>Confirm that your probability density function for <span class="math inline">\(Y\)</span> is a valid pdf.</li>
<li>Plot the probability density function of <span class="math inline">\(Y\)</span>.</li>
</ol>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:TrickyX"></span>
<img src="06-Transformations_files/figure-html/TrickyX-1.png" alt="The probability density function for the random variable\ $X$." width="90%"><p class="caption">
FIGURE 6.8: The probability density function for the random variable <span class="math inline">\(X\)</span>.
</p>
</div>
<div class="exercise">
<p><span id="exr:TrickyXform2" class="exercise"><strong>Exercise 6.21  </strong></span>Suppose the random variable <span class="math inline">\(X\)</span> is defined as shown in Fig. <a href="ChapterTransformations.html#fig:TrickyX">6.8</a>.</p>
<ol style="list-style-type: decimal">
<li>Determine the distribution function for <span class="math inline">\(X\)</span> (this was done in Exercise <a href="ChapterTransformations.html#exr:TrickyXform1">6.20</a>).</li>
<li>Find the probability density function for the random variable <span class="math inline">\(Z\)</span>, where <span class="math inline">\(Z = (X - 2)^2\)</span>.</li>
<li>Confirm that your probability density function for <span class="math inline">\(Z\)</span> is a valid pdf.</li>
<li>Plot the probability density function of <span class="math inline">\(Z\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:RunnerVelocity" class="exercise"><strong>Exercise 6.22  </strong></span>The time taken to run a distance <span class="math inline">\(D\)</span> (in metres) by a professional athlete, say <span class="math inline">\(T\)</span> (in seconds), varies with the distribution shown in Fig. <a href="ChapterTransformations.html#fig:RunnerVelocityVoltage">6.9</a> (left panel).
The average velocity of the runner, say <span class="math inline">\(V\)</span>, is related to the time by <span class="math inline">\(V = D/T\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Determine the probability density function for the runner’s velocity.</li>
<li>Suppose <span class="math inline">\(D = 100\)</span>, <span class="math inline">\(\mu = 12\)</span> and <span class="math inline">\(\Delta = 0.25\)</span>.
Plot the probability density function for <span class="math inline">\(V\)</span>.</li>
</ol>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:RunnerVelocityVoltage"></span>
<img src="06-Transformations_files/figure-html/RunnerVelocityVoltage-1.png" alt="The probability density function for the random variable\ $T$, the time for the run." width="90%"><p class="caption">
FIGURE 6.9: The probability density function for the random variable <span class="math inline">\(T\)</span>, the time for the run.
</p>
</div>
<div class="exercise">
<p><span id="exr:VoltagePower" class="exercise"><strong>Exercise 6.23  </strong></span>Suppose the instantaneous voltage <span class="math inline">\(V\)</span> (in volts) in a circuit varies over time such that
<span class="math display">\[
  f_V(v) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{ -\frac{x^2}{2\sigma^2}\right\}.
\]</span>
as shown in Fig. <a href="ChapterTransformations.html#fig:RunnerVelocityVoltage">6.9</a> (right panel).
(Later, we will identify this as the <em>normal distribution</em>.)</p>
<ol style="list-style-type: decimal">
<li>Determine the probability density function of the instantaneous <em>power</em> in the circuit <span class="math inline">\(P\)</span>, where <span class="math inline">\(P = V^2/R\)</span> for some circuit resistance <span class="math inline">\(R\)</span> (in ohms).</li>
<li>Suppose <span class="math inline">\(\sigma = 1\)</span>, and <span class="math inline">\(R = 10\)</span>.
Plot the probability density function for <span class="math inline">\(P\)</span>.</li>
</ol>
</div>

</div>
</div>



<hr>
<div class="footer"><span style="color: gray; font-size:0.7em">Peter K. Dunn, 2024: <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></span></div>
  <div class="chapter-nav">
<div class="prev"><a href="ChapExpectation.html"><span class="header-section-number">5</span> Mathematical expectation</a></div>
<div class="next"><a href="DiscreteDistributions.html"><span class="header-section-number">7</span> Standard discrete distributions</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ChapterTransformations"><span class="header-section-number">6</span> Transformations of random variables</a></li>
<li><a class="nav-link" href="#introduction"><span class="header-section-number">6.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#ChangeOfVariable"><span class="header-section-number">6.2</span> The change of variable method</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ChangeOfVarDiscrete"><span class="header-section-number">6.2.1</span> Discrete random variables</a></li>
<li><a class="nav-link" href="#ChangeOfVarContinuous"><span class="header-section-number">6.2.2</span> Continuous random variables</a></li>
<li><a class="nav-link" href="#ChangeOfVarDiscreteBivariate"><span class="header-section-number">6.2.3</span> Discrete bivariate case????</a></li>
</ul>
</li>
<li><a class="nav-link" href="#DistributonFunctionMethod"><span class="header-section-number">6.3</span> The distribution function method</a></li>
<li><a class="nav-link" href="#TransformationMoments"><span class="header-section-number">6.4</span> The moment-generating function method</a></li>
<li><a class="nav-link" href="#exercises"><span class="header-section-number">6.5</span> Exercises</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PeterKDunn/DistTheory/blob/main/06-Transformations.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PeterKDunn/DistTheory/edit/main/06-Transformations.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>The Theory of Statistical Distributions</strong>" was written by Peter K. Dunn. It was last built on Last updated: 2025-12-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
